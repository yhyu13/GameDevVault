<!DOCTYPE html>
<!-- saved from url=(0038)https://zhuanlan.zhihu.com/p/430101220 -->
<html lang="zh" data-hairline="true" data-theme="light" data-rh="data-theme"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><title>【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎</title><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta name="renderer" content="webkit"><meta name="force-rendering" content="webkit"><meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"><meta name="google-site-verification" content="FTeR0c8arOPKh8c5DYh_9uu98_zJbaWw53J-Sch9MTg"><meta data-rh="true" name="keywords" content="高性能计算,图形处理器（GPU）,大规模机器学习"><meta data-rh="true" name="description" content="目前网络通信已经成为分布式机器学习的性能瓶颈。本文将讨论GPU通信和PCIe P2P DMA技术，为大规模分布式应用通信性能的优化提供参考。本文将依次回答如下三个问题，并探讨今后IO设备互连该走向什么方向。 为了回答…"><meta data-rh="true" property="og:title" content="【研究综述】浅谈GPU通信和PCIe P2P DMA"><meta data-rh="true" property="og:url" content="https://zhuanlan.zhihu.com/p/430101220"><meta data-rh="true" property="og:description" content="目前网络通信已经成为分布式机器学习的性能瓶颈。本文将讨论GPU通信和PCIe P2P DMA技术，为大规模分布式应用通信性能的优化提供参考。本文将依次回答如下三个问题，并探讨今后IO设备互连该走向什么方向。 为了回答…"><meta data-rh="true" property="og:image" content="https://pic1.zhimg.com/v2-89ea4d6acbeca045b1983fd8c082e497_720w.jpg?source=172ae18b"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="og:site_name" content="知乎专栏"><link data-rh="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-152.a53ae37b.png"><link data-rh="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-152.a53ae37b.png" sizes="152x152"><link data-rh="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-120.bbce8f18.png" sizes="120x120"><link data-rh="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-76.cbade8f9.png" sizes="76x76"><link data-rh="true" rel="apple-touch-icon" href="https://static.zhihu.com/heifetz/assets/apple-touch-icon-60.8f6c52aa.png" sizes="60x60"><link crossorigin="" rel="shortcut icon" type="image/x-icon" href="https://static.zhihu.com/heifetz/favicon.ico"><link crossorigin="" rel="search" type="application/opensearchdescription+xml" href="https://static.zhihu.com/heifetz/search.xml" title="知乎"><link rel="dns-prefetch" href="https://static.zhimg.com/"><link rel="dns-prefetch" href="https://pica.zhimg.com/"><link rel="dns-prefetch" href="https://pic1.zhimg.com/"><link rel="dns-prefetch" href="https://pic2.zhimg.com/"><link rel="dns-prefetch" href="https://pic3.zhimg.com/"><link rel="dns-prefetch" href="https://pic4.zhimg.com/"><link rel="dns-prefetch" href="https://static.zhihu.com/"><style data-emotion-css="1m4merm">.u-safeAreaInset-top{height:constant(safe-area-inset-top) !important;height:env(safe-area-inset-top) !important;}.u-safeAreaInset-bottom{height:constant(safe-area-inset-bottom) !important;height:env(safe-area-inset-bottom) !important;}</style><link href="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/column.app.216a26f4.9984cbe9a79e1fa699d5.css" crossorigin="" rel="stylesheet"><script nonce="">!function(){"use strict";!function(e,n){var r=[];function t(e){return function(){r.push([e,arguments])}}n.Raven={captureException:t("captureException"),captureMessage:t("captureMessage"),captureBreadcrumb:t("captureBreadcrumb")};var a,o,c,i,s,u="undefined"!=typeof DOMError;function d(e){var n=e instanceof Error||e instanceof ErrorEvent||u&&e instanceof DOMError||e instanceof DOMException;Raven.captureException(n?e:new Error(e.message||e.reason))}n.addEventListener("unhandledrejection",d),n.addEventListener("error",d,!0),a=e.src,o=e,c=function(){r.forEach(function(e){var n;(n=Raven)[e[0]].apply(n,e[1])}),n.removeEventListener("unhandledrejection",d),n.removeEventListener("error",d,!0)},i=document.head||document.getElementsByTagName("head")[0],(s=document.createElement("script")).crossOrigin=o.crossOrigin,s.dataset.sentryConfig=o["data-sentry-config"],s.onload=c,s.src=a,i.appendChild(s)}({"defer":true,"crossOrigin":"anonymous","src":"https://unpkg.zhimg.com/@cfe/sentry-script@1.3.1/dist/init.js","data-sentry-config":"{\"dsn\":\"https://2d8d764432cc4f6fb3bc78ab9528299d@crash2.zhihu.com/1224\",\"sampleRate\":0.1,\"release\":\"4582-0108e965\",\"ignoreErrorNames\":[\"NetworkError\",\"SecurityError\"],\"ignoreErrorsPreset\":\"ReactApp\",\"tags\":{\"app_name\":\"heifetz\"}}"},window)}();
</script><script crossorigin="anonymous" data-sentry-config="{&quot;dsn&quot;:&quot;https://2d8d764432cc4f6fb3bc78ab9528299d@crash2.zhihu.com/1224&quot;,&quot;sampleRate&quot;:0.1,&quot;release&quot;:&quot;4582-0108e965&quot;,&quot;ignoreErrorNames&quot;:[&quot;NetworkError&quot;,&quot;SecurityError&quot;],&quot;ignoreErrorsPreset&quot;:&quot;ReactApp&quot;,&quot;tags&quot;:{&quot;app_name&quot;:&quot;heifetz&quot;}}" src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/init.js.download"></script><style data-emotion-css="1l12z7y">.css-1l12z7y{box-shadow:0px 16px 32px rgba(0,0,0,0.04);}</style><style data-emotion-css="1hlrcxk">.css-1hlrcxk{-webkit-transition-property:fill;transition-property:fill;-webkit-transition-duration:0.25s;transition-duration:0.25s;-webkit-transition-timing-function:ease-in;transition-timing-function:ease-in;}</style><style data-emotion-css="1cd9gw4">.css-1cd9gw4{margin-left:.3em;}</style><style data-emotion-css="1yuhvjn">.css-1yuhvjn{margin-top:16px;}</style><style data-emotion-css="3jt6os">.css-3jt6os .FileLinkCard{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;background-color:rgba(246,246,246,0.88);border-radius:12px;box-sizing:border-box;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;margin:1em auto;max-width:100%;overflow:hidden;padding:12px;position:relative;width:390px;}.css-3jt6os .FileLinkCard-icon{-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;height:30px;width:30px;}.css-3jt6os .FileLinkCard-info{margin-left:12px;}.css-3jt6os .FileLinkCard-name{color:#121212;font-size:15px;font-weight:500;line-height:21px;display:-webkit-box;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:2;}.css-3jt6os .FileLinkCard-meta{color:#999999;font-size:12px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;line-height:14px;margin-top:5px;}.css-3jt6os .FileLinkCard-source{white-space:pre;}</style><style data-emotion-css="1wr1m8">.css-1wr1m8 .LinkCard.new{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;box-sizing:border-box;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;width:390px;min-height:84px;border-radius:8px;max-width:100%;overflow:hidden;margin:16px auto;padding:12px 12px 9px 12px;background-color:#F6F6F6;}.css-1wr1m8 .LinkCard.new,.css-1wr1m8 .LinkCard.new:hover{-webkit-text-decoration:none;text-decoration:none;border:none !important;color:inherit !important;}.css-1wr1m8 .LinkCard.new .LinkCard-contents{display:block;-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;position:relative;}.css-1wr1m8 .LinkCard.new .LinkCard-contents .loading{height:14px;background:#EBEBEB;border-radius:7px;}.css-1wr1m8 .LinkCard.new .LinkCard-contents.withTitle{margin-bottom:3px;}.css-1wr1m8 .LinkCard.new .LinkCard-title{display:-webkit-box;font-size:15px;font-weight:500;line-height:1.4;margin-bottom:2px;color:#121212;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-1wr1m8 .LinkCard.new .LinkCard-title.two-line{line-height:20px;display:-webkit-box;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:2;}.css-1wr1m8 .LinkCard.new .LinkCard-title.loading{margin-bottom:8px;width:80%;}.css-1wr1m8 .LinkCard.new .LinkCard-title.loading.withTitle{margin-bottom:6px;}.css-1wr1m8 .LinkCard.new .LinkCard-title.loadingTitle{margin-bottom:5px;}.css-1wr1m8 .LinkCard.new .LinkCard-excerpt{display:-webkit-box;text-overflow:ellipsis;font-size:13px;line-height:18px;color:#999999;margin-bottom:4px;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-1wr1m8 .LinkCard.new .LinkCard-excerpt .LinkCard-author{color:#444444;}.css-1wr1m8 .LinkCard.new .LinkCard-desc{display:-webkit-box;font-size:13px;height:18px;line-height:18px;color:#999999;word-break:break-all;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-1wr1m8 .LinkCard.new .LinkCard-desc .LinkCard-tag,.css-1wr1m8 .LinkCard.new .LinkCard-desc .tag{display:inline-block;font-size:11px;margin-left:8px;padding:0 4px;border-radius:3px;background:rgba(211,211,211,0.3);}.css-1wr1m8 .LinkCard.new .LinkCard-desc.loading{width:40%;}.css-1wr1m8 .LinkCard.new .LinkCard-desc svg{margin-right:2px;}.css-1wr1m8 .LinkCard.new .LinkCard-image{-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;background-color:#EBEBEB;background-size:cover;background-position:center;position:relative;display:block;width:60px;height:60px;margin-left:20px;object-fit:cover;border-radius:inherit;overflow:hidden;}.css-1wr1m8 .LinkCard.new .LinkCard-image.LinkCard-image--default{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;background-color:#EBEBEB;color:#D3D3D3;}.css-1wr1m8 .LinkCard.new .LinkCard-image.LinkCard-image--default svg{color:#999999;}.css-1wr1m8 .LinkCard.new .LinkCard-image img{width:100%;height:100%;object-fit:cover;}.css-1wr1m8 .LinkCard.new .LinkCard-image .LinkCard-image--video{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;position:absolute;top:50%;left:50%;-webkit-transform:translateX(-50%) translateY(-50%);-ms-transform:translateX(-50%) translateY(-50%);transform:translateX(-50%) translateY(-50%);width:24px;height:24px;border-radius:12px;background:rgba(255,255,255,0.9);pointer-events:none;}.css-1wr1m8 .LinkCard.new .LinkCard-image .LinkCard-image--video svg{color:#444444;}.css-1wr1m8 .LinkCard.new .LinkCard-richText .text{color:#444444;}.css-1wr1m8 .LinkCard.new .LinkCard-richText .bold{font-weight:600;}.css-1wr1m8 .LinkCard.new .LinkCard-richText .tag{margin-left:4px;}.css-1wr1m8 .LinkCard.old{position:relative;display:block;margin:1em auto;width:390px;box-sizing:border-box;border-radius:12px;max-width:100%;overflow:hidden;}.css-1wr1m8 .LinkCard.old,.css-1wr1m8 .LinkCard.old:hover{-webkit-text-decoration:none;text-decoration:none;border:none !important;color:inherit !important;}.css-1wr1m8 .LinkCard-ecommerceLoadingCard{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;padding:12px;border-radius:inherit;height:80px;box-sizing:border-box;background:rgba(246,246,246,0.88);color:#D3D3D3;}.css-1wr1m8 .LinkCard-ecommerceLoadingCardAvatarWrapper{width:60px;height:60px;background:#EBEBEB;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;border-radius:6px;margin-right:10px;}.css-1wr1m8 .LinkCard-ecommerceLoadingCardNetwork{width:20px;height:20px;}.css-1wr1m8 .LinkCard-ecommerceLoadingCardLoadingbar{height:60px;-webkit-flex:1;-ms-flex:1;flex:1;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}.css-1wr1m8 .LinkCard-ecommerceLoadingCardLoadingbar span{height:16px;display:inline-block;background:#EBEBEB;}.css-1wr1m8 .LinkCard-ecommerceLoadingCardLoadingbar span:nth-of-type(1){width:60px;margin-bottom:4px;}.css-1wr1m8 .LinkCard-ecommerceLoadingCardLoadingbar span:nth-of-type(2){width:127px;}</style><style data-emotion-css="hypxot">.css-hypxot .LinkCard.old{position:relative;display:block;margin:1em auto;width:390px;box-sizing:border-box;border-radius:12px;max-width:100%;overflow:hidden;}.css-hypxot .LinkCard.old,.css-hypxot .LinkCard.old:hover{-webkit-text-decoration:none;text-decoration:none;border:none !important;color:inherit !important;}.css-hypxot .LinkCard-ecommerceLoadingCard{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;padding:12px;border-radius:inherit;height:80px;box-sizing:border-box;background:rgba(246,246,246,0.88);color:#D3D3D3;}.css-hypxot .LinkCard-ecommerceLoadingCardAvatarWrapper{width:60px;height:60px;background:#EBEBEB;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;border-radius:6px;margin-right:10px;}.css-hypxot .LinkCard-ecommerceLoadingCardNetwork{width:20px;height:20px;}.css-hypxot .LinkCard-ecommerceLoadingCardLoadingbar{height:60px;-webkit-flex:1;-ms-flex:1;flex:1;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}.css-hypxot .LinkCard-ecommerceLoadingCardLoadingbar span{height:16px;display:inline-block;background:#EBEBEB;}.css-hypxot .LinkCard-ecommerceLoadingCardLoadingbar span:nth-of-type(1){width:60px;margin-bottom:4px;}.css-hypxot .LinkCard-ecommerceLoadingCardLoadingbar span:nth-of-type(2){width:127px;}.css-hypxot .LinkCard.new{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;box-sizing:border-box;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;width:390px;min-height:84px;border-radius:8px;max-width:100%;overflow:hidden;margin:16px auto;padding:12px 12px 9px 12px;background-color:#F6F6F6;}.css-hypxot .LinkCard.new,.css-hypxot .LinkCard.new:hover{-webkit-text-decoration:none;text-decoration:none;border:none !important;color:inherit !important;}.css-hypxot .LinkCard.new .LinkCard-contents{display:block;-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;position:relative;}.css-hypxot .LinkCard.new .LinkCard-contents .loading{height:14px;background:#EBEBEB;border-radius:7px;}.css-hypxot .LinkCard.new .LinkCard-contents.withTitle{margin-bottom:3px;}.css-hypxot .LinkCard.new .LinkCard-title{display:-webkit-box;font-size:15px;font-weight:500;line-height:1.4;margin-bottom:2px;color:#121212;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-hypxot .LinkCard.new .LinkCard-title.two-line{line-height:20px;display:-webkit-box;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:2;}.css-hypxot .LinkCard.new .LinkCard-title.loading{margin-bottom:8px;width:80%;}.css-hypxot .LinkCard.new .LinkCard-title.loading.withTitle{margin-bottom:6px;}.css-hypxot .LinkCard.new .LinkCard-title.loadingTitle{margin-bottom:5px;}.css-hypxot .LinkCard.new .LinkCard-excerpt{display:-webkit-box;text-overflow:ellipsis;font-size:13px;line-height:18px;color:#999999;margin-bottom:4px;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-hypxot .LinkCard.new .LinkCard-excerpt .LinkCard-author{color:#444444;}.css-hypxot .LinkCard.new .LinkCard-desc{display:-webkit-box;font-size:13px;height:18px;line-height:18px;color:#999999;word-break:break-all;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-hypxot .LinkCard.new .LinkCard-desc .LinkCard-tag,.css-hypxot .LinkCard.new .LinkCard-desc .tag{display:inline-block;font-size:11px;margin-left:8px;padding:0 4px;border-radius:3px;background:rgba(211,211,211,0.3);}.css-hypxot .LinkCard.new .LinkCard-desc.loading{width:40%;}.css-hypxot .LinkCard.new .LinkCard-desc svg{margin-right:2px;}.css-hypxot .LinkCard.new .LinkCard-image{-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;background-color:#EBEBEB;background-size:cover;background-position:center;position:relative;display:block;width:60px;height:60px;margin-left:20px;object-fit:cover;border-radius:inherit;overflow:hidden;}.css-hypxot .LinkCard.new .LinkCard-image.LinkCard-image--default{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;background-color:#EBEBEB;color:#D3D3D3;}.css-hypxot .LinkCard.new .LinkCard-image.LinkCard-image--default svg{color:#999999;}.css-hypxot .LinkCard.new .LinkCard-image img{width:100%;height:100%;object-fit:cover;}.css-hypxot .LinkCard.new .LinkCard-image .LinkCard-image--video{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;position:absolute;top:50%;left:50%;-webkit-transform:translateX(-50%) translateY(-50%);-ms-transform:translateX(-50%) translateY(-50%);transform:translateX(-50%) translateY(-50%);width:24px;height:24px;border-radius:12px;background:rgba(255,255,255,0.9);pointer-events:none;}.css-hypxot .LinkCard.new .LinkCard-image .LinkCard-image--video svg{color:#444444;}.css-hypxot .LinkCard.new .LinkCard-richText .text{color:#444444;}.css-hypxot .LinkCard.new .LinkCard-richText .bold{font-weight:600;}.css-hypxot .LinkCard.new .LinkCard-richText .tag{margin-left:4px;}.css-hypxot .FileLinkCard{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;background-color:rgba(246,246,246,0.88);border-radius:12px;box-sizing:border-box;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;margin:1em auto;max-width:100%;overflow:hidden;padding:12px;position:relative;width:390px;}.css-hypxot .FileLinkCard-icon{-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;height:30px;width:30px;}.css-hypxot .FileLinkCard-info{margin-left:12px;}.css-hypxot .FileLinkCard-name{color:#121212;font-size:15px;font-weight:500;line-height:21px;display:-webkit-box;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:2;}.css-hypxot .FileLinkCard-meta{color:#999999;font-size:12px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;line-height:14px;margin-top:5px;}.css-hypxot .FileLinkCard-source{white-space:pre;}</style><style data-emotion-css="yvdm7v animation-1sh55c5">.css-yvdm7v{word-break:break-word;line-height:1.6;}.css-yvdm7v a.UserLink-link{color:#175199;}.css-yvdm7v a.UserLink-link:hover{border-bottom:1px solid #175199;}.css-yvdm7v lazy[data-lazy-status]{background-color:#F6F6F6;}.css-yvdm7v lazy[data-lazy-status="ok"]{background-color:transparent;-webkit-animation:animation-1sh55c5 0.5s ease-in;animation:animation-1sh55c5 0.5s ease-in;}.css-yvdm7v > [data-first-child]{margin-top:0;}.css-yvdm7v > :last-child{margin-bottom:0;}.css-yvdm7v h1,.css-yvdm7v h2{clear:left;margin-top:calc((1.4em * 2) / 1.2);margin-bottom:calc(1.4em / 1.2);font-size:1.2em;line-height:1.5;font-weight:600;}.css-yvdm7v h3,.css-yvdm7v h4,.css-yvdm7v h5,.css-yvdm7v h6{clear:left;margin-top:calc((1.4em * 1.5) / 1.1);margin-bottom:calc(1.4em / 1.1);font-size:1.1em;line-height:1.5;font-weight:600;}.css-yvdm7v u{-webkit-text-decoration:none;text-decoration:none;border-bottom:1px solid #444444;}.css-yvdm7v b{font-weight:600;}.css-yvdm7v sup{font-size:0.8em;}.css-yvdm7v sup[data-draft-type='reference']{color:#175199;}.css-yvdm7v a:focus{outline:none;-webkit-transition:box-shadow 0.3s;transition:box-shadow 0.3s;}html[data-focus-visible] .css-yvdm7v a:focus{box-shadow:0 0 0 2px #FFFFFF,0 0 0 4px rgba(5,109,232,0.3);}.css-yvdm7v a.ztext-link,.css-yvdm7v a.internal,.css-yvdm7v a.external{-webkit-text-decoration:none;text-decoration:none;cursor:pointer;border-bottom:1px solid #808080;}.css-yvdm7v a.ztext-link:hover,.css-yvdm7v a.internal:hover,.css-yvdm7v a.external:hover{color:#175199;border-bottom:1px solid #175199;}.css-yvdm7v a.ztext-link > .ellipsis::after,.css-yvdm7v a.internal > .ellipsis::after,.css-yvdm7v a.external > .ellipsis::after{content:'...';}.css-yvdm7v a.ztext-link > .invisible,.css-yvdm7v a.internal > .invisible,.css-yvdm7v a.external > .invisible{font:0/0 a;color:transparent;text-shadow:none;background-color:transparent;}.css-yvdm7v a.ztext-link u,.css-yvdm7v a.internal u,.css-yvdm7v a.external u{border:none;}.css-yvdm7v a.member_mention{color:#175199;}.css-yvdm7v a.member_mention:hover{border-bottom:1px solid #175199;}.css-yvdm7v p{margin:1.4em 0;}.css-yvdm7v p.ztext-empty-paragraph{margin:calc((2.8em- (1.4em * 2 + 1.6em)) / 2) 0;}.css-yvdm7v p.ztext-empty-paragraph + .ztext-empty-paragraph{margin:1.4em 0;}.css-yvdm7v hr{margin:4em auto;width:240px;max-width:100%;border:none;border-top:1px solid #D3D3D3;}.css-yvdm7v img[eeimg]{max-width:100%;vertical-align:middle;}.css-yvdm7v img[eeimg="1"]{margin:0 3px;max-width:calc(100% - 6px);display:inline-block;}.css-yvdm7v img[eeimg="2"]{margin:1.4em auto;display:block;}.css-yvdm7v blockquote{margin:1.4em 0;padding-left:1em;color:#646464;border-left:3px solid #D3D3D3;}.css-yvdm7v ol,.css-yvdm7v ul{margin:1.4em 0;padding:0;width:100%;}.css-yvdm7v ol ol,.css-yvdm7v ul ol,.css-yvdm7v ol ul,.css-yvdm7v ul ul{margin:0;}.css-yvdm7v ol li::before,.css-yvdm7v ul li::before{width:1em;}.css-yvdm7v ol > ol,.css-yvdm7v ul > ol,.css-yvdm7v ol > ul,.css-yvdm7v ul > ul{display:table-row;}.css-yvdm7v ol > ol::before,.css-yvdm7v ul > ol::before,.css-yvdm7v ol > ul::before,.css-yvdm7v ul > ul::before{display:table-cell;content:'';}.css-yvdm7v ul{display:table;}.css-yvdm7v ul>li{display:table-row;list-style:none;}.css-yvdm7v ul>li::before{display:table-cell;content:'•  ';white-space:pre;}.css-yvdm7v ol{display:table;counter-reset:ol;}.css-yvdm7v ol > li{display:table-row;list-style:none;}.css-yvdm7v ol > li::before{display:table-cell;text-align:right;counter-increment:ol;content:counter(ol) '. ';white-space:pre;}.css-yvdm7v ol ol{counter-reset:ol2;}.css-yvdm7v ol ol li::before{counter-increment:ol2;content:counter(ol2) '. ';}.css-yvdm7v ol ol ol{counter-reset:ol3;}.css-yvdm7v ol ol ol li::before{counter-increment:ol3;content:counter(ol3) '. ';}.css-yvdm7v ol ol ol ol{counter-reset:ol4;}.css-yvdm7v ol ol ol ol li::before{counter-increment:ol4;content:counter(ol4) '. ';}.css-yvdm7v figure{margin:1.4em 0;}.css-yvdm7v figure .content_image,.css-yvdm7v figure .origin_image{margin:0 auto;}.css-yvdm7v figure figcaption{margin-top:calc(0.6em / 0.9);padding:0 1em;font-size:0.9em;line-height:1.5;text-align:center;color:#999999;}.css-yvdm7v figure + figure{margin-top:calc(1.4em * 1.6);}.css-yvdm7v figure[data-size='small'],.css-yvdm7v figure:not([data-size]) > [data-size='small']{clear:both;}.css-yvdm7v figure[data-size='left'],.css-yvdm7v figure:not([data-size]) > [data-size='left']{float:left;margin:0 20px 20px 0;max-width:33%;}.css-yvdm7v figure[data-size='right'],.css-yvdm7v figure:not([data-size]) > [data-size='right']{float:right;margin:0 0 20px 20px;max-width:33%;}.css-yvdm7v figure[data-size='collapse']{margin-bottom:0;}.css-yvdm7v figure[data-size='collapse'] + figure{margin-top:0;}.css-yvdm7v .content_image,.css-yvdm7v .origin_image{display:block;max-width:100%;margin:1.4em auto;}.css-yvdm7v .content_image[data-size='small'],.css-yvdm7v .origin_image[data-size='small']{max-width:40%;}.css-yvdm7v .content_image.zh-lightbox-thumb,.css-yvdm7v .origin_image.zh-lightbox-thumb{cursor:-webkit-zoom-in;cursor:-moz-zoom-in;cursor:zoom-in;}.css-yvdm7v code{margin:0 2px;padding:3px 4px;border-radius:3px;font-size:0.9em;background-color:#F6F6F6;}.css-yvdm7v pre{margin:1.4em 0;padding:calc(0.8em / 0.9);font-size:0.9em;word-break:initial;word-wrap:initial;white-space:pre;overflow:auto;-webkit-overflow-scrolling:touch;background:#F6F6F6;border-radius:4px;}.css-yvdm7v pre code{margin:0;padding:0;font-size:inherit;border-radius:0;background-color:inherit;}.css-yvdm7v li pre{white-space:pre-wrap;}.css-yvdm7v table[data-draft-type='table']{border-collapse:collapse;font-size:15px;margin:1.4em auto;max-width:100%;table-layout:fixed;text-align:left;width:100%;}.css-yvdm7v table[data-draft-type='table'][data-size='small']{min-width:260px;width:40%;}.css-yvdm7v table[data-draft-type='table'][data-row-style='striped'] tr:nth-of-type(2n + 1){background:#F6F6F6;}.css-yvdm7v table[data-draft-type='table'] td,.css-yvdm7v table[data-draft-type='table'] th{border:1px solid #D3D3D3;line-height:24px;height:24px;padding:3px 12px;}.css-yvdm7v table[data-draft-type='table'] th{background:#EBEBEB;color:#121212;font-weight:500;}.css-yvdm7v .video-box,.css-yvdm7v .link-box{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;margin:1.4em 0;overflow:auto;white-space:normal;cursor:pointer;border:solid 1px #EBEBEB;border-radius:4px;}.css-yvdm7v .highlight{margin:1em 0;}.css-yvdm7v .highlight pre{margin:0;}.css-yvdm7v .highlight .hll{background-color:#FDFDFD;}.css-yvdm7v .highlight .c{font-style:italic;color:#999999;}.css-yvdm7v .highlight .err{color:#F1403C;}.css-yvdm7v .highlight .k{font-weight:600;}.css-yvdm7v .highlight .o{font-weight:600;}.css-yvdm7v .highlight .cm{font-style:italic;color:#999999;}.css-yvdm7v .highlight .cp{font-weight:600;color:#999999;}.css-yvdm7v .highlight .c1{font-style:italic;color:#999999;}.css-yvdm7v .highlight .cs{font-style:italic;font-weight:600;color:#999999;}.css-yvdm7v .highlight .gd{color:#FF3366;}.css-yvdm7v .highlight .ge{font-style:italic;}.css-yvdm7v .highlight .gr{color:#F1403C;}.css-yvdm7v .highlight .gh{color:#999999;}.css-yvdm7v .highlight .gi{color:#12b370;}.css-yvdm7v .highlight .go{color:#808080;}.css-yvdm7v .highlight .gp{color:#646464;}.css-yvdm7v .highlight .gs{font-weight:600;}.css-yvdm7v .highlight .gu{color:#999999;}.css-yvdm7v .highlight .gt{color:#F1403C;}.css-yvdm7v .highlight .kc{font-weight:600;}.css-yvdm7v .highlight .kd{font-weight:600;}.css-yvdm7v .highlight .kn{font-weight:600;}.css-yvdm7v .highlight .kp{font-weight:600;}.css-yvdm7v .highlight .kr{font-weight:600;}.css-yvdm7v .highlight .kt{font-weight:600;color:#175199;}.css-yvdm7v .highlight .m{color:#056DE8;}.css-yvdm7v .highlight .s{color:#F1403C;}.css-yvdm7v .highlight .na{color:#056DE8;}.css-yvdm7v .highlight .nb{color:#056DE8;}.css-yvdm7v .highlight .nc{font-weight:600;color:#175199;}.css-yvdm7v .highlight .no{color:#056DE8;}.css-yvdm7v .highlight .ni{color:#5555DD;}.css-yvdm7v .highlight .ne{font-weight:600;color:#F1403C;}.css-yvdm7v .highlight .nf{font-weight:600;color:#F1403C;}.css-yvdm7v .highlight .nn{color:#646464;}.css-yvdm7v .highlight .nt{color:#175199;}.css-yvdm7v .highlight .nv{color:#056DE8;}.css-yvdm7v .highlight .ow{font-weight:600;}.css-yvdm7v .highlight .w{color:#BFBFBF;}.css-yvdm7v .highlight .mf{color:#056DE8;}.css-yvdm7v .highlight .mh{color:#056DE8;}.css-yvdm7v .highlight .mi{color:#056DE8;}.css-yvdm7v .highlight .mo{color:#056DE8;}.css-yvdm7v .highlight .sb{color:#F1403C;}.css-yvdm7v .highlight .sc{color:#F1403C;}.css-yvdm7v .highlight .sd{color:#F1403C;}.css-yvdm7v .highlight .s2{color:#F1403C;}.css-yvdm7v .highlight .se{color:#F1403C;}.css-yvdm7v .highlight .sh{color:#F1403C;}.css-yvdm7v .highlight .si{color:#F1403C;}.css-yvdm7v .highlight .sx{color:#F1403C;}.css-yvdm7v .highlight .sr{color:#A5542F;}.css-yvdm7v .highlight .s1{color:#F1403C;}.css-yvdm7v .highlight .ss{color:#F1403C;}.css-yvdm7v .highlight .bp{color:#999999;}.css-yvdm7v .highlight .vc{color:#056DE8;}.css-yvdm7v .highlight .vg{color:#056DE8;}.css-yvdm7v .highlight .vi{color:#056DE8;}.css-yvdm7v .highlight .il{color:#056DE8;}.css-yvdm7v .highlight::-webkit-scrollbar{width:6px;height:6px;}.css-yvdm7v .highlight::-webkit-scrollbar-thumb:horizontal{background-color:rgba(18,18,18,0.5);border-radius:6px;}.css-yvdm7v .highlight::-webkit-scrollbar-thumb:horizontal:hover{background-color:rgba(18,18,18,0.6);}.css-yvdm7v .LinkCard.old{position:relative;display:block;margin:1em auto;width:390px;box-sizing:border-box;border-radius:12px;max-width:100%;overflow:hidden;}.css-yvdm7v .LinkCard.old,.css-yvdm7v .LinkCard.old:hover{-webkit-text-decoration:none;text-decoration:none;border:none !important;color:inherit !important;}.css-yvdm7v .LinkCard-ecommerceLoadingCard{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;padding:12px;border-radius:inherit;height:80px;box-sizing:border-box;background:rgba(246,246,246,0.88);color:#D3D3D3;}.css-yvdm7v .LinkCard-ecommerceLoadingCardAvatarWrapper{width:60px;height:60px;background:#EBEBEB;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;border-radius:6px;margin-right:10px;}.css-yvdm7v .LinkCard-ecommerceLoadingCardNetwork{width:20px;height:20px;}.css-yvdm7v .LinkCard-ecommerceLoadingCardLoadingbar{height:60px;-webkit-flex:1;-ms-flex:1;flex:1;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;}.css-yvdm7v .LinkCard-ecommerceLoadingCardLoadingbar span{height:16px;display:inline-block;background:#EBEBEB;}.css-yvdm7v .LinkCard-ecommerceLoadingCardLoadingbar span:nth-of-type(1){width:60px;margin-bottom:4px;}.css-yvdm7v .LinkCard-ecommerceLoadingCardLoadingbar span:nth-of-type(2){width:127px;}.css-yvdm7v .LinkCard.new{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;box-sizing:border-box;-webkit-flex-direction:row;-ms-flex-direction:row;flex-direction:row;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;width:390px;min-height:84px;border-radius:8px;max-width:100%;overflow:hidden;margin:16px auto;padding:12px 12px 9px 12px;background-color:#F6F6F6;}.css-yvdm7v .LinkCard.new,.css-yvdm7v .LinkCard.new:hover{-webkit-text-decoration:none;text-decoration:none;border:none !important;color:inherit !important;}.css-yvdm7v .LinkCard.new .LinkCard-contents{display:block;-webkit-flex:1 1 auto;-ms-flex:1 1 auto;flex:1 1 auto;position:relative;}.css-yvdm7v .LinkCard.new .LinkCard-contents .loading{height:14px;background:#EBEBEB;border-radius:7px;}.css-yvdm7v .LinkCard.new .LinkCard-contents.withTitle{margin-bottom:3px;}.css-yvdm7v .LinkCard.new .LinkCard-title{display:-webkit-box;font-size:15px;font-weight:500;line-height:1.4;margin-bottom:2px;color:#121212;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-yvdm7v .LinkCard.new .LinkCard-title.two-line{line-height:20px;display:-webkit-box;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:2;}.css-yvdm7v .LinkCard.new .LinkCard-title.loading{margin-bottom:8px;width:80%;}.css-yvdm7v .LinkCard.new .LinkCard-title.loading.withTitle{margin-bottom:6px;}.css-yvdm7v .LinkCard.new .LinkCard-title.loadingTitle{margin-bottom:5px;}.css-yvdm7v .LinkCard.new .LinkCard-excerpt{display:-webkit-box;text-overflow:ellipsis;font-size:13px;line-height:18px;color:#999999;margin-bottom:4px;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-yvdm7v .LinkCard.new .LinkCard-excerpt .LinkCard-author{color:#444444;}.css-yvdm7v .LinkCard.new .LinkCard-desc{display:-webkit-box;font-size:13px;height:18px;line-height:18px;color:#999999;word-break:break-all;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:1;}.css-yvdm7v .LinkCard.new .LinkCard-desc .LinkCard-tag,.css-yvdm7v .LinkCard.new .LinkCard-desc .tag{display:inline-block;font-size:11px;margin-left:8px;padding:0 4px;border-radius:3px;background:rgba(211,211,211,0.3);}.css-yvdm7v .LinkCard.new .LinkCard-desc.loading{width:40%;}.css-yvdm7v .LinkCard.new .LinkCard-desc svg{margin-right:2px;}.css-yvdm7v .LinkCard.new .LinkCard-image{-webkit-flex:0 0 auto;-ms-flex:0 0 auto;flex:0 0 auto;background-color:#EBEBEB;background-size:cover;background-position:center;position:relative;display:block;width:60px;height:60px;margin-left:20px;object-fit:cover;border-radius:inherit;overflow:hidden;}.css-yvdm7v .LinkCard.new .LinkCard-image.LinkCard-image--default{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;background-color:#EBEBEB;color:#D3D3D3;}.css-yvdm7v .LinkCard.new .LinkCard-image.LinkCard-image--default svg{color:#999999;}.css-yvdm7v .LinkCard.new .LinkCard-image img{width:100%;height:100%;object-fit:cover;}.css-yvdm7v .LinkCard.new .LinkCard-image .LinkCard-image--video{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;position:absolute;top:50%;left:50%;-webkit-transform:translateX(-50%) translateY(-50%);-ms-transform:translateX(-50%) translateY(-50%);transform:translateX(-50%) translateY(-50%);width:24px;height:24px;border-radius:12px;background:rgba(255,255,255,0.9);pointer-events:none;}.css-yvdm7v .LinkCard.new .LinkCard-image .LinkCard-image--video svg{color:#444444;}.css-yvdm7v .LinkCard.new .LinkCard-richText .text{color:#444444;}.css-yvdm7v .LinkCard.new .LinkCard-richText .bold{font-weight:600;}.css-yvdm7v .LinkCard.new .LinkCard-richText .tag{margin-left:4px;}.css-yvdm7v .FileLinkCard{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;background-color:rgba(246,246,246,0.88);border-radius:12px;box-sizing:border-box;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;margin:1em auto;max-width:100%;overflow:hidden;padding:12px;position:relative;width:390px;}.css-yvdm7v .FileLinkCard-icon{-webkit-flex-shrink:0;-ms-flex-negative:0;flex-shrink:0;height:30px;width:30px;}.css-yvdm7v .FileLinkCard-info{margin-left:12px;}.css-yvdm7v .FileLinkCard-name{color:#121212;font-size:15px;font-weight:500;line-height:21px;display:-webkit-box;text-overflow:ellipsis;overflow:hidden;-webkit-box-orient:vertical;-webkit-line-clamp:2;}.css-yvdm7v .FileLinkCard-meta{color:#999999;font-size:12px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;line-height:14px;margin-top:5px;}.css-yvdm7v .FileLinkCard-source{white-space:pre;}@-webkit-keyframes animation-1sh55c5{from{opacity:0;}to{opacity:1;}}@keyframes animation-1sh55c5{from{opacity:0;}to{opacity:1;}}</style><style data-emotion-css="u1frr4">.css-u1frr4{width:724px;}.css-u1frr4 .Modal-content{margin:22px 0 5px;}.css-u1frr4 .Creator-QuestionShared-title{padding-right:65px;}</style><script charset="utf-8" src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/column.zswsdid.8a757e7f9aca174311cb.js.download" crossorigin="anonymous"></script><script charset="utf-8" src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/column.shared_da7c8ae9ba4d3befc7c2f1c0b3e151cc8ee375ec.af12ecf8f2d548afdf54.js.download" crossorigin="anonymous"></script><link rel="stylesheet" type="text/css" href="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/column.user-hover-card.216a26f4.2325354b564ca3c742a9.css" crossorigin="anonymous"><script charset="utf-8" src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/column.user-hover-card.71fc423e9dc0dd03156b.js.download" crossorigin="anonymous"></script><link rel="stylesheet" type="text/css" href="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/column.Labels.216a26f4.7d19d2afdc588e36471f.css" crossorigin="anonymous"><script charset="utf-8" src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/column.Labels.a730f78c61b869939ce0.js.download" crossorigin="anonymous"></script><link rel="stylesheet" type="text/css" href="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/column.GoodsRecommendGoodsCardList.216a26f4.fa4bea774ed719d42a42.css" crossorigin="anonymous"><script charset="utf-8" src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/column.GoodsRecommendGoodsCardList.ab2afb8cb93040927be1.js.download" crossorigin="anonymous"></script><link rel="stylesheet" type="text/css" href="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/column.modals.216a26f4.4cc94e5a02bc6d62ae13.css" crossorigin="anonymous"><script charset="utf-8" src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/column.modals.a1ce0d73eb75e5779eea.js.download" crossorigin="anonymous"></script><script charset="utf-8" src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/column.report_modals.bed2ca0468847d780826.js.download" crossorigin="anonymous"></script><script charset="utf-8" src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/column.lib_cf230269.1f03be8440230089d5eb.js.download" crossorigin="anonymous"></script><script charset="utf-8" src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/column.comments-v3.94b98e3ddfcd5d8fbe3c.js.download" crossorigin="anonymous"></script><style data-emotion="css"></style><script charset="utf-8" src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/column.81.e7fba72373a0d6bae521.js.download" crossorigin="anonymous"></script><script charset="utf-8" src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/column.lib_9974496f.5b97ef76824871658209.js.download" crossorigin="anonymous"></script><script charset="utf-8" src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/column.shared_03103dc5b8182a3433c5ef33bacb88093fd08a38.06cbe3c48b6f221e0ffd.js.download" crossorigin="anonymous"></script><script charset="utf-8" src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/column.shared_889419e066c38251e2dcbb9a7c42dbfc379cadeb.d310b40a3fff5126c470.js.download" crossorigin="anonymous"></script><link rel="stylesheet" type="text/css" href="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/column.EditableV2.216a26f4.56bfcd6fcf02391f767f.css" crossorigin="anonymous"><script charset="utf-8" src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/column.EditableV2.9f0e35d0c4103cc5b4ea.js.download" crossorigin="anonymous"></script></head><body class="WhiteBg-body PostIndex-body" data-rh="class" style=""><div id="root"><div class="App"><div class="LoadingBar"></div><div><span style="position:absolute;top:-10000px;left:-10000px" role="log" aria-live="assertive"></span></div><main role="main" class="App-main"><div class="Post-content" data-zop-usertoken="{&quot;userToken&quot;:&quot;ao-ta-kang-007&quot;}" data-zop="{&quot;authorName&quot;:&quot;函谷叨客&quot;,&quot;itemId&quot;:430101220,&quot;title&quot;:&quot;【研究综述】浅谈GPU通信和PCIe P2P DMA&quot;,&quot;type&quot;:&quot;article&quot;}" data-za-detail-view-path-module="PostItem" data-za-extra-module="{&quot;card&quot;:{&quot;content&quot;:{&quot;type&quot;:&quot;Post&quot;,&quot;token&quot;:&quot;430101220&quot;}}}"><div class="ColumnPageHeader-Wrapper"><div><div class="Sticky ColumnPageHeader is-fixed css-1l12z7y" style="width: 1581.33px; top: 0px; left: 0px;"><div class="ColumnPageHeader-content"><a href="https://www.zhihu.com/" aria-label="知乎"><svg viewBox="0 0 64 30" fill="#056DE8" width="64" height="30" class="css-1hlrcxk"><path d="M29.05 4.582H16.733V25.94h3.018l.403 2.572 4.081-2.572h4.815V4.582zm-5.207 18.69l-2.396 1.509-.235-1.508h-1.724V7.233h6.78v16.04h-2.425zM14.46 14.191H9.982c0-.471.033-.954.039-1.458v-5.5h5.106V5.935a1.352 1.352 0 0 0-.404-.957 1.378 1.378 0 0 0-.968-.396H5.783c.028-.088.056-.177.084-.255.274-.82 1.153-3.326 1.153-3.326a4.262 4.262 0 0 0-2.413.698c-.57.4-.912.682-1.371 1.946-.532 1.453-.997 2.856-1.31 3.693C1.444 8.674.28 11.025.28 11.025a5.85 5.85 0 0 0 2.52-.61c1.119-.593 1.679-1.502 2.054-2.883l.09-.3h2.334v5.5c0 .5-.045.982-.073 1.46h-4.12c-.71 0-1.39.278-1.893.775a2.638 2.638 0 0 0-.783 1.874h6.527a17.717 17.717 0 0 1-.778 3.649 16.796 16.796 0 0 1-3.012 5.273A33.104 33.104 0 0 1 0 28.74s3.13 1.175 5.425-.954c1.388-1.292 2.631-3.814 3.23-5.727a28.09 28.09 0 0 0 1.12-5.229h5.967v-1.37a1.254 1.254 0 0 0-.373-.899 1.279 1.279 0 0 0-.909-.37z"></path><path d="M11.27 19.675l-2.312 1.491 5.038 7.458a6.905 6.905 0 0 0 .672-2.218 3.15 3.15 0 0 0-.28-2.168l-3.118-4.563zM51.449 15.195V5.842c4.181-.205 7.988-.405 9.438-.483l.851-.05c.387-.399.885-2.395.689-3.021-.073-.25-.213-.666-.638-.555a33.279 33.279 0 0 1-4.277.727c-2.766.321-3.97.404-7.804.682-6.718.487-12.709.72-12.709.72a2.518 2.518 0 0 0 .788 1.834 2.567 2.567 0 0 0 1.883.706c2.278-.095 5.598-.25 8.996-.41v9.203h-12.78c0 .703.281 1.377.783 1.874a2.69 2.69 0 0 0 1.892.777h10.105v7.075c0 .887-.464 1.192-1.231 1.214h-3.92a4.15 4.15 0 0 0 .837 1.544 4.2 4.2 0 0 0 1.403 1.067 6.215 6.215 0 0 0 2.71.277c1.36-.066 2.967-.826 2.967-3.57v-7.607h11.28c.342 0 .67-.135.91-.374.242-.239.378-.563.378-.902v-1.375H51.449z"></path><path d="M42.614 8.873a2.304 2.304 0 0 0-1.508-.926 2.334 2.334 0 0 0-1.727.405l-.376.272 4.255 5.85 2.24-1.62-2.884-3.98zM57.35 8.68l-3.125 4.097 2.24 1.663 4.517-5.927-.375-.277a2.32 2.32 0 0 0-1.722-.452 2.327 2.327 0 0 0-1.536.896z"></path></svg></a><i class="ColumnPageHeader-Line"></i><div class="ColumnPageHeader-Title"><div class="ColumnPageHeader-TitleName"><span class="ColumnPageHeader-TitleMeta">首发于</span><a class="ColumnLink ColumnPageHeader-TitleColumn" href="https://www.zhihu.com/column/c_1440266400069345280">高性能互连网络</a></div></div><div class="ColumnPageHeader-Button"><div class="Popover"><button title="更多" id="Popover1-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover1-content" type="button" class="Button ColumnPageHeader-MenuToggler Button--plain"><svg width="24" height="24" viewBox="0 0 24 24" data-new-api="Dots24" data-old-api="Dots" class="Zi Zi--Dots" fill="currentColor"><path d="M5.34 12a1.665 1.665 0 11-3.33 0 1.665 1.665 0 013.33 0zm8.325 0a1.665 1.665 0 11-3.33 0 1.665 1.665 0 013.33 0zm8.325 0a1.665 1.665 0 11-3.33 0 1.665 1.665 0 013.33 0z"></path></svg></button></div><button type="button" class="Button ColumnPageHeader-WriteButton Button--blue"><svg width="24" height="24" viewBox="0 0 24 24" data-new-api="PencilPaper24" data-old-api="EditSurround" class="Zi Zi--EditSurround" fill="currentColor"><path d="M3.55 5.97a2.415 2.415 0 012.415-2.416h7.56a.75.75 0 010 1.5h-7.56a.915.915 0 00-.915.915v12.072c0 .505.41.915.915.915h12.074c.506 0 .915-.41.915-.915v-7.557a.75.75 0 011.5 0v7.557a2.415 2.415 0 01-2.415 2.415H5.965A2.415 2.415 0 013.55 18.04V5.969z" fill-rule="evenodd" clip-rule="evenodd"></path><path d="M20.239 3.77a.75.75 0 010 1.06l-8.206 8.206a.75.75 0 01-1.06-1.06l8.205-8.206a.75.75 0 011.06 0z" fill-rule="evenodd" clip-rule="evenodd"></path></svg>写文章</button></div></div><div class="ColumnPageHeader-profile"><div class="Popover AppHeader-menu"><button id="Popover11-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover11-content" type="button" class="Button AppHeader-profileEntry Button--plain"><img class="Avatar AppHeader-profileAvatar" width="30" height="30" src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-ef69d369588e9764f9252225e6dc29ce_is.jpg" srcset="https://pica.zhimg.com/v2-ef69d369588e9764f9252225e6dc29ce_im.jpg?source=32738c0c 2x" alt="点击打开奥塔康007的主页"></button></div><div class="Popover AppHeaderProfileMenu-creatorHintPopover"><div class="AppHeaderProfileMenu-creatorHintToggler" id="Popover12-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover12-content"></div></div></div></div><div class="Sticky--holder" style="position: relative; inset: 0px; display: block; float: none; margin: 0px; height: 52px;"></div></div></div><img class="TitleImage" src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-89ea4d6acbeca045b1983fd8c082e497_1440w.jpg" alt="【研究综述】浅谈GPU通信和PCIe P2P DMA"><article class="Post-Main Post-NormalMain" tabindex="-1"><header class="Post-Header"><h1 class="Post-Title">【研究综述】浅谈GPU通信和PCIe P2P DMA</h1><div class="Post-Author"><div class="AuthorInfo" itemprop="author" itemscope="" itemtype="http://schema.org/Person"><div class="AuthorInfo"><meta itemprop="name" content="函谷叨客"><meta itemprop="image" content="https://pica.zhimg.com/v2-8966d1ab2d8ee8980d116f4d746ce456_l.jpg?source=172ae18b"><meta itemprop="url" content="https://www.zhihu.com/people/han-gu-tao-ke"><meta itemprop="zhihu:followerCount"><span class="UserLink AuthorInfo-avatarWrapper"><div class="Popover"><div id="Popover14-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover14-content"><a href="https://www.zhihu.com/people/han-gu-tao-ke" target="_blank" class="UserLink-link" data-za-detail-view-element_name="User"><img class="Avatar Avatar--round AuthorInfo-avatar" width="38" height="38" src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-8966d1ab2d8ee8980d116f4d746ce456_xs.jpg" srcset="https://pica.zhimg.com/v2-8966d1ab2d8ee8980d116f4d746ce456_l.jpg?source=172ae18b 2x" alt="函谷叨客"></a></div></div></span><div class="AuthorInfo-content"><div class="AuthorInfo-head"><span class="UserLink AuthorInfo-name"><div class="Popover"><div id="Popover15-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover15-content"><a href="https://www.zhihu.com/people/han-gu-tao-ke" target="_blank" class="UserLink-link" data-za-detail-view-element_name="User">函谷叨客</a></div></div></span></div><div class="AuthorInfo-detail"><div class="AuthorInfo-badge"><div class="ztext AuthorInfo-badgeText">从事高性能互连网络研究</div></div></div></div></div></div><button type="button" class="Button FollowButton Button--primary Button--blue"><span style="display:inline-flex;align-items:center">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" data-new-api="PlusFill24" data-old-api="Plus" class="Zi Zi--Plus FollowButton-icon" fill="currentColor"><path d="M13.25 3.25a1.25 1.25 0 10-2.5 0v7.5h-7.5a1.25 1.25 0 100 2.5h7.5v7.5a1.25 1.25 0 102.5 0v-7.5h7.5a1.25 1.25 0 000-2.5h-7.5v-7.5z" fill-rule="evenodd" clip-rule="evenodd"></path></svg></span>关注他</button></div><div class="LabelContainer-wrapper"></div><div role="button" tabindex="0"><span class="Voters"><button type="button" class="Button Button--plain">269 人<!-- -->赞同了该文章</button></span></div></header><div class="Post-RichTextContainer"><div class="css-1yuhvjn"><div class="RichText ztext Post-RichText css-yvdm7v" options="[object Object]"><p data-first-child="" data-pid="cCwojx_b">目前网络通信已经成为分布式机器学习的性能瓶颈。本文将讨论GPU通信和PCIe P2P DMA技术，为大规模分布式应用通信性能的优化提供参考。本文将依次回答如下三个问题，并探讨今后IO设备互连该走向什么方向。</p><p class="ztext-empty-paragraph"><br></p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-589c2e8cc43934697166b6edc599b82d_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic2.zhimg.com/v2-589c2e8cc43934697166b6edc599b82d_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-589c2e8cc43934697166b6edc599b82d_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic2.zhimg.com/v2-589c2e8cc43934697166b6edc599b82d_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-589c2e8cc43934697166b6edc599b82d_b.jpg" data-lazy-status="ok"></figure><p data-pid="ZVV_xR1G">为了回答上述问题，本文将分为四个部分展开。首先，简要介绍GPU的基本架构和GPU内存管理技术的演进与发展；重点讨论GPUDirect技术的演进，技术细节和其性能评测；之后，更一般地，我们在第三部分讨论不同GPU互连架构下，通信性能的特征和差异；最后，我们对现有设备通信进行扩展，讨论通用P2P技术的演进。</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-36dd894509c45bf41fae7b37de6667c6_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic3.zhimg.com/v2-36dd894509c45bf41fae7b37de6667c6_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-36dd894509c45bf41fae7b37de6667c6_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic3.zhimg.com/v2-36dd894509c45bf41fae7b37de6667c6_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-36dd894509c45bf41fae7b37de6667c6_b.jpg" data-lazy-status="ok"></figure><p data-pid="hO7qE6lQ">首先是第一部分内容，我将简要介绍GPU内存管理方式的演进。这部分内容主要参考了[1-6]。</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-8793cdc626e9547ecea374e95786185e_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic3.zhimg.com/v2-8793cdc626e9547ecea374e95786185e_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-8793cdc626e9547ecea374e95786185e_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic3.zhimg.com/v2-8793cdc626e9547ecea374e95786185e_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-8793cdc626e9547ecea374e95786185e_b.jpg" data-lazy-status="ok"></figure><p data-pid="GpUY75l8">这张图是开普勒GPU架构图。其中，HSHUB（High Speed HUB）完成GPU与CPU之间的数据交换，所有的存储器件接入一个交叉开关。计算核心被划分为不同的SM（Stream Multi-Processor）。每个SM包含数十至数百个计算核心，共享SM中的存储资源。其中，共享内存部分被用作scratchpad，这部分存储资源需要用户进行显式管理，RO Cache用于存放一些常量数据。与CPU不同的地方在于，L1 Cache和L2 Cache之间不维护一致性。</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-e98f24bee6a58d50cbec7f7207859b79_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic2.zhimg.com/v2-e98f24bee6a58d50cbec7f7207859b79_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-e98f24bee6a58d50cbec7f7207859b79_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic2.zhimg.com/v2-e98f24bee6a58d50cbec7f7207859b79_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-e98f24bee6a58d50cbec7f7207859b79_b.jpg" data-lazy-status="ok"></figure><p data-pid="qXTSpfD6">从用户编程角度而言，在使用存储资源时看到的就是CPU指针和GPU指针。对GPU内存的使用经历了三个阶段，第一个阶段是分离内存管理，GPU上运行的Kernel代码不能直接访问CPU内存，在载入Kernel之前或Kernel执行结束之后必须进行显式的拷贝操作；第二个阶段是半分离内存管理，Kernel代码能够直接用指针寻址到整个系统中的内存资源；第三个阶段是分离内存管理，CPU还是GPU上的代码都可以使用指针直接访问到系统中的任意内存资源。对于用户而言，第三个阶段看起来只是提供了一个语法糖，但在底层硬件实现上两者有着显著的差异。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-24b88a78a9e8ce22757edbe1db286e78_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic1.zhimg.com/v2-24b88a78a9e8ce22757edbe1db286e78_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-24b88a78a9e8ce22757edbe1db286e78_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic1.zhimg.com/v2-24b88a78a9e8ce22757edbe1db286e78_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-24b88a78a9e8ce22757edbe1db286e78_b.jpg" data-lazy-status="ok"></figure><p data-pid="rjUMOlHo">接下来我将分别详细介绍三种不同内存管理方式的区别以及部分实现细节。</p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-ddbbc1b0223a88d4fa08ed67f4b74803_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic4.zhimg.com/v2-ddbbc1b0223a88d4fa08ed67f4b74803_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-ddbbc1b0223a88d4fa08ed67f4b74803_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic4.zhimg.com/v2-ddbbc1b0223a88d4fa08ed67f4b74803_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-ddbbc1b0223a88d4fa08ed67f4b74803_b.jpg" data-lazy-status="ok"></figure><p data-pid="tg5-3pKG">对于分离内存管理，其又可以分为两种，即锁页内存和零拷贝内存。在最原始的方式下，从主机内存拷贝数据到GPU，首先操作系统会分配一块用于数据中转的临时锁页内存，然后将用户缓冲区中的数据拷贝到锁页内存中，再通过PCIe DMA拷贝到GPU显存中。</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-e4b7c3482e384deaa755c8242fe4d9b9_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic2.zhimg.com/v2-e4b7c3482e384deaa755c8242fe4d9b9_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-e4b7c3482e384deaa755c8242fe4d9b9_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic2.zhimg.com/v2-e4b7c3482e384deaa755c8242fe4d9b9_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-e4b7c3482e384deaa755c8242fe4d9b9_b.jpg" data-lazy-status="ok"></figure><p data-pid="gewyy_0J">而对于锁页内存，首先分配内存的API发生了变化，而且分配的区域将直接成为锁页内存区域，在向GPU显存进行拷贝时只需要进行一次PCIe DMA操作即可。</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-a585bf939aa55a4190abef7eeaacc08a_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic3.zhimg.com/v2-a585bf939aa55a4190abef7eeaacc08a_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-a585bf939aa55a4190abef7eeaacc08a_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic3.zhimg.com/v2-a585bf939aa55a4190abef7eeaacc08a_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-a585bf939aa55a4190abef7eeaacc08a_b.jpg" data-lazy-status="ok"></figure><p data-pid="3a-5FrIh">进一步的，刚才看到GPU要使用CPU的数据是需要通过CudaMemcpy进行显式拷贝操作的，这种方式适合大批量的数据传递。如果只是想更新某个标志位，可以使用零拷贝内存。所谓零拷贝，就是GPU寄存器堆直接与主机内存交互。从代码里可以看到，将主机内存指针进行映射后，Kernel就可以直接使用指针来访问主机内存了，读取的数据会直接写入寄存器中。</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-a0b4218635498b8ddeebe87da3c252e1_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic2.zhimg.com/v2-a0b4218635498b8ddeebe87da3c252e1_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-a0b4218635498b8ddeebe87da3c252e1_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic2.zhimg.com/v2-a0b4218635498b8ddeebe87da3c252e1_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-a0b4218635498b8ddeebe87da3c252e1_b.jpg" data-lazy-status="ok"></figure><p data-pid="mt1WBDiq">在分离内存管理的基础上，Nvidia推出了半分分离内存管理，也就是统一虚拟地址空间。</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-4861e9ef304168561d100b2138505c0a_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic3.zhimg.com/v2-4861e9ef304168561d100b2138505c0a_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-4861e9ef304168561d100b2138505c0a_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic3.zhimg.com/v2-4861e9ef304168561d100b2138505c0a_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-4861e9ef304168561d100b2138505c0a_b.jpg" data-lazy-status="ok"></figure><p data-pid="JE3iy8pu">对于半分离内存管理，实际上也是语法糖，将原有的四个方向的拷贝函数合成了一个，用户调用统一的拷贝函数，由Cuda Runtime来判定数据源和目标所在的物理地址。</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-e8fd6a2599ed019fa6671358c7be28ea_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic3.zhimg.com/v2-e8fd6a2599ed019fa6671358c7be28ea_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-e8fd6a2599ed019fa6671358c7be28ea_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic3.zhimg.com/v2-e8fd6a2599ed019fa6671358c7be28ea_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-e8fd6a2599ed019fa6671358c7be28ea_b.jpg" data-lazy-status="ok"></figure><p data-pid="j1q1GLYQ">在UVA之后，Nvidia又创造性地提出了Unified Memory统一内存管理机制。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-fa48a328cec51cd0a86e03496a81ebe8_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic1.zhimg.com/v2-fa48a328cec51cd0a86e03496a81ebe8_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-fa48a328cec51cd0a86e03496a81ebe8_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic1.zhimg.com/v2-fa48a328cec51cd0a86e03496a81ebe8_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-fa48a328cec51cd0a86e03496a81ebe8_b.jpg" data-lazy-status="ok"></figure><p data-pid="DCCIKOH-">Unified Memory在Unified Virtual Address的基础上更进一步，将系统内的所有内存资源都整合到相同的虚拟地址空间中。不管是CPU还是GPU代码，不用再区分其指针指向的空间，这给用户编程提供了极大的便利性。</p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-2916c9b3c950d24383ad9c21226e16ff_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic4.zhimg.com/v2-2916c9b3c950d24383ad9c21226e16ff_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-2916c9b3c950d24383ad9c21226e16ff_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic4.zhimg.com/v2-2916c9b3c950d24383ad9c21226e16ff_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-2916c9b3c950d24383ad9c21226e16ff_b.jpg" data-lazy-status="ok"></figure><p data-pid="BcoyBtY0">我们看两个例子，代码功能是在CPU上分配一段数据，CPU进行运算，将结果拷贝到GPU上运算，GPU运算结束再拷贝到CPU中，CPU再继续运算。如果使用Unified Memory，在分配完数据后，不需要进行显式数据拷贝，直接调用相关函数对其进行处理即可，在GPU处理完后需要执行一次同步。</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-38c832c1b77f1014e21502e567214999_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic2.zhimg.com/v2-38c832c1b77f1014e21502e567214999_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-38c832c1b77f1014e21502e567214999_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic2.zhimg.com/v2-38c832c1b77f1014e21502e567214999_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-38c832c1b77f1014e21502e567214999_b.jpg" data-lazy-status="ok"></figure><p data-pid="G_6M4PNS">上面例子的优势还不明显，我们再看下一个例子。这是一个深拷贝操作，CPU分配一个二维数组，显式拷贝时，要对二维数组进行逐行拷贝。但使用Unified Memory，Kernel就可以直接对数据进行操作。到这里我们看到了UM作为语法糖发挥的一些作用，看起来与UVA好像区别不大，都是GPU虚拟地址直接访问主机内存空间。但对于UVA，GPU访问主存是直接将数据搬到寄存器里的，不经过其显存，这也就意味着每次访问都至少要经过一次PCIe操作。UM在底层硬件实现上机制完全不同。</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-83387ccd2d522f8e6a0929ca2b070f2a_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic3.zhimg.com/v2-83387ccd2d522f8e6a0929ca2b070f2a_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-83387ccd2d522f8e6a0929ca2b070f2a_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic3.zhimg.com/v2-83387ccd2d522f8e6a0929ca2b070f2a_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-83387ccd2d522f8e6a0929ca2b070f2a_b.jpg" data-lazy-status="ok"></figure><p data-pid="eAc9M0wt">实际上，直到Pascal架构才算真正有了对UM的硬件上的支持。在Pascal架构之前，Kepler和Maxwell仅仅还是沿用了前面讲的CPU数据搬移到GPU寄存器中，只是在CUDA Runtime中提供了对地址的判断。而在Pascal架构上，实现了对物理内存页的按需迁移，GPU和CPU的并发访问，内存超额配置等，以及在Volta架构上又进一步实现了访问计数器，GPU和CPU的Cache一致性等新特性。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-75718b57afa47b9155cb1e1b7f170d88_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic1.zhimg.com/v2-75718b57afa47b9155cb1e1b7f170d88_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-75718b57afa47b9155cb1e1b7f170d88_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic1.zhimg.com/v2-75718b57afa47b9155cb1e1b7f170d88_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-75718b57afa47b9155cb1e1b7f170d88_b.jpg" data-lazy-status="ok"></figure><p data-pid="imLxeAc4">我们首先来看在Pascal架构之前UM的硬件工作方式。这段代码首先分配GPU显存，这时GPU的MMU会分配一段物理内存，然后构造页表项。</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-14ba6af8c4ade02f50af4660a0b61f61_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic2.zhimg.com/v2-14ba6af8c4ade02f50af4660a0b61f61_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-14ba6af8c4ade02f50af4660a0b61f61_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic2.zhimg.com/v2-14ba6af8c4ade02f50af4660a0b61f61_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-14ba6af8c4ade02f50af4660a0b61f61_b.jpg" data-lazy-status="ok"></figure><p data-pid="DDQf9cSg">当CPU指针访问这段显存时，发生缺页异常，进行物理页迁移，将GPU的物理页迁移到CPU内存中，此时GPU的页表会进行释放。</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-66af9d18ba43452a91abbf103e72fef2_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic3.zhimg.com/v2-66af9d18ba43452a91abbf103e72fef2_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-66af9d18ba43452a91abbf103e72fef2_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic3.zhimg.com/v2-66af9d18ba43452a91abbf103e72fef2_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-66af9d18ba43452a91abbf103e72fef2_b.jpg" data-lazy-status="ok"></figure><p data-pid="a7rXO8p8">而当Kernel使用该地址时，会再次构造GPU页表项，将CPU内存页迁移到GPU上。</p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-e3af1d452635383cfde04ab41c286603_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic4.zhimg.com/v2-e3af1d452635383cfde04ab41c286603_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-e3af1d452635383cfde04ab41c286603_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic4.zhimg.com/v2-e3af1d452635383cfde04ab41c286603_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-e3af1d452635383cfde04ab41c286603_b.jpg" data-lazy-status="ok"></figure><p data-pid="KgWdfSBT">在这种方式下，UM不能支持内存超额配置，也就是申请的内存数量不能超过GPU显存总量。同时也不支持按需页迁移，例如当GPU显存已经塞满时，如果要访问CPU内存，数据会直接进入GPU寄存器，而不会对显存进行置换，如果频繁访问CPU内存就会带来较大的开销。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-6d7a56696bd7674e374982fb42b6f110_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic1.zhimg.com/v2-6d7a56696bd7674e374982fb42b6f110_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-6d7a56696bd7674e374982fb42b6f110_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic1.zhimg.com/v2-6d7a56696bd7674e374982fb42b6f110_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-6d7a56696bd7674e374982fb42b6f110_b.jpg" data-lazy-status="ok"></figure><p data-pid="59F8X0g1">在Pascal之后的架构对GPU缺页异常提供了支持，在分配GPU内存时，只是分配了一个页表项，没有进行实际的显存分配。</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-f0a6dfa3ed5125495af6a899ba6941b5_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic2.zhimg.com/v2-f0a6dfa3ed5125495af6a899ba6941b5_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-f0a6dfa3ed5125495af6a899ba6941b5_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic2.zhimg.com/v2-f0a6dfa3ed5125495af6a899ba6941b5_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-f0a6dfa3ed5125495af6a899ba6941b5_b.jpg" data-lazy-status="ok"></figure><p data-pid="HAlAq59d">当CPU代码访问内存时，发生缺页异常，分配CPU物理内存页，创建CPU页表项。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-9e91c0c5f25c106171d8b7fa777eb828_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic1.zhimg.com/v2-9e91c0c5f25c106171d8b7fa777eb828_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-9e91c0c5f25c106171d8b7fa777eb828_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic1.zhimg.com/v2-9e91c0c5f25c106171d8b7fa777eb828_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-9e91c0c5f25c106171d8b7fa777eb828_b.jpg" data-lazy-status="ok"></figure><p data-pid="e5OR3Frz">当GPU代码访问时，发生GPU缺页异常，CPU内存页通过PCIe被迁移到GPU显存中。</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-08d458e9bc08f345b500d72e22b4fa06_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic3.zhimg.com/v2-08d458e9bc08f345b500d72e22b4fa06_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-08d458e9bc08f345b500d72e22b4fa06_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic3.zhimg.com/v2-08d458e9bc08f345b500d72e22b4fa06_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-08d458e9bc08f345b500d72e22b4fa06_b.jpg" data-lazy-status="ok"></figure><p data-pid="Rj2OXwAW">接下来我们看Pascal架构是怎么支持内存超额配置和按需页迁移的。在当前状态下，对于GPU和CPU虚拟地址空间，Page 1到Page 4指向了GPU显存，Page 5指向了CPU内存。当GPU访问Page 5时，发现GPU页表为空，出现缺页异常。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-0388efda4af62df909dd22689c097840_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic1.zhimg.com/v2-0388efda4af62df909dd22689c097840_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-0388efda4af62df909dd22689c097840_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic1.zhimg.com/v2-0388efda4af62df909dd22689c097840_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-0388efda4af62df909dd22689c097840_b.jpg" data-lazy-status="ok"></figure><p data-pid="sOninmU7">此时，GPU的MMU会在显存中选择一个物理页面迁移到CPU主存中，这里是Page 4，然后在CPU页表中建立Page 4到物理页面的映射。</p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-48da64f02c0e01d5295880f4bbd37b57_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic4.zhimg.com/v2-48da64f02c0e01d5295880f4bbd37b57_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-48da64f02c0e01d5295880f4bbd37b57_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic4.zhimg.com/v2-48da64f02c0e01d5295880f4bbd37b57_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-48da64f02c0e01d5295880f4bbd37b57_b.jpg" data-lazy-status="ok"></figure><p data-pid="NXQxwGPN">同时，CPU主存中的Page 5被迁移到GPU显存中，建立Page 5到物理页面的映射。</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-4a4646df1874ce6badcb5df1a40e85ba_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic3.zhimg.com/v2-4a4646df1874ce6badcb5df1a40e85ba_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-4a4646df1874ce6badcb5df1a40e85ba_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic3.zhimg.com/v2-4a4646df1874ce6badcb5df1a40e85ba_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-4a4646df1874ce6badcb5df1a40e85ba_b.jpg" data-lazy-status="ok"></figure><p data-pid="limLhLn-">完成整个缺页异常的处理流程。</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-93fd4821eea953288bf050c0c893dc79_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic2.zhimg.com/v2-93fd4821eea953288bf050c0c893dc79_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-93fd4821eea953288bf050c0c893dc79_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic2.zhimg.com/v2-93fd4821eea953288bf050c0c893dc79_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-93fd4821eea953288bf050c0c893dc79_b.jpg" data-lazy-status="ok"></figure><p data-pid="FuOOX956">上述示例只是给出了基本的按需页迁移的过程。UM还涉及到很多相关问题，比如Cache一致性问题，CPU和GPU对同一个数据的多次并发读写，导致页面来回迁移的问题等，以及冷热页面的替换算法问题等。Power系列对UM特性的支持更完备，一个主要原因是其支持GPU和Power 9直接通过NVLink进行互连，后面在Summit和SummitDev的评测中我们可以看到这种架构。需要注意的是，UM本质上还是一种语法糖，这些特性的支持也只是为了尽可能提升语法糖的性能。由于这部分内容本身不是今天讨论的重点，所以点到为止。更详细的性能测评数据可以看相关参考文献。</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-aa63c420adbbd77e34ade8d943819126_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic3.zhimg.com/v2-aa63c420adbbd77e34ade8d943819126_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-aa63c420adbbd77e34ade8d943819126_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic3.zhimg.com/v2-aa63c420adbbd77e34ade8d943819126_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-aa63c420adbbd77e34ade8d943819126_b.jpg" data-lazy-status="ok"></figure><p data-pid="HaEx2N5G">接下来是本文讨论的重点内容，GPUDirect技术的介绍。首先我会介绍GPUDirect技术是如何演进的，然后我会重点讨论GPUDirect技术的实现细节，最后给出GPUDirect技术的详细评测结果。这部分内容主要参考了[7-9]。</p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-93515c2d0ac2f808636492d10e29a6af_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic4.zhimg.com/v2-93515c2d0ac2f808636492d10e29a6af_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-93515c2d0ac2f808636492d10e29a6af_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic4.zhimg.com/v2-93515c2d0ac2f808636492d10e29a6af_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-93515c2d0ac2f808636492d10e29a6af_b.jpg" data-lazy-status="ok"></figure><p data-pid="nfWQ6Cpw">在介绍GPUDirect技术之前，我们不妨回顾一下GPU通信的过程。通常可以将其粗略地划分为CPU控制的GPU通信和GPU控制的GPU通信。在第一种情况下，GPU运算完成后，将数据同步给CPU，由CPU执行MPI通信。按照算法设计，GPU可以等待CPU通信完成后继续执行运算，或者在通信过程中就开始继续运算。不管哪种方式，整个过程中，一定要由CPU进行通信的控制以及与计算过程的同步，这就必然引起PCIe的通信开销。</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-3b969d398d63df3ce133115c486279f2_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic3.zhimg.com/v2-3b969d398d63df3ce133115c486279f2_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-3b969d398d63df3ce133115c486279f2_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic3.zhimg.com/v2-3b969d398d63df3ce133115c486279f2_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-3b969d398d63df3ce133115c486279f2_b.jpg" data-lazy-status="ok"></figure><p data-pid="0HDZ9K48">而对于GPU控制的通信而言，整个执行流程中CPU都会旁路，GPU独立发起通信，并和网络设备进行同步。缺陷是要消耗部分GPU计算资源来完成通信，并且GPU控制通信的效率可能并不高，后面的实验结果也会证实这一点。</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-973df7f05681621c7f9ea711da944a21_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic2.zhimg.com/v2-973df7f05681621c7f9ea711da944a21_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-973df7f05681621c7f9ea711da944a21_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic2.zhimg.com/v2-973df7f05681621c7f9ea711da944a21_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-973df7f05681621c7f9ea711da944a21_b.jpg" data-lazy-status="ok"></figure><p data-pid="8xAtaW6e">回顾了GPU的两种基本通信模式后，我们进入到GPUDirect的发展历史中。首先在2009年出现了GPUDirect 1.0技术，在1.0之前。GPU和CPU无法共享通信缓冲区，通信数据需要在内存中进行一次拷贝后，再发向网卡。而1.0就是为了避免这种拷贝的，程序pin住一段内存后，既可以用作与GPU的数据交互， 又可以作为网卡的Memory Region使用。</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-9df1c4da72c9f1b96ef4e08c5c6f362e_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic3.zhimg.com/v2-9df1c4da72c9f1b96ef4e08c5c6f362e_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-9df1c4da72c9f1b96ef4e08c5c6f362e_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic3.zhimg.com/v2-9df1c4da72c9f1b96ef4e08c5c6f362e_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-9df1c4da72c9f1b96ef4e08c5c6f362e_b.jpg" data-lazy-status="ok"></figure><p data-pid="AihuXYVz">第二代GPUDirect技术被称作GPUDirect P2P，重点解决的是节点内GPU通信问题。两个GPU可以通过PCIe P2P直接进行数据搬移，避免了主机内存和CPU的参与。</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-5b57d0016d6b77d53a619fc02243bfa5_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic2.zhimg.com/v2-5b57d0016d6b77d53a619fc02243bfa5_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-5b57d0016d6b77d53a619fc02243bfa5_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic2.zhimg.com/v2-5b57d0016d6b77d53a619fc02243bfa5_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-5b57d0016d6b77d53a619fc02243bfa5_b.jpg" data-lazy-status="ok"></figure><p data-pid="vd0IPudX">而第三代GPUDirect技术就是我们所熟知的GPUDirect RDMA了，GPU和网卡可以直接通过PCIe进行数据交互，避免了跨节点通信过程中内存和CPU的参与。</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-f405f41723ca5b6edf56913d53cb36da_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic3.zhimg.com/v2-f405f41723ca5b6edf56913d53cb36da_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-f405f41723ca5b6edf56913d53cb36da_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic3.zhimg.com/v2-f405f41723ca5b6edf56913d53cb36da_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-f405f41723ca5b6edf56913d53cb36da_b.jpg" data-lazy-status="ok"></figure><p data-pid="TFBXDyLp">接下来我们将继续深入下去，探讨上述技术究竟如何落实。</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-ef2b137c65dec837d126b032f111d415_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic2.zhimg.com/v2-ef2b137c65dec837d126b032f111d415_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-ef2b137c65dec837d126b032f111d415_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic2.zhimg.com/v2-ef2b137c65dec837d126b032f111d415_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-ef2b137c65dec837d126b032f111d415_b.jpg" data-lazy-status="ok"></figure><p data-pid="bwqJh06W">在上述GPUDirect RDMA的示意图中，我们只看到了GPU和网卡进行数据搬移，但是还有很多问题其实都被忽略掉了。那么，如果我们将上述通信过程细化，至少有三个关键问题需要解决。首先，为了实现CPU控制通信，数据进行P2P搬移，我们要解决网卡直接读写GPU显存的问题；其次，为了实现GPU直接控制通信，还有两个问题要解决。其一，GPU如何访问通信资源？其二，GPU如何与网卡进行同步？</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-87822b0e166f209586f85c348a7ca269_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic2.zhimg.com/v2-87822b0e166f209586f85c348a7ca269_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-87822b0e166f209586f85c348a7ca269_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic2.zhimg.com/v2-87822b0e166f209586f85c348a7ca269_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-87822b0e166f209586f85c348a7ca269_b.jpg" data-lazy-status="ok"></figure><p data-pid="9S4D4osZ">接下来我们将逐次解决上述问题。</p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-7f2168e9e161e8298a55eac5ef6ae0db_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic4.zhimg.com/v2-7f2168e9e161e8298a55eac5ef6ae0db_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-7f2168e9e161e8298a55eac5ef6ae0db_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic4.zhimg.com/v2-7f2168e9e161e8298a55eac5ef6ae0db_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-7f2168e9e161e8298a55eac5ef6ae0db_b.jpg" data-lazy-status="ok"></figure><p data-pid="lCyLezK6">首先，对于网卡读写GPU显存，我们不妨先回顾一下网卡是如何访问CPU内存的。对于用户进程而言， 其将一个虚拟地址传递给网卡驱动，通过注册内存区域获取物理页表项，然后将页表填入网卡的MTT表中。在这个过程中，内存中建立了页表项，同时，pin memory的操作对每个物理内存页的元数据进行了修改，对于网卡而言，其动作是进行虚拟地址到物理地址的转换，然后发起PCIe请求，至于物理地址映射到主机内存还是设备内存它并不关心。因此，如果我们能够解决向网卡注册GPU虚拟地址的问题，就等价于解决了网卡读写GPU显存的问题。</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-9b9b768791247bba4ab67a111d58a015_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic2.zhimg.com/v2-9b9b768791247bba4ab67a111d58a015_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-9b9b768791247bba4ab67a111d58a015_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic2.zhimg.com/v2-9b9b768791247bba4ab67a111d58a015_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-9b9b768791247bba4ab67a111d58a015_b.jpg" data-lazy-status="ok"></figure><p data-pid="HSk0x-a5">但是，当我们直接使用一个GPU虚拟地址进行内存注册时，会得到一个Segmetation Fault的错误。因为reg_mr注册时会陷入内核，通过调用get_user_pages获取物理页表，但对于GPU虚拟地址，CPU并不存在其对应的页表项，自然会出现错误。为了实现GPU内存的注册，需要对驱动进行一定的修改。</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-6e89ef0f8e4c3269a3ceff1455b623e5_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic2.zhimg.com/v2-6e89ef0f8e4c3269a3ceff1455b623e5_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-6e89ef0f8e4c3269a3ceff1455b623e5_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic2.zhimg.com/v2-6e89ef0f8e4c3269a3ceff1455b623e5_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-6e89ef0f8e4c3269a3ceff1455b623e5_b.jpg" data-lazy-status="ok"></figure><p data-pid="aFnYsJU8">为了实现网卡对其它设备内存的注册，MLNX提供了一套标准的注册框架。所有的设备驱动需要向MLNX的设备管理模块进行注册，提供类似于操作系统get_ser_pages的回调函数，当网卡驱动需要对一个地址进行注册时，会对地址进行判断，然后调用相应的函数获得设备指针，最终调用设备驱动中的物理页获取函数，得到设备内存的物理地址。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-b099df93fe6585370cfde364cf841b78_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic1.zhimg.com/v2-b099df93fe6585370cfde364cf841b78_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-b099df93fe6585370cfde364cf841b78_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic1.zhimg.com/v2-b099df93fe6585370cfde364cf841b78_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-b099df93fe6585370cfde364cf841b78_b.jpg" data-lazy-status="ok"></figure><p data-pid="ZXEUec6U">这张图是Nvidia提供的注册函数与MLNX驱动框架之间的对接，具体细节就不再详细阐述了。</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-d3759661398e3b050a1ac54047c3aeb5_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic2.zhimg.com/v2-d3759661398e3b050a1ac54047c3aeb5_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-d3759661398e3b050a1ac54047c3aeb5_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic2.zhimg.com/v2-d3759661398e3b050a1ac54047c3aeb5_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-d3759661398e3b050a1ac54047c3aeb5_b.jpg" data-lazy-status="ok"></figure><p data-pid="FIkR_tws">在新的注册框架下，通过内存注册，GPU内存在BAR空间的地址被下发到网卡，当网卡使用这些地址读写GPU显存时，GPU内部的HSHUB再进行一次地址映射，将BAR空间地址映射为实际的显存页面。这里有一个隐含的Trick，GPU的虚拟地址到物理地址也是分页寻址的。</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-71f4396ac670619c6f2a0534d9c9f57a_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic3.zhimg.com/v2-71f4396ac670619c6f2a0534d9c9f57a_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-71f4396ac670619c6f2a0534d9c9f57a_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic3.zhimg.com/v2-71f4396ac670619c6f2a0534d9c9f57a_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-71f4396ac670619c6f2a0534d9c9f57a_b.jpg" data-lazy-status="ok"></figure><p data-pid="tbuWOuOX">至此，网卡能够直接读写GPU显存了，这也就意味着我们已经实现了CPU控制的GPU通信，同时数据通过PCIe P2P进行传输。接下来我们重点考虑GPU直接控制的通信方式。</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-41da4e95f387b9979972542717f35c51_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic2.zhimg.com/v2-41da4e95f387b9979972542717f35c51_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-41da4e95f387b9979972542717f35c51_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic2.zhimg.com/v2-41da4e95f387b9979972542717f35c51_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-41da4e95f387b9979972542717f35c51_b.jpg" data-lazy-status="ok"></figure><p data-pid="HD_uGyfg">GPU控制通信其实就是GPU对通信资源进行相应的操作。为了解决这个问题，我们首先从一个比较宏观的角度来看CPU进行RDMA通信时包含哪些操作。从图中的分类可以看到，CPU在通信过程中，除了提交工作请求和同步，其它所有工作都在进行通信资源的创建和设置，而且都需要和内核进行交互。首先，GPU没有必要管理这些资源创建过程，其次，GPU上的代码也没有办法直接跟主机操作系统进行交互。因此，唯一能够且有必要由GPU控制的流程就是提交工作请求和同步过程。接下来我们重点考虑这一过程的实现。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-c260f4cc5abc7482ea5064027587adc0_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic1.zhimg.com/v2-c260f4cc5abc7482ea5064027587adc0_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-c260f4cc5abc7482ea5064027587adc0_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic1.zhimg.com/v2-c260f4cc5abc7482ea5064027587adc0_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-c260f4cc5abc7482ea5064027587adc0_b.jpg" data-lazy-status="ok"></figure><p data-pid="VDIGGwVN">在提交工作请求中，涉及到的通信资源有哪些呢？按照资源类型，可以分为上下文资源，队列资源和数据区域。按照资源所处的位置，又可以分为位于设备内存和主机内存。其中，部分资源是仅由网卡进行访问的，这部分资源可以留在主机内存中保持不变，例如队列基地址，通信序列号等。另一部分资源是由CPU进行读写或临时创建的，因此需要详细考虑。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-e83dd6edddd364350d6210d14fef3f40_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic1.zhimg.com/v2-e83dd6edddd364350d6210d14fef3f40_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-e83dd6edddd364350d6210d14fef3f40_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic1.zhimg.com/v2-e83dd6edddd364350d6210d14fef3f40_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-e83dd6edddd364350d6210d14fef3f40_b.jpg" data-lazy-status="ok"></figure><p data-pid="Th_lDOJq">当我们迁移到GPU的场景下，我们发现，GPU要访问这些通信资源，至少要考虑两个问题。</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-2fa6380c9b95281b686ad581a6c64aee_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic3.zhimg.com/v2-2fa6380c9b95281b686ad581a6c64aee_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-2fa6380c9b95281b686ad581a6c64aee_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic3.zhimg.com/v2-2fa6380c9b95281b686ad581a6c64aee_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-2fa6380c9b95281b686ad581a6c64aee_b.jpg" data-lazy-status="ok"></figure><p data-pid="-hjJ6hdw">首先，门铃资源位于网卡，GPU要控制通信必然要涉及到写门铃，也就是GPU如何访问网卡寄存器的问题。</p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-93cb9ae03e1b352b959fb0be608fd15f_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic4.zhimg.com/v2-93cb9ae03e1b352b959fb0be608fd15f_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-93cb9ae03e1b352b959fb0be608fd15f_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic4.zhimg.com/v2-93cb9ae03e1b352b959fb0be608fd15f_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-93cb9ae03e1b352b959fb0be608fd15f_b.jpg" data-lazy-status="ok"></figure><p data-pid="tfU1rKh0">第二个问题在于，除了刚才提到的网卡要直接操作的资源，GPU控制的这些资源，可以放在主机内存，也可以放在显存中。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-1e83b54bbe861408fef0b9eb8ffec844_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic1.zhimg.com/v2-1e83b54bbe861408fef0b9eb8ffec844_r.jpg"/></noscript><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic1.zhimg.com/v2-1e83b54bbe861408fef0b9eb8ffec844_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-1e83b54bbe861408fef0b9eb8ffec844_b.jpg"></figure><p data-pid="dMJhJzJg">对于问题一，我们还是先参考CPU是如何访问网卡BAR空间的。在CPU的页表中其实包含两种表项，一种表项指向实际的物理内存，表项的创建发生于出现缺页异常，另一种表项指向IO设备空间，由ioremap函数创建。通过ioremap，设备内存被映射到CPU的虚拟地址空间。</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-ea4984141868c996499430fb3fa42189_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic2.zhimg.com/v2-ea4984141868c996499430fb3fa42189_r.jpg"/></noscript><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic2.zhimg.com/v2-ea4984141868c996499430fb3fa42189_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-ea4984141868c996499430fb3fa42189_b.jpg"></figure><p data-pid="gJlWqqVH">对于GPU而言，使用cudaHostMemRegister和cudaHostGetDevicePointer等函数可以建立GPU虚拟地址到CPU内存空间的映射，也就是在GPU中建立到主机内存的页表项。</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-ff7de1d8f95a3501dc6ab3bf61ad69ea_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic3.zhimg.com/v2-ff7de1d8f95a3501dc6ab3bf61ad69ea_r.jpg"/></noscript><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic3.zhimg.com/v2-ff7de1d8f95a3501dc6ab3bf61ad69ea_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-ff7de1d8f95a3501dc6ab3bf61ad69ea_b.jpg"></figure><p data-pid="Ve50tC7N">但在早期的CUDA版本中，如果使用ioremap映射后的地址进行注册，会引发段错误。</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-ec81970eb8f9b75bdba25799fc42ddf2_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic3.zhimg.com/v2-ec81970eb8f9b75bdba25799fc42ddf2_r.jpg"/></noscript><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic3.zhimg.com/v2-ec81970eb8f9b75bdba25799fc42ddf2_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-ec81970eb8f9b75bdba25799fc42ddf2_b.jpg"></figure><p data-pid="51zc04wr">在CUDA 4.0之后该问题被修正，PCIe BAR空间能够直接映射到GPU虚拟地址空间。GPU访问门铃寄存器的问题得以解决。</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-ad6a80891289f08408af1af31ad0d65d_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic2.zhimg.com/v2-ad6a80891289f08408af1af31ad0d65d_r.jpg"/></noscript><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic2.zhimg.com/v2-ad6a80891289f08408af1af31ad0d65d_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-ad6a80891289f08408af1af31ad0d65d_b.jpg"></figure><p data-pid="GY7Z1OTr">如何确保2在1之后完成？放在显存中显然可以加速对通信资源的访问，但如果通信连接较大，势必会消耗大量的显存资源，因此需要进行折衷考虑。</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-e3a7123182af839a7781a2342b00f0ae_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic3.zhimg.com/v2-e3a7123182af839a7781a2342b00f0ae_r.jpg"/></noscript><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic3.zhimg.com/v2-e3a7123182af839a7781a2342b00f0ae_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-e3a7123182af839a7781a2342b00f0ae_b.jpg"></figure><p data-pid="rqqeSG31">放在显存中显然可以加速对通信资源的访问，但如果通信连接较大，势必会消耗大量的显存资源，因此需要进行折衷考虑。后面的评测仅仅从通信性能上考量两种放置策略的差异。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-5028da7e886a30d7147dd2f692baafb4_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic1.zhimg.com/v2-5028da7e886a30d7147dd2f692baafb4_r.jpg"/></noscript><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic1.zhimg.com/v2-5028da7e886a30d7147dd2f692baafb4_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-5028da7e886a30d7147dd2f692baafb4_b.jpg"></figure><p data-pid="VZCkqgZ0">最后一个问题就是GPU如何提交网络请求并与网卡进行同步。实际上有ibv_post_send，ibv_post_recv和ibv_poll_cq三个函数就可以了，因此，需要做的事情就是将libibverbs移植到GPU上执行。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-a159c6f3d886ae6458468ac263073400_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic1.zhimg.com/v2-a159c6f3d886ae6458468ac263073400_r.jpg"/></noscript><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic1.zhimg.com/v2-a159c6f3d886ae6458468ac263073400_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-a159c6f3d886ae6458468ac263073400_b.jpg"></figure><p data-pid="2AfT6lc7">移植本身没有什么太大的难度，大部分libibverbs库的代码都可以直接在GPU上运行。至此，我们解决了全部GPU控制通信的问题。</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-ea76684e778f7b1656e66ddf4e2d71b2_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic3.zhimg.com/v2-ea76684e778f7b1656e66ddf4e2d71b2_r.jpg"/></noscript><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic3.zhimg.com/v2-ea76684e778f7b1656e66ddf4e2d71b2_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-ea76684e778f7b1656e66ddf4e2d71b2_b.jpg"></figure><p class="ztext-empty-paragraph"><br></p><p data-pid="QvppUBLL">我们对整个过程做一个小结和回顾。首先，我们修改了Mellanox和Nvidia的内存注册部分，达到了网卡直接读写GPU显存的目的，实现了CPU控制的GPUDirect；接着，我们对通信资源进行划分，结合内存映射部分的修改，达到了GPU访问通信资源的目的，最后对libibverbs进行代码移植，最终实现了GPU控制的GPUDirect功能。在完成上述目标后，接下来要做的就是对GPUDirect进行优化，那么首先要对其进行详细的性能评测。</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-238ebd0d4342ab00a6878340c187e825_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic2.zhimg.com/v2-238ebd0d4342ab00a6878340c187e825_r.jpg"/></noscript><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic2.zhimg.com/v2-238ebd0d4342ab00a6878340c187e825_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-238ebd0d4342ab00a6878340c187e825_b.jpg"></figure><p data-pid="HN5Me9i_">对GPUDirect的性能评测主要分为两个部分，其一是不同的拓扑连接方式，也就是GPU在节点内是否隶属于同一个RC或PCIe Switch，这部分数据来源是Nvidia；其二是不同的控制方式，也就是CPU控制的通信和GPU控制的通信，这部分数据来源是德国海德堡大学。</p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-c862eddd4eb2156c61694289d1c9848f_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic4.zhimg.com/v2-c862eddd4eb2156c61694289d1c9848f_r.jpg"/></noscript><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic4.zhimg.com/v2-c862eddd4eb2156c61694289d1c9848f_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-c862eddd4eb2156c61694289d1c9848f_b.jpg"></figure><p data-pid="CEpFEvSl">所有的延迟测试都是用ud ping pong，带宽测试都是rdma_write。网卡理论带宽是56Gbps。</p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-88710f8b43f4cc38ce302f7e80f59b57_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic4.zhimg.com/v2-88710f8b43f4cc38ce302f7e80f59b57_r.jpg"/></noscript><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic4.zhimg.com/v2-88710f8b43f4cc38ce302f7e80f59b57_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-88710f8b43f4cc38ce302f7e80f59b57_b.jpg"></figure><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-030a66d6aecb9ebbfba4ab83bd4e90be_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic3.zhimg.com/v2-030a66d6aecb9ebbfba4ab83bd4e90be_r.jpg"/></noscript><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic3.zhimg.com/v2-030a66d6aecb9ebbfba4ab83bd4e90be_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-030a66d6aecb9ebbfba4ab83bd4e90be_b.jpg"></figure><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-402aa3fbe67539aefcdab56591894c4e_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic3.zhimg.com/v2-402aa3fbe67539aefcdab56591894c4e_r.jpg"/></noscript><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic3.zhimg.com/v2-402aa3fbe67539aefcdab56591894c4e_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-402aa3fbe67539aefcdab56591894c4e_b.jpg"></figure><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-0f0e70b17e762dd85c799e22d74a54e6_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic3.zhimg.com/v2-0f0e70b17e762dd85c799e22d74a54e6_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-0f0e70b17e762dd85c799e22d74a54e6_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic3.zhimg.com/v2-0f0e70b17e762dd85c799e22d74a54e6_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-0f0e70b17e762dd85c799e22d74a54e6_b.jpg" data-lazy-status="ok"></figure><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-437d831eaad2cb5bca39bd7c7465daf0_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic1.zhimg.com/v2-437d831eaad2cb5bca39bd7c7465daf0_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-437d831eaad2cb5bca39bd7c7465daf0_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic1.zhimg.com/v2-437d831eaad2cb5bca39bd7c7465daf0_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-437d831eaad2cb5bca39bd7c7465daf0_b.jpg" data-lazy-status="ok"></figure><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-df5f565f59e9a538426739593746049a_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic3.zhimg.com/v2-df5f565f59e9a538426739593746049a_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-df5f565f59e9a538426739593746049a_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic3.zhimg.com/v2-df5f565f59e9a538426739593746049a_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-df5f565f59e9a538426739593746049a_b.jpg" data-lazy-status="ok"></figure><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-98ae80c3358bd8d640582a33006ec75b_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic4.zhimg.com/v2-98ae80c3358bd8d640582a33006ec75b_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-98ae80c3358bd8d640582a33006ec75b_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic4.zhimg.com/v2-98ae80c3358bd8d640582a33006ec75b_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-98ae80c3358bd8d640582a33006ec75b_b.jpg" data-lazy-status="ok"></figure><p data-pid="zkKCWeZz">对比不同拓扑结构下的带宽，可以看到由CPU和GPU直接进行通信性能最好，对于GPU和GPU的通信，通过PCIe Switch进行转发的效果最佳。</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-eb24eaac2624d1e96ceef5ca30227a09_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic2.zhimg.com/v2-eb24eaac2624d1e96ceef5ca30227a09_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-eb24eaac2624d1e96ceef5ca30227a09_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic2.zhimg.com/v2-eb24eaac2624d1e96ceef5ca30227a09_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-eb24eaac2624d1e96ceef5ca30227a09_b.jpg" data-lazy-status="ok"></figure><p data-pid="S8A-bLoq">在延迟测试中能看到类似的结果。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-a1f69cff5c743f9a939592bc99a5dfb0_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic1.zhimg.com/v2-a1f69cff5c743f9a939592bc99a5dfb0_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-a1f69cff5c743f9a939592bc99a5dfb0_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic1.zhimg.com/v2-a1f69cff5c743f9a939592bc99a5dfb0_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-a1f69cff5c743f9a939592bc99a5dfb0_b.jpg" data-lazy-status="ok"></figure><p data-pid="hKGTF4vd">之后我们对CPU和GPU控制的通信进行对比。对比对象分为4类，首先是CPU控制的CPU和CPU通信，这是通信性能的天花板。然后是两类GPU控制的通信，分别是队列开辟在CPU内存中和GPU显存中，然后是CPU控制的GPU通信，使用P2P进行数据搬移，队列位于CPU内存中。实验测试指标是延迟，带宽和消息速率。在看实验结果之前我们可以预期自上到下性能应该是逐渐降低的。</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-21b86fb6df070731b3724b41a085bdea_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic3.zhimg.com/v2-21b86fb6df070731b3724b41a085bdea_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-21b86fb6df070731b3724b41a085bdea_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic3.zhimg.com/v2-21b86fb6df070731b3724b41a085bdea_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-21b86fb6df070731b3724b41a085bdea_b.jpg" data-lazy-status="ok"></figure><p data-pid="IYsMgsmf">基本上后面的延迟和带宽结果和推测是吻合的。</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-4e6be5e5b6b60cdc624c2625f5635252_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic3.zhimg.com/v2-4e6be5e5b6b60cdc624c2625f5635252_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-4e6be5e5b6b60cdc624c2625f5635252_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic3.zhimg.com/v2-4e6be5e5b6b60cdc624c2625f5635252_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-4e6be5e5b6b60cdc624c2625f5635252_b.jpg" data-lazy-status="ok"></figure><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-0ba4ec3a3b721772cedb2fae8aaa33ae_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic3.zhimg.com/v2-0ba4ec3a3b721772cedb2fae8aaa33ae_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-0ba4ec3a3b721772cedb2fae8aaa33ae_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic3.zhimg.com/v2-0ba4ec3a3b721772cedb2fae8aaa33ae_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-0ba4ec3a3b721772cedb2fae8aaa33ae_b.jpg" data-lazy-status="ok"></figure><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-9b3c07ccfc6c5cc8038900041bd64060_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic1.zhimg.com/v2-9b3c07ccfc6c5cc8038900041bd64060_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-9b3c07ccfc6c5cc8038900041bd64060_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic1.zhimg.com/v2-9b3c07ccfc6c5cc8038900041bd64060_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-9b3c07ccfc6c5cc8038900041bd64060_b.jpg" data-lazy-status="ok"></figure><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-1b269417587c520df22e23d07f27d599_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic2.zhimg.com/v2-1b269417587c520df22e23d07f27d599_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-1b269417587c520df22e23d07f27d599_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic2.zhimg.com/v2-1b269417587c520df22e23d07f27d599_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-1b269417587c520df22e23d07f27d599_b.jpg" data-lazy-status="ok"></figure><p data-pid="a830PMXo">之后我们对通信函数的执行延迟进行分析，可以看到CPU提交WQE的速率要远远高于GPU。这主要是因为提交WQE的代码里有大量的分支语句，而GPU的计算核心主要是进行数据并行计算，因此其控制逻辑的执行能力远远弱于CPU。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-309c13eb5d296d6f535767f3e4b23ca0_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic1.zhimg.com/v2-309c13eb5d296d6f535767f3e4b23ca0_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-309c13eb5d296d6f535767f3e4b23ca0_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic1.zhimg.com/v2-309c13eb5d296d6f535767f3e4b23ca0_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-309c13eb5d296d6f535767f3e4b23ca0_b.jpg" data-lazy-status="ok"></figure><p data-pid="j8dSRB5U">接下来我们对GPUDirect的评测部分进行小结，首先，在不同PCIe拓扑连接关系下，网卡和GPU位于相同的PCIe Switch下的性能是最优的，其次是同一个RC下，性能最差的是跨QPI的通信。对于不同的通信控制方式，最好的方式是CPU控制加数据P2P，GPU控制方式的性能瓶颈在于执行verbs的开销太大。</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-ebd9f15047f22a114dd8d4584d6b55f5_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic2.zhimg.com/v2-ebd9f15047f22a114dd8d4584d6b55f5_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-ebd9f15047f22a114dd8d4584d6b55f5_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic2.zhimg.com/v2-ebd9f15047f22a114dd8d4584d6b55f5_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-ebd9f15047f22a114dd8d4584d6b55f5_b.jpg" data-lazy-status="ok"></figure><p data-pid="5s5lieVX">接下来进入我们的第三部分，不同互连架构下的GPU通信性能评测。</p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-6121359304512b6a8740824cc3e5d2d7_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic4.zhimg.com/v2-6121359304512b6a8740824cc3e5d2d7_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-6121359304512b6a8740824cc3e5d2d7_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic4.zhimg.com/v2-6121359304512b6a8740824cc3e5d2d7_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-6121359304512b6a8740824cc3e5d2d7_b.jpg" data-lazy-status="ok"></figure><p data-pid="01AcGr6z">在前两部分我们重点探讨了GPU的节点间通信性能，这部分我们将详细分析节点内的通信性能。这部分内容来自TPDS的一篇文章[10]，主要是对PCIe，NVLink等GPU节点内互连的性能进行了评测。测试集使用的是Tartan Benchmark Suite。论文的内容非常多，我这里只列举了延迟，带宽和NUMA的影响，路由策略和拓扑方面不做讨论。通信模式上也只考虑点对点通信，有需要的话可以再去论文里面找数据。这篇文章实际上给出了很多评测数据，但实际上有价值的数据可能并不多，更多的是提供不同互连架构的带宽延迟相对性能的感性认知。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-4cc2b2b898baebb980f8ae155a252054_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic1.zhimg.com/v2-4cc2b2b898baebb980f8ae155a252054_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-4cc2b2b898baebb980f8ae155a252054_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic1.zhimg.com/v2-4cc2b2b898baebb980f8ae155a252054_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-4cc2b2b898baebb980f8ae155a252054_b.jpg" data-lazy-status="ok"></figure><p data-pid="3tjfGRYZ">首先介绍一下节点内通信的评测环境。</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-afec45b19d409fec5fd66f49c6dd9ec9_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic2.zhimg.com/v2-afec45b19d409fec5fd66f49c6dd9ec9_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-afec45b19d409fec5fd66f49c6dd9ec9_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic2.zhimg.com/v2-afec45b19d409fec5fd66f49c6dd9ec9_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-afec45b19d409fec5fd66f49c6dd9ec9_b.jpg" data-lazy-status="ok"></figure><p data-pid="bE22V1bm">节点内评测用了两个系统，DGX-1和DGX-2，其中DGX-1又用了两种GPU和互连。在左图中， 每个平面内的GPU形成一个全连接，不同平面内形成NUMA架构，NVLink本身不支持路由，不同平面间的GPU通信必须通过GPU进行转发。每个P100最多4个NVLink插槽，每个V100最多6个NVLink插槽。每个插槽可以理解为是200Gbps，P100带宽上限400Gbps，V100带宽上限1Tbps。</p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-c9a034c1173d197c5bf5c526c14b8eab_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic4.zhimg.com/v2-c9a034c1173d197c5bf5c526c14b8eab_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-c9a034c1173d197c5bf5c526c14b8eab_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic4.zhimg.com/v2-c9a034c1173d197c5bf5c526c14b8eab_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-c9a034c1173d197c5bf5c526c14b8eab_b.jpg" data-lazy-status="ok"></figure><p data-pid="zJ72JFMP">在DGX-2系统中引入了NVSwitch，主要用于加速GPU之间的all-to-all通信。所有节点划分为两个baseboard，每个baseboard包括6台交换机和8个节点，每个节点出6个lane，每个lane的带宽是200Gbps，节点聚合带宽达到1.2Tbps。</p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-51a1c3c23139cac38d919c529446e2cf_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic4.zhimg.com/v2-51a1c3c23139cac38d919c529446e2cf_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-51a1c3c23139cac38d919c529446e2cf_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic4.zhimg.com/v2-51a1c3c23139cac38d919c529446e2cf_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-51a1c3c23139cac38d919c529446e2cf_b.jpg" data-lazy-status="ok"></figure><p data-pid="CLkt-u8p">在DGX-2内部，不同GPU通过PCIe互连成为树形结构，每个CPU下面挂两级PCIe Switch，用于互连8个V100。还有一个系统是NV-SLI，它只有两个节点，节点间通过8个NVLink-Lane进行互连，聚合带宽可以达到1.6Tbps。</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-1cab568633bafb72c462e74ebf323631_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic2.zhimg.com/v2-1cab568633bafb72c462e74ebf323631_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-1cab568633bafb72c462e74ebf323631_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic2.zhimg.com/v2-1cab568633bafb72c462e74ebf323631_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-1cab568633bafb72c462e74ebf323631_b.jpg" data-lazy-status="ok"></figure><p data-pid="blO8d8wv">接下来对不同互连结构的通信性能进行评测，首先是DGX-1平台，图中给出了P100平台和V100平台下PCIe和NVLink的通信延迟。色调越冷延迟越高。对于PCIe通信而言，节点之间的通信延迟几乎是均匀分布的，不管是同一个PCIe Switch下，还是同一个CPU下，还是不同CPU下，延迟基本上都在20微秒左右。V100的延迟略有增加，作者认为是其通信转发的流水线深度有所增加。对于NVLink，P100和V100基本上展现出了相同的趋势，对于0号节点，1，2，3，4因为与其直接相连，所以延迟相同，而5，6，7需要4号节点做转发，所以延迟较高，甚至比CPU转发的延迟更高。</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-9b780ea8f05ccd473eb0ce4970e9407d_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic2.zhimg.com/v2-9b780ea8f05ccd473eb0ce4970e9407d_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-9b780ea8f05ccd473eb0ce4970e9407d_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic2.zhimg.com/v2-9b780ea8f05ccd473eb0ce4970e9407d_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-9b780ea8f05ccd473eb0ce4970e9407d_b.jpg" data-lazy-status="ok"></figure><p data-pid="y5TLvqH0">对于NV-SLI系统，只有两个GPU，NV-SLI访问延迟约8微秒，PCIe访问延迟约13微秒。</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-2f079e23cb0fc23a2ffe782160856d95_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic2.zhimg.com/v2-2f079e23cb0fc23a2ffe782160856d95_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-2f079e23cb0fc23a2ffe782160856d95_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic2.zhimg.com/v2-2f079e23cb0fc23a2ffe782160856d95_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-2f079e23cb0fc23a2ffe782160856d95_b.jpg" data-lazy-status="ok"></figure><p data-pid="VsodJkQO">对于DGX-2系统，所有的访问都是对称的，NVSwitch引入的跳步延迟几乎可以忽略不计。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-3cbf63dd3758eee4c4d60113ba17e4a0_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic1.zhimg.com/v2-3cbf63dd3758eee4c4d60113ba17e4a0_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-3cbf63dd3758eee4c4d60113ba17e4a0_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic1.zhimg.com/v2-3cbf63dd3758eee4c4d60113ba17e4a0_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-3cbf63dd3758eee4c4d60113ba17e4a0_b.jpg" data-lazy-status="ok"></figure><p data-pid="8hiVguaI">接下来看通信带宽，在DGX-1中，对于PCIe通信，居然出现了一种NUMA anti-locality现象，也就是离的越近的节点，其带宽反而越低。我们观察0号节点，发现其和1号节点隶属于同一个PCIe Switch，但其带宽反而低于不同PCIe Switch下的节点对。对于NVLink，其带宽则符合NUMA的访问规律，离的越远，访问带宽越低。</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-49f8d9aeaeb392c40c2844a4d94b9c8a_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic3.zhimg.com/v2-49f8d9aeaeb392c40c2844a4d94b9c8a_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-49f8d9aeaeb392c40c2844a4d94b9c8a_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic3.zhimg.com/v2-49f8d9aeaeb392c40c2844a4d94b9c8a_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-49f8d9aeaeb392c40c2844a4d94b9c8a_b.jpg" data-lazy-status="ok"></figure><p data-pid="6fPppnaw">NV-SLI的带宽和延迟的变化趋势基本一致。</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-8441b8ee79abd0b82aef7db4574078a5_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic2.zhimg.com/v2-8441b8ee79abd0b82aef7db4574078a5_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-8441b8ee79abd0b82aef7db4574078a5_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic2.zhimg.com/v2-8441b8ee79abd0b82aef7db4574078a5_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-8441b8ee79abd0b82aef7db4574078a5_b.jpg" data-lazy-status="ok"></figure><p data-pid="6HOzba1R">DGX-2中可以看到更加明显的anti-locality现象。</p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-a8a071aaafbd8313486f403048733c6f_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic4.zhimg.com/v2-a8a071aaafbd8313486f403048733c6f_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-a8a071aaafbd8313486f403048733c6f_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic4.zhimg.com/v2-a8a071aaafbd8313486f403048733c6f_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-a8a071aaafbd8313486f403048733c6f_b.jpg" data-lazy-status="ok"></figure><p data-pid="9w4YV5nF">接下来讨论节点间通信的评测结果。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-318f5dfe7b54e2dd398005795254769c_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic1.zhimg.com/v2-318f5dfe7b54e2dd398005795254769c_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-318f5dfe7b54e2dd398005795254769c_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic1.zhimg.com/v2-318f5dfe7b54e2dd398005795254769c_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-318f5dfe7b54e2dd398005795254769c_b.jpg" data-lazy-status="ok"></figure><p data-pid="iv3RS8ix">节点间通信测试使用的是Summit和SummitDev两个集群。其中SummitDev的CPU是Power 8，通过x-Bus互连，带宽约38GB/s，GPU是P100Summit超算节点内部互连架构图，CPU是Power 9，通过x-Bus互连，带宽约64GB/s，GPU是V100，通过NVLink直接跟Power 9相连。</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-9ee9ce505c5a2a89b82a03c909c39c25_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic2.zhimg.com/v2-9ee9ce505c5a2a89b82a03c909c39c25_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-9ee9ce505c5a2a89b82a03c909c39c25_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic2.zhimg.com/v2-9ee9ce505c5a2a89b82a03c909c39c25_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-9ee9ce505c5a2a89b82a03c909c39c25_b.jpg" data-lazy-status="ok"></figure><p data-pid="oPRARQ0r">评测中比较了5种通信实现方式。首先，pinnedMem指的是数据从显存拷贝到主存时是否使用了pinned memory，GPUDirect指的是网卡和GPU是否能够共用内存中的缓冲区。对于UnpinnedMem，至少要经过三次拷贝，第一次从GPU显存拷贝到CPU中的临时缓冲区，然后拷贝到用户缓冲区，再拷贝到网卡通信缓冲区。PinnedMem GPUDirect只需要经过一次GPU显存到内存的拷贝。</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-62f9bbcd2a2be98fa74298e34e92e7f6_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic3.zhimg.com/v2-62f9bbcd2a2be98fa74298e34e92e7f6_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-62f9bbcd2a2be98fa74298e34e92e7f6_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic3.zhimg.com/v2-62f9bbcd2a2be98fa74298e34e92e7f6_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-62f9bbcd2a2be98fa74298e34e92e7f6_b.jpg" data-lazy-status="ok"></figure><p data-pid="vNBmi2S3">从实验结果中观察到以下现象：1.直到4KB大小，不同策略的通信延迟和带宽性能差异不大；2.对于延迟，在4KB到64KB，GPUDirect RDMA表现出了较差的性能；3.对于带宽，在4KB到256KB，GPUDirect RDMA表现出了较差的性能。作者认为大概率是因为Power 8的IOH转发性能较差；4.从4MB开始，GPUDirect RDMA的相对性能有所提升，但还是比Pinned Mem-GPUDirect差一些；5.当消息大小超过64MB后，GPUDirect的带宽开始下滑。</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-74b18867743396c602c6be16e45b7575_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic2.zhimg.com/v2-74b18867743396c602c6be16e45b7575_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-74b18867743396c602c6be16e45b7575_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic2.zhimg.com/v2-74b18867743396c602c6be16e45b7575_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-74b18867743396c602c6be16e45b7575_b.jpg" data-lazy-status="ok"></figure><p data-pid="WZBngwC1">在Summit上，GPUDirect表现出了较好的性能，但并不清楚Summit对GPUDirect RDMA做了什么样的优化。</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-526ad196d3ee618341fbc5c0ab44ac36_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic3.zhimg.com/v2-526ad196d3ee618341fbc5c0ab44ac36_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-526ad196d3ee618341fbc5c0ab44ac36_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic3.zhimg.com/v2-526ad196d3ee618341fbc5c0ab44ac36_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-526ad196d3ee618341fbc5c0ab44ac36_b.jpg" data-lazy-status="ok"></figure><p data-pid="ZKc-RnCf">到现在为止，我们已经分析了GPUDirect的实现，性能特征，已经它和其它通信方式的对比。继续往前走，我们将遇到的问题就是如何去处理通用IO设备通信问题。这部分内容主要参考了[11-13]。</p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-21431a159fa642f6724a5c9e8c5986ef_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic4.zhimg.com/v2-21431a159fa642f6724a5c9e8c5986ef_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-21431a159fa642f6724a5c9e8c5986ef_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic4.zhimg.com/v2-21431a159fa642f6724a5c9e8c5986ef_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-21431a159fa642f6724a5c9e8c5986ef_b.jpg" data-lazy-status="ok"></figure><p data-pid="J736kfj7">目前，加速器，存储，网络这三者之间都表现出强烈的对等通信需求。我们可以看到，网络和存储之间出现了NVMe over Fabrics，加速器和存储之间有GPU和SSD直通，即Nvidia的Magnum IO框架，网络和加速器之间有GPUDirect，Habana，谷歌TPU。但是这些设备之间的通信框架和标准五花八门，没有一个统一的对等通信框架。</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-944a980eb2a196b726cbaa017fb09de2_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic3.zhimg.com/v2-944a980eb2a196b726cbaa017fb09de2_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-944a980eb2a196b726cbaa017fb09de2_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic3.zhimg.com/v2-944a980eb2a196b726cbaa017fb09de2_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-944a980eb2a196b726cbaa017fb09de2_b.jpg" data-lazy-status="ok"></figure><p data-pid="zDUNUK2t">因此，Linux想在内核里增加对P2P通信的统一支持，目前整个社区提出的解决方案大概有以下几种，分别针对不同的应用场景，我就不再详细展开介绍了。今天重点讨论的是POC，它是内核提供的一组标准API，全称是Provider，Orchestrator，Client架构。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-a0bf47308820557faee98f9b4d7a2738_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic1.zhimg.com/v2-a0bf47308820557faee98f9b4d7a2738_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-a0bf47308820557faee98f9b4d7a2738_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic1.zhimg.com/v2-a0bf47308820557faee98f9b4d7a2738_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-a0bf47308820557faee98f9b4d7a2738_b.jpg" data-lazy-status="ok"></figure><p data-pid="BK6kOQE7">现在对P2P的支持仅限于同一个PCIe Switch下的不同End Point，对于同一个RC下的End Point或不同RC下的End Point不做任何保障。内核提供了一个设备厂商白名单，位于白名单上的芯片组能够确保是支持P2P功能的。整个P2P框架中分为三部分，顾名思义，Provider提供P2P内存资源，类似于正常DMA的内存资源，Client发起P2P操作，Orchestrator协同两者的工作。之所以增加一个Orchestrator是因为同一个Provider可能要提供给多个Client使用，Orchestrator起到了一个管理者的作用，类似于之前Mellanox提供的网卡P2P框架中的peer_mem模块。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-2e8e9725a7bd4583f8ae5482c1923dac_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic1.zhimg.com/v2-2e8e9725a7bd4583f8ae5482c1923dac_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-2e8e9725a7bd4583f8ae5482c1923dac_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic1.zhimg.com/v2-2e8e9725a7bd4583f8ae5482c1923dac_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-2e8e9725a7bd4583f8ae5482c1923dac_b.jpg" data-lazy-status="ok"></figure><p data-pid="HAZYGLbF">每个模块使用内核提供的标准API，provider进行资源注册和开放，orchestrator进行P2P内存分配和释放，client使用新的DMA接口进行内存映射，获取物理地址表项。</p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-258a22db80ac586ee5875be9f3481e73_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic4.zhimg.com/v2-258a22db80ac586ee5875be9f3481e73_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-258a22db80ac586ee5875be9f3481e73_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic4.zhimg.com/v2-258a22db80ac586ee5875be9f3481e73_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-258a22db80ac586ee5875be9f3481e73_b.jpg" data-lazy-status="ok"></figure><p data-pid="wFj_wlbY">对于P2P技术而言，GPUDirect算是其应用层，那么之后我们将进行一些微基准测试，看看P2P技术在PCIe层面究竟表现如何。在图中实验平台中，两个IO设备作为对等通信实体挂在同一个PCIe Switch下面，其中一个通过P2P DMA访问另一个设备的内存或通过普通DMA访问主存。CPU上运行应用程序来产生内存读写负载，观察在有内存负载的情况下，P2P DMA和访存的性能差异。接下来的所有实验基本上都沿用该设计，只是IO设备会进行替换。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-fd368e44d52f587fd3c32e898e7d3e6c_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic1.zhimg.com/v2-fd368e44d52f587fd3c32e898e7d3e6c_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-fd368e44d52f587fd3c32e898e7d3e6c_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic1.zhimg.com/v2-fd368e44d52f587fd3c32e898e7d3e6c_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-fd368e44d52f587fd3c32e898e7d3e6c_b.jpg" data-lazy-status="ok"></figure><p data-pid="t1mGT5Ey">首先是一个微基准测试，两个设备分别是NoLoad和NetFPGA。其中，NoLoad是一个基于FPGA的NVMe加速器，其支持CMB（Controller Memory Buffer）。CMB是NVMe协议的可选项，驱动可以使用CMB作为命令队列缓冲区，以及数据缓冲区。同时，对pcie-bench进行了修改，使其能够读写其它IO设备的内存空间。内存负载选用的是ParaDNN和sysbench，ParaDNN产生的是神经网络训练负载，是一个20层的循环神经网络，128*4096*128的输入。sysbench将进行持续性的内存读写。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-d329791ae91ea36a9b0f77e7774ad234_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic1.zhimg.com/v2-d329791ae91ea36a9b0f77e7774ad234_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-d329791ae91ea36a9b0f77e7774ad234_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic1.zhimg.com/v2-d329791ae91ea36a9b0f77e7774ad234_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-d329791ae91ea36a9b0f77e7774ad234_b.jpg" data-lazy-status="ok"></figure><p data-pid="jh3uLSQn">实验中使用512B DMA随机写操作，持续120秒，柱状图给出的是平均值。Error bar给出了测试时间段内的最高值和最小值。无负载情况下，内存写操作和p2p写操作的测试结果与pcie-bench测试结果相同；ParaDNN干扰下，最多会使内存写操作带宽降至一半。sysbench干扰下，内存读操作几乎不受影响，内存写操作最多将带宽降低至30%。</p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-0e136b0eb06920e5840d973c77135227_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic4.zhimg.com/v2-0e136b0eb06920e5840d973c77135227_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-0e136b0eb06920e5840d973c77135227_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic4.zhimg.com/v2-0e136b0eb06920e5840d973c77135227_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-0e136b0eb06920e5840d973c77135227_b.jpg" data-lazy-status="ok"></figure><p data-pid="tI88q2cV">读测试进行1000次512B读操作，记录这些读操作的延迟概率密度分布。sysbench的内存写操作严重影响了DMA Read的延迟性能；DMA p2p的读性能完全不受任何内存负载的影响；DMA p2p的读延迟性能相对于普通DMA要稍高一些。</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-5487e2406dd76cdda027a2e99e55001a_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic3.zhimg.com/v2-5487e2406dd76cdda027a2e99e55001a_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-5487e2406dd76cdda027a2e99e55001a_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic3.zhimg.com/v2-5487e2406dd76cdda027a2e99e55001a_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-5487e2406dd76cdda027a2e99e55001a_b.jpg" data-lazy-status="ok"></figure><p data-pid="S589bFEH">第二个测试用于考察内存负载对于网络通信性能的影响。硬件使用Intel XL710网卡，物理带宽40Gbps，作者修改了一个开源的以太网通信框架netmap，使其可以将IO设备内存作为网络通信缓冲区使用。每台机器使用8个CPU核心进行收发包的处理，对数据包进行batch，每32个包进行一次发送，记录30秒内的带宽。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-4e5b0002dec71f2d280973dcdca4803c_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic1.zhimg.com/v2-4e5b0002dec71f2d280973dcdca4803c_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-4e5b0002dec71f2d280973dcdca4803c_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic1.zhimg.com/v2-4e5b0002dec71f2d280973dcdca4803c_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-4e5b0002dec71f2d280973dcdca4803c_b.jpg" data-lazy-status="ok"></figure><p data-pid="BhkIG34j">在内存读写负载较高时，发送方向的带宽几乎不受任何影响，和无负载情况保持相同。</p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-5fbd2777dad8bec8070b8f72e489b36b_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic4.zhimg.com/v2-5fbd2777dad8bec8070b8f72e489b36b_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-5fbd2777dad8bec8070b8f72e489b36b_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic4.zhimg.com/v2-5fbd2777dad8bec8070b8f72e489b36b_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-5fbd2777dad8bec8070b8f72e489b36b_b.jpg" data-lazy-status="ok"></figure><p data-pid="Nal-RLrW">对于Rx DMA，在包大小为1500B时，内存读负载使其带宽下降了15%，内存写负载使其带宽下降了27%。说明设备发起的DMA写请求更容易受到内存负载的影响。当包长小于256B时，不管是Tx还是Rx，P2P的带宽都小于普通DMA带宽，这是因为NoLoad本身是一个存储设备，其读写都是以一个block大小为单位进行的，即512B，小数据很难充分利用其带宽。同时，图d中，为什么P2P的带宽会受到内存负载影响。作者的解释是完成事件队列开在内存中，Tx方向上对描述符写回进行了合并，而Rx没有，每个接收到的数据包都要进行描述符写回，所以Rx更容易受到内存负载的影响，换言之Rx方向上的IOPS更高，导致其受到了内存负载的影响。</p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-db43383a02ce2ac5d0d72f88eb034f1b_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic4.zhimg.com/v2-db43383a02ce2ac5d0d72f88eb034f1b_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-db43383a02ce2ac5d0d72f88eb034f1b_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic4.zhimg.com/v2-db43383a02ce2ac5d0d72f88eb034f1b_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-db43383a02ce2ac5d0d72f88eb034f1b_b.jpg" data-lazy-status="ok"></figure><p data-pid="8bNvFHDK">上图通过处理器的PCM(Processor Counter Monitor)记录了P2P DMA过程中，Tx和Rx方向上的DMA写操作，这些DMA仅用于描述符的写回。很显然，Tx的描述符写回吞吐远低于Rx的描述符写回，说明Tx的描述符写回对内存带宽的需求并不高。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-064b1a25121ca598f854b862f5c99ab4_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic1.zhimg.com/v2-064b1a25121ca598f854b862f5c99ab4_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-064b1a25121ca598f854b862f5c99ab4_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic1.zhimg.com/v2-064b1a25121ca598f854b862f5c99ab4_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-064b1a25121ca598f854b862f5c99ab4_b.jpg" data-lazy-status="ok"></figure><p data-pid="TFKICQFG">测试三使用NVMe SSD作为P2P操作的发起方，作者对UNVMe驱动进行了修改，测试过程中仍然使用8个CPU核心，NVMe的batch size是64。</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-fce765beef8406272a136a32c622d43d_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic2.zhimg.com/v2-fce765beef8406272a136a32c622d43d_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-fce765beef8406272a136a32c622d43d_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic2.zhimg.com/v2-fce765beef8406272a136a32c622d43d_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-fce765beef8406272a136a32c622d43d_b.jpg" data-lazy-status="ok"></figure><p data-pid="RCs6S-DH">NVMe写命令的吞吐量基本不受内存负载影响，论文中没有给出具体实验结果。对于NVMe的读命令和网卡的Rx，都需要写回完成事件，即都需要发起DMA Write操作，但是NVMe的读命令却不受内存负载的影响。其根本原因在于两者的IOPS不一样，对于商用NVMe SSD，1M IOPS已经是一个很高的数值了，但对于网卡而言，哪怕只是10Gbps线速，IOPS要达到约14.88M左右，因此，NIC RX受到RX描述符写回的影响更大。可以看到网卡的单次操作最大是1500B，而NVMe SSD起步至少就是4KB，因此网卡的IOPS要高很多。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-ac72c9d3b90fbda07bc2a8dded4fb31c_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic1.zhimg.com/v2-ac72c9d3b90fbda07bc2a8dded4fb31c_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-ac72c9d3b90fbda07bc2a8dded4fb31c_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic1.zhimg.com/v2-ac72c9d3b90fbda07bc2a8dded4fb31c_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-ac72c9d3b90fbda07bc2a8dded4fb31c_b.jpg" data-lazy-status="ok"></figure><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-d963c9c4c020a09ac05eac6d23fd4126_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic3.zhimg.com/v2-d963c9c4c020a09ac05eac6d23fd4126_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-d963c9c4c020a09ac05eac6d23fd4126_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic3.zhimg.com/v2-d963c9c4c020a09ac05eac6d23fd4126_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-d963c9c4c020a09ac05eac6d23fd4126_b.jpg" data-lazy-status="ok"></figure><p data-pid="h5Brmv6u">对于NVMe的读命令和网卡的Rx，都需要写回完成事件，即都需要发起DMA Write操作，但是NVMe的读命令却不受内存负载的影响。其根本原因在于两者的IOPS不一样，对于商用NVMe SSD，1M IOPS已经是一个很高的数值了，但对于网卡而言，哪怕只是10Gbps线速，IOPS要达到约14.88M左右，因此，NIC RX受到RX描述符写回的影响更大。可以看到网卡的单次操作最大是1500B，而NVMe SSD起步至少就是4KB，因此网卡的IOPS要高很多。</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-ded14e9a6911ae94eb6673f006853332_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic3.zhimg.com/v2-ded14e9a6911ae94eb6673f006853332_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-ded14e9a6911ae94eb6673f006853332_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic3.zhimg.com/v2-ded14e9a6911ae94eb6673f006853332_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-ded14e9a6911ae94eb6673f006853332_b.jpg" data-lazy-status="ok"></figure><p data-pid="OaimeXB5">我们对上述P2P性能测试进行一个小结。</p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-73f6fb90f5de39f2b95265b2d671bc17_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic4.zhimg.com/v2-73f6fb90f5de39f2b95265b2d671bc17_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-73f6fb90f5de39f2b95265b2d671bc17_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic4.zhimg.com/v2-73f6fb90f5de39f2b95265b2d671bc17_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-73f6fb90f5de39f2b95265b2d671bc17_b.jpg" data-lazy-status="ok"></figure><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-6533a6a8f15fdd4240a6a052ba2ca2a4_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic1.zhimg.com/v2-6533a6a8f15fdd4240a6a052ba2ca2a4_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-6533a6a8f15fdd4240a6a052ba2ca2a4_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic1.zhimg.com/v2-6533a6a8f15fdd4240a6a052ba2ca2a4_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-6533a6a8f15fdd4240a6a052ba2ca2a4_b.jpg" data-lazy-status="ok"></figure><p data-pid="zeP-F8mL">至此，我们已经解决了现阶段P2P技术和GPUDirect技术的若干疑问，下一个面临的问题就是IO设备直接通信将如何发展下去。</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-637f5be742f8e540f6e2c2362b41b809_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic2.zhimg.com/v2-637f5be742f8e540f6e2c2362b41b809_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-637f5be742f8e540f6e2c2362b41b809_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic2.zhimg.com/v2-637f5be742f8e540f6e2c2362b41b809_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-637f5be742f8e540f6e2c2362b41b809_b.jpg" data-lazy-status="ok"></figure><p data-pid="MLH44at5">我们刚才提到的统一P2P框架，其实也只是处于整个发展过程中的过渡期，其出发点还是要兼容现有的PCIe协议，但是PCIe本质上还是为CPU和IO设备进行通信而设计的，并不适用于设备互连。</p><figure data-size="normal"><noscript><img src="https://pic2.zhimg.com/v2-8ae28f4842b8107438b4ae182e4fbce9_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic2.zhimg.com/v2-8ae28f4842b8107438b4ae182e4fbce9_r.jpg"/></noscript><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-8ae28f4842b8107438b4ae182e4fbce9_1440w.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic2.zhimg.com/v2-8ae28f4842b8107438b4ae182e4fbce9_r.jpg" data-actualsrc="https://pic2.zhimg.com/v2-8ae28f4842b8107438b4ae182e4fbce9_b.jpg" data-lazy-status="ok"></figure><p data-pid="NSXvm7rx">所以我认为下一个阶段不再是加速器、网络、存储三足鼎立，而应该是所有的设备都能够具有直接通信的能力，作为对等IO进行互连互通。</p><figure data-size="normal"><noscript><img src="https://pic1.zhimg.com/v2-35de1cde53d8e90a5bef96c68909893c_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic1.zhimg.com/v2-35de1cde53d8e90a5bef96c68909893c_r.jpg"/></noscript><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic1.zhimg.com/v2-35de1cde53d8e90a5bef96c68909893c_r.jpg" data-actualsrc="https://pic1.zhimg.com/v2-35de1cde53d8e90a5bef96c68909893c_b.jpg"></figure><p data-pid="FESt_p9R">那么首先要解决的一个问题就是怎么为这些对等IO设备提供统一的资源抽象。我们知道，CPU在使用加速器例如GPU，使用加载内核和同步的方式，使用SSD的时候使用读写命令队列，GPU使用SSD也采用这种方式。那么SSD是否能够直接使用GPU资源或其它加速器资源？</p><figure data-size="normal"><noscript><img src="https://pic3.zhimg.com/v2-c933c11af54b6bd95701584e4963f06a_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic3.zhimg.com/v2-c933c11af54b6bd95701584e4963f06a_r.jpg"/></noscript><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic3.zhimg.com/v2-c933c11af54b6bd95701584e4963f06a_r.jpg" data-actualsrc="https://pic3.zhimg.com/v2-c933c11af54b6bd95701584e4963f06a_b.jpg"></figure><p data-pid="Z24aH-G4">我们是否能够给所有设备提供一套标准的访问抽象？我认为不管是CPU和GPU通信，还是CPU和SSD通信，其本质都是一个请求和响应的交互模式，那么，是否有可能为对等IO设备的通信提供一套RPC的调用接口，不管是存储还是计算资源都能够通过相同的接口进行调用？</p><figure data-size="normal"><noscript><img src="https://pic4.zhimg.com/v2-8d107dc44ccec03a8d6783f6e4dd037b_b.jpg" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb" width="1280" data-original="https://pic4.zhimg.com/v2-8d107dc44ccec03a8d6783f6e4dd037b_r.jpg"/></noscript><img src="data:image/svg+xml;utf8,&lt;svg xmlns=&#39;http://www.w3.org/2000/svg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;/svg&gt;" data-caption="" data-size="normal" data-rawwidth="1280" data-rawheight="720" class="origin_image zh-lightbox-thumb lazy" width="1280" data-original="https://pic4.zhimg.com/v2-8d107dc44ccec03a8d6783f6e4dd037b_r.jpg" data-actualsrc="https://pic4.zhimg.com/v2-8d107dc44ccec03a8d6783f6e4dd037b_b.jpg"></figure><p data-pid="NmbS8RHz">---------------------------------------------------------------------------</p><p data-pid="1OU6_b5I">参考文献：</p><p data-pid="MhXVcf2A">1.A quantitative evaluation of unified memory in GPUs</p><p data-pid="3T8T3w9t">2.An Evaluation of Unified Memory Technology on NVIDIA GPUs</p><p data-pid="AdKjArPI">3.Performance Evaluation of Advanced Features in CUDA Unified Memory</p><p data-pid="1Bz-ySLS">4.Unified Memory on Pascal and Volta</p><p data-pid="VtfVjm1_">5.Everything you need to know about unified memory</p><p data-pid="sUSSIBNI">6.Benchmarking GPUDirect RDMA on Modern Server Platforms</p><p data-pid="jFxktmju">7.Direct Communication between distributed GPUs</p><p data-pid="XSTTtHGV">8.Towards Efficient Communication Methods and Models for Scalable GPU-Centric Computing Systems</p><p data-pid="lS1Thrux">9.An introduction to CUDA-Aware MPI</p><p data-pid="dA9wEM97">10.Evaluating modern GPU interconnect</p><p data-pid="X_5NJcQU">11.Exploring the PCIe Routes</p><p data-pid="AQqYqbbb">12.How beneficial is Peer-to-Peer DMA?</p><p data-pid="z4LAxgKA">13.SPIN: Seamless Operating System Integration of Peer-to-Peer DMA Between SSDs and GPUs</p></div></div></div><div role="button" tabindex="0" class="ContentItem-time">编辑于 2021-11-09 16:56</div><div class="Reward"><div><div class="Reward-tagline">「真诚赞赏，手留余香」</div><button class="Reward-rewardBtn">赞赏</button></div><div class="Reward-countZero">还没有人赞赏，快来当第一个赞赏的人吧！</div></div><div class="Post-topicsAndReviewer"><div class="TopicList Post-Topics"><div class="Tag Topic" data-za-detail-view-path-module="TopicItem" data-za-extra-module="{&quot;card&quot;:{&quot;content&quot;:{&quot;type&quot;:&quot;Topic&quot;,&quot;token&quot;:&quot;19608622&quot;}}}"><span class="Tag-content"><a class="TopicLink" href="https://www.zhihu.com/topic/19608622" target="_blank"><div class="Popover"><div id="Popover2-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover2-content">高性能计算</div></div></a></span></div><div class="Tag Topic" data-za-detail-view-path-module="TopicItem" data-za-extra-module="{&quot;card&quot;:{&quot;content&quot;:{&quot;type&quot;:&quot;Topic&quot;,&quot;token&quot;:&quot;19570894&quot;}}}"><span class="Tag-content"><a class="TopicLink" href="https://www.zhihu.com/topic/19570894" target="_blank"><div class="Popover"><div id="Popover3-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover3-content">图形处理器（GPU）</div></div></a></span></div><div class="Tag Topic" data-za-detail-view-path-module="TopicItem" data-za-extra-module="{&quot;card&quot;:{&quot;content&quot;:{&quot;type&quot;:&quot;Topic&quot;,&quot;token&quot;:&quot;20047090&quot;}}}"><span class="Tag-content"><a class="TopicLink" href="https://www.zhihu.com/topic/20047090" target="_blank"><div class="Popover"><div id="Popover4-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover4-content">大规模机器学习</div></div></a></span></div></div></div><div><div class="Sticky RichContent-actions is-fixed is-bottom" style="width: 690px; bottom: 0px; left: 445.667px;"><div class="ContentItem-actions" data-za-detail-view-path-module="BottomBar" data-za-extra-module="{&quot;card&quot;:{&quot;content&quot;:{&quot;type&quot;:&quot;Post&quot;,&quot;id&quot;:&quot;430101220&quot;}}}"><span><button aria-label="赞同 269 " aria-live="polite" type="button" class="Button VoteButton VoteButton--up"><span style="display:inline-flex;align-items:center">​<svg width="10" height="10" viewBox="0 0 24 24" data-new-api="AgreeFill24" data-old-api="TriangleUp" class="Zi Zi--TriangleUp VoteButton-TriangleUp" fill="currentColor"><path d="M13.792 3.681c-.781-1.406-2.803-1.406-3.584 0l-7.79 14.023c-.76 1.367.228 3.046 1.791 3.046h15.582c1.563 0 2.55-1.68 1.791-3.046l-7.79-14.023z" fill-rule="evenodd" clip-rule="evenodd"></path></svg></span>赞同 269</button><button aria-label="反对" aria-live="polite" type="button" class="Button VoteButton VoteButton--down"><span style="display:inline-flex;align-items:center">​<svg width="10" height="10" viewBox="0 0 24 24" data-new-api="OpposeFill24" data-old-api="TriangleDown" class="Zi Zi--TriangleDown" fill="currentColor"><path d="M13.792 20.319c-.781 1.406-2.803 1.406-3.584 0L2.418 6.296c-.76-1.367.228-3.046 1.791-3.046h15.582c1.563 0 2.55 1.68 1.791 3.046l-7.79 14.023z" fill-rule="evenodd" clip-rule="evenodd"></path></svg></span></button></span><button type="button" class="Button BottomActions-CommentBtn Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" data-new-api="ChatBubbleFill24" data-old-api="Comment" class="Zi Zi--Comment Button-zi" fill="currentColor"><path d="M12 2.75a9.25 9.25 0 104.737 17.197l2.643.817a1 1 0 001.25-1.25l-.8-2.588A9.25 9.25 0 0012 2.75z" fill-rule="evenodd" clip-rule="evenodd"></path></svg></span>16 条评论</button><div class="Popover ShareMenu"><div class="ShareMenu-toggler" id="Popover5-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover5-content"><img class="ShareMenu-fakeQRCode" src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/qrcode" alt="微信二维码"><button type="button" class="Button Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" data-new-api="PaperplaneFill24" data-old-api="Share" class="Zi Zi--Share Button-zi" fill="currentColor"><path d="M19.47 1.914a.8.8 0 011.204.778l-1.872 16.386a.9.9 0 01-1.204.743l-4.615-1.692a.7.7 0 00-.831.28l-1.927 3.02c-.43.674-1.474.369-1.474-.43v-3.865a.8.8 0 01.179-.504l5.808-7.148a.595.595 0 00-.897-.781l-5.93 6.354a1.1 1.1 0 01-1.258.252L2.57 13.46a.8.8 0 01-.08-1.415l16.98-10.13z"></path></svg></span>分享</button></div></div><button aria-live="polite" type="button" class="Button ContentItem-action Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" data-new-api="HeartFill24" data-old-api="Heart" class="Zi Zi--Heart Button-zi" fill="currentColor"><path d="M12.004 4.934c1.015-.944 2.484-1.618 3.98-1.618 3.48 0 6.53 3.265 6.15 7.614-.11 1.254-.686 2.55-1.458 3.753-.778 1.215-1.79 2.392-2.845 3.419-1.054 1.028-2.168 1.923-3.161 2.566a9.96 9.96 0 01-1.41.777c-.418.182-.862.32-1.268.32s-.848-.137-1.267-.317a9.918 9.918 0 01-1.407-.771c-.992-.64-2.103-1.53-3.156-2.555-1.052-1.024-2.062-2.2-2.84-3.417-.77-1.208-1.346-2.51-1.456-3.775-.38-4.349 2.67-7.614 6.15-7.614 1.484 0 2.983.673 3.988 1.618z" fill-rule="evenodd" clip-rule="evenodd"></path></svg></span>喜欢</button><button type="button" class="Button Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" data-new-api="StarFill24" data-old-api="Star" class="Zi Zi--Star Button-zi" fill="currentColor"><path d="M10.484 3.307c.673-1.168 2.358-1.168 3.032 0l2.377 4.122a.25.25 0 00.165.12l4.655.987c1.319.28 1.84 1.882.937 2.884l-3.186 3.535a.25.25 0 00-.063.193l.5 4.733c.142 1.34-1.222 2.33-2.453 1.782l-4.346-1.938a.25.25 0 00-.204 0l-4.346 1.938c-1.231.549-2.595-.442-2.453-1.782l.5-4.733a.25.25 0 00-.064-.193L2.35 11.42c-.903-1.002-.382-2.604.937-2.884l4.655-.987a.25.25 0 00.164-.12l2.378-4.122z"></path></svg></span>收藏</button><button type="button" class="Button ContentItem-action Button--plain Button--withIcon Button--withLabel"><span style="display:inline-flex;align-items:center">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" data-new-api="TrayFullFill24" data-old-api="Deliver" class="Zi Zi--Deliver Button-zi" fill="currentColor"><g fill-rule="evenodd" clip-rule="evenodd"><path d="M7.821 12a.75.75 0 01.75-.75h6.857a.75.75 0 010 1.5H8.571a.75.75 0 01-.75-.75zm1.144-4a.75.75 0 01.75-.75h4.571a.75.75 0 010 1.5H9.715a.75.75 0 01-.75-.75z"></path><path d="M7.527 3.15a2.35 2.35 0 00-2.309 1.91L3.165 15.84a.85.85 0 00-.015.16v2.5a2.35 2.35 0 002.35 2.35h13a2.35 2.35 0 002.35-2.35V16a.848.848 0 00-.015-.16L18.78 5.06a2.35 2.35 0 00-2.308-1.91H7.527zm0 1.7a.65.65 0 00-.639.528l-1.88 9.872h13.984l-1.88-9.872a.65.65 0 00-.64-.528H7.528z"></path></g></svg></span>申请转载</button><div class="Post-ActionMenuButton"><div class="Popover"><div id="Popover6-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover6-content"><button type="button" class="Button Button--plain Button--withIcon Button--iconOnly"><span style="display:inline-flex;align-items:center">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" data-new-api="Dots24" data-old-api="Dots" class="Zi Zi--Dots Button-zi" fill="currentColor"><path d="M5.34 12a1.665 1.665 0 11-3.33 0 1.665 1.665 0 013.33 0zm8.325 0a1.665 1.665 0 11-3.33 0 1.665 1.665 0 013.33 0zm8.325 0a1.665 1.665 0 11-3.33 0 1.665 1.665 0 013.33 0z"></path></svg></span></button></div></div></div></div><div class="Post-SideActions" style="opacity: 1;"><button class="like"><div class="Post-SideActions-icon"><svg width="16" height="16" viewBox="0 0 24 24" data-new-api="AgreeFill24" data-old-api="TriangleUp" class="Zi Zi--TriangleUp Post-SideActions-upIcon" fill="currentColor"><path d="M13.792 3.681c-.781-1.406-2.803-1.406-3.584 0l-7.79 14.023c-.76 1.367.228 3.046 1.791 3.046h15.582c1.563 0 2.55-1.68 1.791-3.046l-7.79-14.023z" fill-rule="evenodd" clip-rule="evenodd"></path></svg></div><div class="likeCount"><div class="likeCount-inner" data-previous="已赞同 270">赞同 269</div></div></button><div class="Popover ShareMenu"><div class="ShareMenu-toggler" id="Popover54-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover54-content"><img class="ShareMenu-fakeQRCode" src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/qrcode" alt="微信二维码"><button><div class="Post-SideActions-icon"><span style="display: inline-flex; align-items: center;">​<svg width="20" height="20" viewBox="0 0 24 24" data-new-api="PaperplaneFill24" data-old-api="Share" class="Zi Zi--Share" fill="currentColor"><path d="M19.47 1.914a.8.8 0 011.204.778l-1.872 16.386a.9.9 0 01-1.204.743l-4.615-1.692a.7.7 0 00-.831.28l-1.927 3.02c-.43.674-1.474.369-1.474-.43v-3.865a.8.8 0 01.179-.504l5.808-7.148a.595.595 0 00-.897-.781l-5.93 6.354a1.1 1.1 0 01-1.258.252L2.57 13.46a.8.8 0 01-.08-1.415l16.98-10.13z"></path></svg></span></div>分享</button></div></div></div></div><div class="Sticky--holder" style="position: static; inset: auto auto 0px 0px; display: block; float: none; margin: 0px 0px 10px; height: 54px;"></div></div></article><div class="Post-Sub Post-NormalSub"><div style="overflow: unset;" data-za-detail-view-path-module="CommentList" data-za-extra-module="{}"><div class="Comments-container css-plbgu"><div class="css-79elbk"><div><div class="css-1fo89v5"><img class="Avatar css-1oi6kgx" src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-ef69d369588e9764f9252225e6dc29ce_l.jpg" srcset="https://pica.zhimg.com/v2-ef69d369588e9764f9252225e6dc29ce_l.jpg?source=32738c0c 2x"><div class="css-x0pxoz"><div class="css-i6bazn"><div class="css-0"><div class="InputLike css-ip4bff Editable"><div class="Dropzone Editable-content RichText RichText--editable RichText--clearBoth ztext" style="min-height: 38px;"><div class="DraftEditor-root"><div class="public-DraftEditorPlaceholder-root"><div class="public-DraftEditorPlaceholder-inner" id="placeholder-bq0cc" style="white-space: pre-wrap;">评论千万条，友善第一条</div></div><div class="DraftEditor-editorContainer"><div aria-describedby="placeholder-bq0cc" class="notranslate public-DraftEditor-content" contenteditable="true" spellcheck="true" tabindex="0" style="outline: none; user-select: text; white-space: pre-wrap; overflow-wrap: break-word;" role="textbox"><div data-contents="true"><div class="Editable-unstyled" data-block="true" data-editor="bq0cc" data-offset-key="4r2ja-0-0"><div data-offset-key="4r2ja-0-0" class="public-DraftStyleDefault-block public-DraftStyleDefault-ltr"><span data-offset-key="4r2ja-0-0"><br data-text="true"></span></div></div></div></div></div></div></div><div></div><input multiple="" type="file" accept="image/webp,image/jpg,image/jpeg,image/png,image/gif" style="display: none;"></div></div></div></div></div></div><div class="css-z07uxh"><div class="css-we6n55"><div class="css-vpssrj"><div class="css-1k10w8f">16 条评论</div></div><div class="css-59erns"></div><div class="css-1hnxfhy"><div class="css-gjiv4z">默认</div><div class="css-1v9si9f">时间</div></div></div><div class="css-840pn3"><div class="css-1frn93x"><div class="css-vurnku"><div><div class="css-194v73m"><div class="css-1jll2aj"><div class="Popover"><div id="Popover18-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover18-content"><a href="https://www.zhihu.com/people/4e2454dcafc7c50f1241854f1f6994bb" target="_blank" class="css-1d3mfcn"><img class="Avatar css-1qchsfe" src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-a5cb37a6fbedbde1faa54fac3aca3fa2_l.jpg" srcset="https://pic1.zhimg.com/v2-a5cb37a6fbedbde1faa54fac3aca3fa2_l.jpg?source=06d4cd63 2x" alt="zero" loading="lazy"></a></div></div></div><div class="css-14nvvry"><div class="css-1besdh8"><div class="css-dza3t2"><div class="css-1tww9qq"><div class="Popover"><div id="Popover19-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover19-content"><a href="https://www.zhihu.com/people/4e2454dcafc7c50f1241854f1f6994bb" target="_blank" class="css-o7lu8j">zero</a></div></div></div></div><svg width="16" height="16" viewBox="0 0 24 24" data-new-api="Dots24" data-old-api="Dots24" class="ZDI ZDI--Dots24 css-1jofpfq" fill="currentColor"><path d="M5.34 12a1.665 1.665 0 11-3.33 0 1.665 1.665 0 013.33 0zm8.325 0a1.665 1.665 0 11-3.33 0 1.665 1.665 0 013.33 0zm8.325 0a1.665 1.665 0 11-3.33 0 1.665 1.665 0 013.33 0z"></path></svg></div><div class="CommentContent css-1ygdre8">CPU用DDR，GPU用HBM。总是有各种麻烦的互联。现在intel最新的xeon服务器有了HBM版本了，如果CPU和GPU都是HBM，以后unified memory才会真的好用吧。</div><div class="css-dbby2p"><div class="css-82fsyv"><div class="css-12cl38p">2021-11-29</div></div><div class="css-18opwoy"><button type="button" class="Button  css-1o56bgb"><span style="display: inline-flex; align-items: center;">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" data-new-api="ChatBubbleFill24" data-old-api="ChatBubbleFill24" class="ZDI ZDI--ChatBubbleFill24 css-15ro776" fill="currentColor"><path d="M12 2.75a9.25 9.25 0 104.737 17.197l2.643.817a1 1 0 001.25-1.25l-.8-2.588A9.25 9.25 0 0012 2.75z" fill-rule="evenodd" clip-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button css-h1yvwn" style="transform: none;"><span style="display: inline-flex; align-items: center;">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" data-new-api="ThumbFill24" data-old-api="ThumbFill24" class="ZDI ZDI--ThumbFill24 css-15ro776" fill="currentColor"><path d="M8.5 4.078c0-1.834 1.986-2.979 3.573-2.06a4.826 4.826 0 012.379 4.71l-.114 1.022h3.581c2.53 0 4.334 2.454 3.58 4.868l-1.823 5.833a3.784 3.784 0 01-3.848 2.64c-2.372-.147-6.042-.341-8.828-.341H4.5A1.75 1.75 0 012.75 19V9.5c0-.967.784-1.75 1.75-1.75h.637a3.418 3.418 0 003.19-2.191c.115-.296.173-.611.173-.928v-.553z"></path></svg></span>1</button></div></div></div></div></div><div><div class="css-194v73m"><div class="css-1jll2aj"><div class="Popover"><div id="Popover20-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover20-content"><a href="https://www.zhihu.com/people/7e1c185a6a99c53630650341a8f4f984" target="_blank" class="css-1d3mfcn"><img class="Avatar css-1qchsfe" src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-997e47a97fee93f16e73d5f7dd9dca46_l.jpg" srcset="https://pic1.zhimg.com/v2-997e47a97fee93f16e73d5f7dd9dca46_l.jpg?source=06d4cd63 2x" alt="Yaowen Xu" loading="lazy"></a></div></div></div><div class="css-14nvvry"><div class="css-1besdh8"><div class="css-dza3t2"><div class="css-1tww9qq"><div class="Popover"><div id="Popover21-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover21-content"><a href="https://www.zhihu.com/people/7e1c185a6a99c53630650341a8f4f984" target="_blank" class="css-o7lu8j">Yaowen Xu</a></div></div></div></div><svg width="16" height="16" viewBox="0 0 24 24" data-new-api="Dots24" data-old-api="Dots24" class="ZDI ZDI--Dots24 css-1jofpfq" fill="currentColor"><path d="M5.34 12a1.665 1.665 0 11-3.33 0 1.665 1.665 0 013.33 0zm8.325 0a1.665 1.665 0 11-3.33 0 1.665 1.665 0 013.33 0zm8.325 0a1.665 1.665 0 11-3.33 0 1.665 1.665 0 013.33 0z"></path></svg></div><div class="CommentContent css-1ygdre8"><p>牛的，写的有理有据；<img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-c71427010ca7866f9b08c37ec20672e0.png" class="sticker"></p></div><div class="css-dbby2p"><div class="css-82fsyv"><div class="css-12cl38p">07-07</div></div><div class="css-18opwoy"><button type="button" class="Button  css-1o56bgb"><span style="display: inline-flex; align-items: center;">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" data-new-api="ChatBubbleFill24" data-old-api="ChatBubbleFill24" class="ZDI ZDI--ChatBubbleFill24 css-15ro776" fill="currentColor"><path d="M12 2.75a9.25 9.25 0 104.737 17.197l2.643.817a1 1 0 001.25-1.25l-.8-2.588A9.25 9.25 0 0012 2.75z" fill-rule="evenodd" clip-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button css-h1yvwn" style="transform: none;"><span style="display: inline-flex; align-items: center;">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" data-new-api="ThumbFill24" data-old-api="ThumbFill24" class="ZDI ZDI--ThumbFill24 css-15ro776" fill="currentColor"><path d="M8.5 4.078c0-1.834 1.986-2.979 3.573-2.06a4.826 4.826 0 012.379 4.71l-.114 1.022h3.581c2.53 0 4.334 2.454 3.58 4.868l-1.823 5.833a3.784 3.784 0 01-3.848 2.64c-2.372-.147-6.042-.341-8.828-.341H4.5A1.75 1.75 0 012.75 19V9.5c0-.967.784-1.75 1.75-1.75h.637a3.418 3.418 0 003.19-2.191c.115-.296.173-.611.173-.928v-.553z"></path></svg></span>赞</button></div></div></div></div></div><div><div class="css-194v73m"><div class="css-1jll2aj"><div class="Popover"><div id="Popover22-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover22-content"><a href="https://www.zhihu.com/people/66954c2d8efa345862ec823e48ff1157" target="_blank" class="css-1d3mfcn"><img class="Avatar css-1qchsfe" src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-abed1a8c04700ba7d72b45195223e0ff_l.jpg" srcset="https://picx.zhimg.com/v2-abed1a8c04700ba7d72b45195223e0ff_l.jpg?source=06d4cd63 2x" alt="红领巾" loading="lazy"></a></div></div></div><div class="css-14nvvry"><div class="css-1besdh8"><div class="css-dza3t2"><div class="css-1tww9qq"><div class="Popover"><div id="Popover23-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover23-content"><a href="https://www.zhihu.com/people/66954c2d8efa345862ec823e48ff1157" target="_blank" class="css-o7lu8j">红领巾</a></div></div></div></div><svg width="16" height="16" viewBox="0 0 24 24" data-new-api="Dots24" data-old-api="Dots24" class="ZDI ZDI--Dots24 css-1jofpfq" fill="currentColor"><path d="M5.34 12a1.665 1.665 0 11-3.33 0 1.665 1.665 0 013.33 0zm8.325 0a1.665 1.665 0 11-3.33 0 1.665 1.665 0 013.33 0zm8.325 0a1.665 1.665 0 11-3.33 0 1.665 1.665 0 013.33 0z"></path></svg></div><div class="CommentContent css-1ygdre8">很受用。顺便请教一下，求推荐看哪些方面的书籍或知识可以深入理解pcie设备、BAR地址、主机内存，rdma网卡之间怎么关联的。内存映射关系怎么建立实现的这些知识。</div><div class="css-dbby2p"><div class="css-82fsyv"><div class="css-12cl38p">05-09</div></div><div class="css-18opwoy"><button type="button" class="Button  css-1o56bgb"><span style="display: inline-flex; align-items: center;">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" data-new-api="ChatBubbleFill24" data-old-api="ChatBubbleFill24" class="ZDI ZDI--ChatBubbleFill24 css-15ro776" fill="currentColor"><path d="M12 2.75a9.25 9.25 0 104.737 17.197l2.643.817a1 1 0 001.25-1.25l-.8-2.588A9.25 9.25 0 0012 2.75z" fill-rule="evenodd" clip-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button css-h1yvwn" style="transform: none;"><span style="display: inline-flex; align-items: center;">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" data-new-api="ThumbFill24" data-old-api="ThumbFill24" class="ZDI ZDI--ThumbFill24 css-15ro776" fill="currentColor"><path d="M8.5 4.078c0-1.834 1.986-2.979 3.573-2.06a4.826 4.826 0 012.379 4.71l-.114 1.022h3.581c2.53 0 4.334 2.454 3.58 4.868l-1.823 5.833a3.784 3.784 0 01-3.848 2.64c-2.372-.147-6.042-.341-8.828-.341H4.5A1.75 1.75 0 012.75 19V9.5c0-.967.784-1.75 1.75-1.75h.637a3.418 3.418 0 003.19-2.191c.115-.296.173-.611.173-.928v-.553z"></path></svg></span>赞</button></div></div></div></div></div><div><div class="css-194v73m"><div class="css-1jll2aj"><div class="Popover"><div id="Popover24-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover24-content"><a href="https://www.zhihu.com/people/8585668ab2e0d738b223ae757dc7cc83" target="_blank" class="css-1d3mfcn"><img class="Avatar css-1qchsfe" src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-abed1a8c04700ba7d72b45195223e0ff_l(1).jpg" srcset="https://pic4.zhimg.com/v2-abed1a8c04700ba7d72b45195223e0ff_l.jpg?source=06d4cd63 2x" alt="goodzjk" loading="lazy"></a></div></div></div><div class="css-14nvvry"><div class="css-1besdh8"><div class="css-dza3t2"><div class="css-1tww9qq"><div class="Popover"><div id="Popover25-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover25-content"><a href="https://www.zhihu.com/people/8585668ab2e0d738b223ae757dc7cc83" target="_blank" class="css-o7lu8j">goodzjk</a></div></div><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-4812630bc27d642f7cafcd6cdeca3d7a.jpg" class="css-1pj8qrb"></div></div><svg width="16" height="16" viewBox="0 0 24 24" data-new-api="Dots24" data-old-api="Dots24" class="ZDI ZDI--Dots24 css-1jofpfq" fill="currentColor"><path d="M5.34 12a1.665 1.665 0 11-3.33 0 1.665 1.665 0 013.33 0zm8.325 0a1.665 1.665 0 11-3.33 0 1.665 1.665 0 013.33 0zm8.325 0a1.665 1.665 0 11-3.33 0 1.665 1.665 0 013.33 0z"></path></svg></div><div class="CommentContent css-1ygdre8">Pcie的位置在哪</div><div class="css-dbby2p"><div class="css-82fsyv"><div class="css-12cl38p">04-19</div></div><div class="css-18opwoy"><button type="button" class="Button  css-1o56bgb"><span style="display: inline-flex; align-items: center;">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" data-new-api="ChatBubbleFill24" data-old-api="ChatBubbleFill24" class="ZDI ZDI--ChatBubbleFill24 css-15ro776" fill="currentColor"><path d="M12 2.75a9.25 9.25 0 104.737 17.197l2.643.817a1 1 0 001.25-1.25l-.8-2.588A9.25 9.25 0 0012 2.75z" fill-rule="evenodd" clip-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button css-h1yvwn" style="transform: none;"><span style="display: inline-flex; align-items: center;">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" data-new-api="ThumbFill24" data-old-api="ThumbFill24" class="ZDI ZDI--ThumbFill24 css-15ro776" fill="currentColor"><path d="M8.5 4.078c0-1.834 1.986-2.979 3.573-2.06a4.826 4.826 0 012.379 4.71l-.114 1.022h3.581c2.53 0 4.334 2.454 3.58 4.868l-1.823 5.833a3.784 3.784 0 01-3.848 2.64c-2.372-.147-6.042-.341-8.828-.341H4.5A1.75 1.75 0 012.75 19V9.5c0-.967.784-1.75 1.75-1.75h.637a3.418 3.418 0 003.19-2.191c.115-.296.173-.611.173-.928v-.553z"></path></svg></span>赞</button></div></div></div></div></div><div><div class="css-194v73m"><div class="css-1jll2aj"><div class="Popover"><div id="Popover26-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover26-content"><a href="https://www.zhihu.com/people/ff7c2814d422998437de96905e88b883" target="_blank" class="css-1d3mfcn"><img class="Avatar css-1qchsfe" src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-69e6441f7fe6e9d3d33c6c1d1be993a0_l.jpg" srcset="https://pic1.zhimg.com/v2-69e6441f7fe6e9d3d33c6c1d1be993a0_l.jpg?source=06d4cd63 2x" alt="慧维智能" loading="lazy"></a></div></div></div><div class="css-14nvvry"><div class="css-1besdh8"><div class="css-dza3t2"><div class="css-1tww9qq"><div class="Popover"><div id="Popover27-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover27-content"><a href="https://www.zhihu.com/people/ff7c2814d422998437de96905e88b883" target="_blank" class="css-o7lu8j">慧维智能</a></div></div></div></div><svg width="16" height="16" viewBox="0 0 24 24" data-new-api="Dots24" data-old-api="Dots24" class="ZDI ZDI--Dots24 css-1jofpfq" fill="currentColor"><path d="M5.34 12a1.665 1.665 0 11-3.33 0 1.665 1.665 0 013.33 0zm8.325 0a1.665 1.665 0 11-3.33 0 1.665 1.665 0 013.33 0zm8.325 0a1.665 1.665 0 11-3.33 0 1.665 1.665 0 013.33 0z"></path></svg></div><div class="CommentContent css-1ygdre8">大佬大佬<img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-c71427010ca7866f9b08c37ec20672e0.png" class="sticker"><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-c71427010ca7866f9b08c37ec20672e0.png" class="sticker"></div><div class="css-dbby2p"><div class="css-82fsyv"><div class="css-12cl38p">2021-12-05</div></div><div class="css-18opwoy"><button type="button" class="Button  css-1o56bgb"><span style="display: inline-flex; align-items: center;">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" data-new-api="ChatBubbleFill24" data-old-api="ChatBubbleFill24" class="ZDI ZDI--ChatBubbleFill24 css-15ro776" fill="currentColor"><path d="M12 2.75a9.25 9.25 0 104.737 17.197l2.643.817a1 1 0 001.25-1.25l-.8-2.588A9.25 9.25 0 0012 2.75z" fill-rule="evenodd" clip-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button css-h1yvwn" style="transform: none;"><span style="display: inline-flex; align-items: center;">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" data-new-api="ThumbFill24" data-old-api="ThumbFill24" class="ZDI ZDI--ThumbFill24 css-15ro776" fill="currentColor"><path d="M8.5 4.078c0-1.834 1.986-2.979 3.573-2.06a4.826 4.826 0 012.379 4.71l-.114 1.022h3.581c2.53 0 4.334 2.454 3.58 4.868l-1.823 5.833a3.784 3.784 0 01-3.848 2.64c-2.372-.147-6.042-.341-8.828-.341H4.5A1.75 1.75 0 012.75 19V9.5c0-.967.784-1.75 1.75-1.75h.637a3.418 3.418 0 003.19-2.191c.115-.296.173-.611.173-.928v-.553z"></path></svg></span>赞</button></div></div></div></div></div><div><div class="css-194v73m"><div class="css-1jll2aj"><div class="Popover"><div id="Popover28-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover28-content"><a href="https://www.zhihu.com/people/b42c1d831e114d12f5e53cd53c25131a" target="_blank" class="css-1d3mfcn"><img class="Avatar css-1qchsfe" src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/93b931c4767f83c4ff031cf63d17fdc8_l.jpg" srcset="https://pica.zhimg.com/93b931c4767f83c4ff031cf63d17fdc8_l.jpg?source=06d4cd63 2x" alt="萍水相逢" loading="lazy"></a></div></div></div><div class="css-14nvvry"><div class="css-1besdh8"><div class="css-dza3t2"><div class="css-1tww9qq"><div class="Popover"><div id="Popover29-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover29-content"><a href="https://www.zhihu.com/people/b42c1d831e114d12f5e53cd53c25131a" target="_blank" class="css-o7lu8j">萍水相逢</a></div></div></div></div><svg width="16" height="16" viewBox="0 0 24 24" data-new-api="Dots24" data-old-api="Dots24" class="ZDI ZDI--Dots24 css-1jofpfq" fill="currentColor"><path d="M5.34 12a1.665 1.665 0 11-3.33 0 1.665 1.665 0 013.33 0zm8.325 0a1.665 1.665 0 11-3.33 0 1.665 1.665 0 013.33 0zm8.325 0a1.665 1.665 0 11-3.33 0 1.665 1.665 0 013.33 0z"></path></svg></div><div class="CommentContent css-1ygdre8">写的太好了，虽然看的一知半解。这是目前中文资料里面写的最细的了，作者整理资源辛苦了，Nvidia的东西都是闭源的，根本搞不清楚人家里面都干的啥。</div><div class="css-dbby2p"><div class="css-82fsyv"><div class="css-12cl38p">2021-12-02</div></div><div class="css-18opwoy"><button type="button" class="Button  css-1o56bgb"><span style="display: inline-flex; align-items: center;">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" data-new-api="ChatBubbleFill24" data-old-api="ChatBubbleFill24" class="ZDI ZDI--ChatBubbleFill24 css-15ro776" fill="currentColor"><path d="M12 2.75a9.25 9.25 0 104.737 17.197l2.643.817a1 1 0 001.25-1.25l-.8-2.588A9.25 9.25 0 0012 2.75z" fill-rule="evenodd" clip-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button css-h1yvwn" style="transform: none;"><span style="display: inline-flex; align-items: center;">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" data-new-api="ThumbFill24" data-old-api="ThumbFill24" class="ZDI ZDI--ThumbFill24 css-15ro776" fill="currentColor"><path d="M8.5 4.078c0-1.834 1.986-2.979 3.573-2.06a4.826 4.826 0 012.379 4.71l-.114 1.022h3.581c2.53 0 4.334 2.454 3.58 4.868l-1.823 5.833a3.784 3.784 0 01-3.848 2.64c-2.372-.147-6.042-.341-8.828-.341H4.5A1.75 1.75 0 012.75 19V9.5c0-.967.784-1.75 1.75-1.75h.637a3.418 3.418 0 003.19-2.191c.115-.296.173-.611.173-.928v-.553z"></path></svg></span>赞</button></div></div></div></div></div><div><div class="css-194v73m"><div class="css-1jll2aj"><div class="Popover"><div id="Popover30-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover30-content"><a href="https://www.zhihu.com/people/ce04daa3c78556035ffef420496f6bee" target="_blank" class="css-1d3mfcn"><img class="Avatar css-1qchsfe" src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-abed1a8c04700ba7d72b45195223e0ff_l(2).jpg" srcset="https://pic2.zhimg.com/v2-abed1a8c04700ba7d72b45195223e0ff_l.jpg?source=06d4cd63 2x" alt="沉默的猴子" loading="lazy"></a></div></div></div><div class="css-14nvvry"><div class="css-1besdh8"><div class="css-dza3t2"><div class="css-1tww9qq"><div class="Popover"><div id="Popover31-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover31-content"><a href="https://www.zhihu.com/people/ce04daa3c78556035ffef420496f6bee" target="_blank" class="css-o7lu8j">沉默的猴子</a></div></div></div></div><svg width="16" height="16" viewBox="0 0 24 24" data-new-api="Dots24" data-old-api="Dots24" class="ZDI ZDI--Dots24 css-1jofpfq" fill="currentColor"><path d="M5.34 12a1.665 1.665 0 11-3.33 0 1.665 1.665 0 013.33 0zm8.325 0a1.665 1.665 0 11-3.33 0 1.665 1.665 0 013.33 0zm8.325 0a1.665 1.665 0 11-3.33 0 1.665 1.665 0 013.33 0z"></path></svg></div><div class="CommentContent css-1ygdre8">猜测：Intel chipset内部的PCIe design（例如RC），受限于需要综合考量各种Device IO源、各种inter-cycle的order等，所以并不如一个纯粹的PCIe switch更有效率。<br>另外，关于下一代IO设备通信发展方向，就是Nvidia正在做的吧。以后的CPU就是个单纯的控制中心，大量的通信都是通过单独的Link在Device之间直接完成。</div><div class="css-dbby2p"><div class="css-82fsyv"><div class="css-12cl38p">2021-11-29</div></div><div class="css-18opwoy"><button type="button" class="Button  css-1o56bgb"><span style="display: inline-flex; align-items: center;">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" data-new-api="ChatBubbleFill24" data-old-api="ChatBubbleFill24" class="ZDI ZDI--ChatBubbleFill24 css-15ro776" fill="currentColor"><path d="M12 2.75a9.25 9.25 0 104.737 17.197l2.643.817a1 1 0 001.25-1.25l-.8-2.588A9.25 9.25 0 0012 2.75z" fill-rule="evenodd" clip-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button css-h1yvwn" style="transform: none;"><span style="display: inline-flex; align-items: center;">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" data-new-api="ThumbFill24" data-old-api="ThumbFill24" class="ZDI ZDI--ThumbFill24 css-15ro776" fill="currentColor"><path d="M8.5 4.078c0-1.834 1.986-2.979 3.573-2.06a4.826 4.826 0 012.379 4.71l-.114 1.022h3.581c2.53 0 4.334 2.454 3.58 4.868l-1.823 5.833a3.784 3.784 0 01-3.848 2.64c-2.372-.147-6.042-.341-8.828-.341H4.5A1.75 1.75 0 012.75 19V9.5c0-.967.784-1.75 1.75-1.75h.637a3.418 3.418 0 003.19-2.191c.115-.296.173-.611.173-.928v-.553z"></path></svg></span>赞</button></div></div></div></div><div><div class="css-8j5fyx"><div class="css-1jll2aj"><div class="Popover"><div id="Popover32-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover32-content"><a href="https://www.zhihu.com/people/4b88b8fd34703b95cde7a736a85ec8cb" target="_blank" class="css-1d3mfcn"><img class="Avatar css-1qchsfe" src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-8966d1ab2d8ee8980d116f4d746ce456_l.jpg" srcset="https://pic1.zhimg.com/v2-8966d1ab2d8ee8980d116f4d746ce456_l.jpg?source=06d4cd63 2x" alt="函谷叨客" loading="lazy"></a></div></div></div><div class="css-14nvvry"><div class="css-1besdh8"><div class="css-dza3t2"><div class="css-1tww9qq"><div class="Popover"><div id="Popover33-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover33-content"><a href="https://www.zhihu.com/people/4b88b8fd34703b95cde7a736a85ec8cb" target="_blank" class="css-o7lu8j">函谷叨客</a></div></div><span class="css-h9ndtl" href="">作者</span></div></div><svg width="16" height="16" viewBox="0 0 24 24" data-new-api="Dots24" data-old-api="Dots24" class="ZDI ZDI--Dots24 css-1jofpfq" fill="currentColor"><path d="M5.34 12a1.665 1.665 0 11-3.33 0 1.665 1.665 0 013.33 0zm8.325 0a1.665 1.665 0 11-3.33 0 1.665 1.665 0 013.33 0zm8.325 0a1.665 1.665 0 11-3.33 0 1.665 1.665 0 013.33 0z"></path></svg></div><div class="CommentContent css-1ygdre8">关于下一代IO设备通信，我了解到的Nvidia目前也只是GPU之间能走私有互连，GPU跟其它IO设备通信还是绕不开PCIe。虽然去中心化做设备直接互连是趋势，但是无论从硬件架构还是软件接口都涉及到巨大的变革，我认为已经不仅仅是技术层面的问题了。另外想请教一下inter-cycle的order指的是什么？</div><div class="css-dbby2p"><div class="css-82fsyv"><div class="css-12cl38p">2021-11-29</div></div><div class="css-18opwoy"><button type="button" class="Button  css-1o56bgb"><span style="display: inline-flex; align-items: center;">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" data-new-api="ChatBubbleFill24" data-old-api="ChatBubbleFill24" class="ZDI ZDI--ChatBubbleFill24 css-15ro776" fill="currentColor"><path d="M12 2.75a9.25 9.25 0 104.737 17.197l2.643.817a1 1 0 001.25-1.25l-.8-2.588A9.25 9.25 0 0012 2.75z" fill-rule="evenodd" clip-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button css-h1yvwn" style="transform: none;"><span style="display: inline-flex; align-items: center;">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" data-new-api="ThumbFill24" data-old-api="ThumbFill24" class="ZDI ZDI--ThumbFill24 css-15ro776" fill="currentColor"><path d="M8.5 4.078c0-1.834 1.986-2.979 3.573-2.06a4.826 4.826 0 012.379 4.71l-.114 1.022h3.581c2.53 0 4.334 2.454 3.58 4.868l-1.823 5.833a3.784 3.784 0 01-3.848 2.64c-2.372-.147-6.042-.341-8.828-.341H4.5A1.75 1.75 0 012.75 19V9.5c0-.967.784-1.75 1.75-1.75h.637a3.418 3.418 0 003.19-2.191c.115-.296.173-.611.173-.928v-.553z"></path></svg></span>1</button></div></div></div></div></div><div><div class="css-8j5fyx"><div class="css-1jll2aj"><div class="Popover"><div id="Popover34-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover34-content"><a href="https://www.zhihu.com/people/ce04daa3c78556035ffef420496f6bee" target="_blank" class="css-1d3mfcn"><img class="Avatar css-1qchsfe" src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-abed1a8c04700ba7d72b45195223e0ff_l(3).jpg" srcset="https://pic1.zhimg.com/v2-abed1a8c04700ba7d72b45195223e0ff_l.jpg?source=06d4cd63 2x" alt="沉默的猴子" loading="lazy"></a></div></div></div><div class="css-14nvvry"><div class="css-1besdh8"><div class="css-dza3t2"><div class="css-1tww9qq"><div class="Popover"><div id="Popover35-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover35-content"><a href="https://www.zhihu.com/people/ce04daa3c78556035ffef420496f6bee" target="_blank" class="css-o7lu8j">沉默的猴子</a></div></div></div><svg width="12" height="12" viewBox="0 0 16 16" data-new-api="ArrowRightAlt16" data-old-api="ArrowRightAlt16" class="ZDI ZDI--ArrowRightAlt16 css-5hz1ob" fill="currentColor"><path d="M10.727 7.48a.63.63 0 010 1.039l-4.299 2.88c-.399.268-.926-.028-.926-.519V5.12c0-.491.527-.787.926-.52l4.299 2.881z"></path></svg><div class="css-1tww9qq"><div class="Popover"><div id="Popover36-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover36-content"><a href="https://www.zhihu.com/people/4b88b8fd34703b95cde7a736a85ec8cb" target="_blank" class="css-o7lu8j">函谷叨客</a></div></div></div></div><svg width="16" height="16" viewBox="0 0 24 24" data-new-api="Dots24" data-old-api="Dots24" class="ZDI ZDI--Dots24 css-1jofpfq" fill="currentColor"><path d="M5.34 12a1.665 1.665 0 11-3.33 0 1.665 1.665 0 013.33 0zm8.325 0a1.665 1.665 0 11-3.33 0 1.665 1.665 0 013.33 0zm8.325 0a1.665 1.665 0 11-3.33 0 1.665 1.665 0 013.33 0z"></path></svg></div><div class="CommentContent css-1ygdre8">正如你所说，英伟达已经实现了GPU-GPU私有连接，这就是IO设备通信的模型，只不过它是英伟达自家的GPU之间而已。另外，它在收购Mellanox后，也做了很多跟网络相关的工作，但主要是软件层面实现的P2P访问，当它发现现有的软件方案已经不足以支撑其对带宽的需求时，也一定会像GPU一样，实现在GPU和网卡之间的私有连接。<br>对于inter-cycle，我的猜测是：chipset作为CPU、DRAM、IO的控制中心，其design内部不仅有PCIe RC的逻辑，还要维持cache coherency、考虑upstream/downstream cycle的order、考虑来自不同的RC、integrated device的各类IO cycle，还有P2P cycle是否需要经过translation engine处理、甚至还可能暗地分配这些IO来源的带宽...所有需要考量的这些因素都会影响GPU-GPU之间P2P cycle的执行。因此，相对于PCIe Switch这样单纯的硬件逻辑（对于P2P，只要不enable ACS，P2P cycle甚至都不会向Upstream送，直接在Switch内部转发到target），目前的Intel chipset并不适合压榨Spec规定的带宽极限，或者说只能在某些方面或者方向上达到标称带宽。</div><div class="css-dbby2p"><div class="css-82fsyv"><div class="css-12cl38p">2021-11-30</div></div><div class="css-18opwoy"><button type="button" class="Button  css-1o56bgb"><span style="display: inline-flex; align-items: center;">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" data-new-api="ChatBubbleFill24" data-old-api="ChatBubbleFill24" class="ZDI ZDI--ChatBubbleFill24 css-15ro776" fill="currentColor"><path d="M12 2.75a9.25 9.25 0 104.737 17.197l2.643.817a1 1 0 001.25-1.25l-.8-2.588A9.25 9.25 0 0012 2.75z" fill-rule="evenodd" clip-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button css-h1yvwn" style="transform: none;"><span style="display: inline-flex; align-items: center;">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" data-new-api="ThumbFill24" data-old-api="ThumbFill24" class="ZDI ZDI--ThumbFill24 css-15ro776" fill="currentColor"><path d="M8.5 4.078c0-1.834 1.986-2.979 3.573-2.06a4.826 4.826 0 012.379 4.71l-.114 1.022h3.581c2.53 0 4.334 2.454 3.58 4.868l-1.823 5.833a3.784 3.784 0 01-3.848 2.64c-2.372-.147-6.042-.341-8.828-.341H4.5A1.75 1.75 0 012.75 19V9.5c0-.967.784-1.75 1.75-1.75h.637a3.418 3.418 0 003.19-2.191c.115-.296.173-.611.173-.928v-.553z"></path></svg></span>赞</button></div></div></div></div></div></div><div><div class="css-194v73m"><div class="css-1jll2aj"><div class="Popover"><div id="Popover37-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover37-content"><a href="https://www.zhihu.com/people/16805d6ad7f660227e45e8c0999341b9" target="_blank" class="css-1d3mfcn"><img class="Avatar css-1qchsfe" src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/10cd7b09b5944a1d5e8c0c5a60ac138f_l.jpg" srcset="https://pic3.zhimg.com/10cd7b09b5944a1d5e8c0c5a60ac138f_l.jpg?source=06d4cd63 2x" alt="木头骨头石头" loading="lazy"></a></div></div></div><div class="css-14nvvry"><div class="css-1besdh8"><div class="css-dza3t2"><div class="css-1tww9qq"><div class="Popover"><div id="Popover38-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover38-content"><a href="https://www.zhihu.com/people/16805d6ad7f660227e45e8c0999341b9" target="_blank" class="css-o7lu8j">木头骨头石头</a></div></div></div></div><svg width="16" height="16" viewBox="0 0 24 24" data-new-api="Dots24" data-old-api="Dots24" class="ZDI ZDI--Dots24 css-1jofpfq" fill="currentColor"><path d="M5.34 12a1.665 1.665 0 11-3.33 0 1.665 1.665 0 013.33 0zm8.325 0a1.665 1.665 0 11-3.33 0 1.665 1.665 0 013.33 0zm8.325 0a1.665 1.665 0 11-3.33 0 1.665 1.665 0 013.33 0z"></path></svg></div><div class="CommentContent css-1ygdre8">请教一下作者，分离式内存管理和 PCIe MMIO 的关系，感觉 PCIe MMIO 是分离式内存管理的基础</div><div class="css-dbby2p"><div class="css-82fsyv"><div class="css-12cl38p">2021-11-25</div></div><div class="css-18opwoy"><button type="button" class="Button  css-1o56bgb"><span style="display: inline-flex; align-items: center;">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" data-new-api="ChatBubbleFill24" data-old-api="ChatBubbleFill24" class="ZDI ZDI--ChatBubbleFill24 css-15ro776" fill="currentColor"><path d="M12 2.75a9.25 9.25 0 104.737 17.197l2.643.817a1 1 0 001.25-1.25l-.8-2.588A9.25 9.25 0 0012 2.75z" fill-rule="evenodd" clip-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button css-h1yvwn" style="transform: none;"><span style="display: inline-flex; align-items: center;">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" data-new-api="ThumbFill24" data-old-api="ThumbFill24" class="ZDI ZDI--ThumbFill24 css-15ro776" fill="currentColor"><path d="M8.5 4.078c0-1.834 1.986-2.979 3.573-2.06a4.826 4.826 0 012.379 4.71l-.114 1.022h3.581c2.53 0 4.334 2.454 3.58 4.868l-1.823 5.833a3.784 3.784 0 01-3.848 2.64c-2.372-.147-6.042-.341-8.828-.341H4.5A1.75 1.75 0 012.75 19V9.5c0-.967.784-1.75 1.75-1.75h.637a3.418 3.418 0 003.19-2.191c.115-.296.173-.611.173-.928v-.553z"></path></svg></span>赞</button></div></div></div></div><div><div class="css-8j5fyx"><div class="css-1jll2aj"><div class="Popover"><div id="Popover39-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover39-content"><a href="https://www.zhihu.com/people/16805d6ad7f660227e45e8c0999341b9" target="_blank" class="css-1d3mfcn"><img class="Avatar css-1qchsfe" src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/10cd7b09b5944a1d5e8c0c5a60ac138f_l(1).jpg" srcset="https://pica.zhimg.com/10cd7b09b5944a1d5e8c0c5a60ac138f_l.jpg?source=06d4cd63 2x" alt="木头骨头石头" loading="lazy"></a></div></div></div><div class="css-14nvvry"><div class="css-1besdh8"><div class="css-dza3t2"><div class="css-1tww9qq"><div class="Popover"><div id="Popover40-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover40-content"><a href="https://www.zhihu.com/people/16805d6ad7f660227e45e8c0999341b9" target="_blank" class="css-o7lu8j">木头骨头石头</a></div></div></div><svg width="12" height="12" viewBox="0 0 16 16" data-new-api="ArrowRightAlt16" data-old-api="ArrowRightAlt16" class="ZDI ZDI--ArrowRightAlt16 css-5hz1ob" fill="currentColor"><path d="M10.727 7.48a.63.63 0 010 1.039l-4.299 2.88c-.399.268-.926-.028-.926-.519V5.12c0-.491.527-.787.926-.52l4.299 2.881z"></path></svg><div class="css-1tww9qq"><div class="Popover"><div id="Popover41-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover41-content"><a href="https://www.zhihu.com/people/4b88b8fd34703b95cde7a736a85ec8cb" target="_blank" class="css-o7lu8j">函谷叨客</a></div></div></div></div><svg width="16" height="16" viewBox="0 0 24 24" data-new-api="Dots24" data-old-api="Dots24" class="ZDI ZDI--Dots24 css-1jofpfq" fill="currentColor"><path d="M5.34 12a1.665 1.665 0 11-3.33 0 1.665 1.665 0 013.33 0zm8.325 0a1.665 1.665 0 11-3.33 0 1.665 1.665 0 013.33 0zm8.325 0a1.665 1.665 0 11-3.33 0 1.665 1.665 0 013.33 0z"></path></svg></div><div class="CommentContent css-1ygdre8">感谢作者大大<img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-c71427010ca7866f9b08c37ec20672e0.png" class="sticker"></div><div class="css-dbby2p"><div class="css-82fsyv"><div class="css-12cl38p">2021-11-25</div></div><div class="css-18opwoy"><button type="button" class="Button  css-1o56bgb"><span style="display: inline-flex; align-items: center;">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" data-new-api="ChatBubbleFill24" data-old-api="ChatBubbleFill24" class="ZDI ZDI--ChatBubbleFill24 css-15ro776" fill="currentColor"><path d="M12 2.75a9.25 9.25 0 104.737 17.197l2.643.817a1 1 0 001.25-1.25l-.8-2.588A9.25 9.25 0 0012 2.75z" fill-rule="evenodd" clip-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button css-h1yvwn" style="transform: none;"><span style="display: inline-flex; align-items: center;">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" data-new-api="ThumbFill24" data-old-api="ThumbFill24" class="ZDI ZDI--ThumbFill24 css-15ro776" fill="currentColor"><path d="M8.5 4.078c0-1.834 1.986-2.979 3.573-2.06a4.826 4.826 0 012.379 4.71l-.114 1.022h3.581c2.53 0 4.334 2.454 3.58 4.868l-1.823 5.833a3.784 3.784 0 01-3.848 2.64c-2.372-.147-6.042-.341-8.828-.341H4.5A1.75 1.75 0 012.75 19V9.5c0-.967.784-1.75 1.75-1.75h.637a3.418 3.418 0 003.19-2.191c.115-.296.173-.611.173-.928v-.553z"></path></svg></span>赞</button></div></div></div></div></div><div><div class="css-8j5fyx"><div class="css-1jll2aj"><div class="Popover"><div id="Popover42-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover42-content"><a href="https://www.zhihu.com/people/4b88b8fd34703b95cde7a736a85ec8cb" target="_blank" class="css-1d3mfcn"><img class="Avatar css-1qchsfe" src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-8966d1ab2d8ee8980d116f4d746ce456_l.jpg" srcset="https://pic1.zhimg.com/v2-8966d1ab2d8ee8980d116f4d746ce456_l.jpg?source=06d4cd63 2x" alt="函谷叨客" loading="lazy"></a></div></div></div><div class="css-14nvvry"><div class="css-1besdh8"><div class="css-dza3t2"><div class="css-1tww9qq"><div class="Popover"><div id="Popover43-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover43-content"><a href="https://www.zhihu.com/people/4b88b8fd34703b95cde7a736a85ec8cb" target="_blank" class="css-o7lu8j">函谷叨客</a></div></div><span class="css-h9ndtl" href="">作者</span></div></div><svg width="16" height="16" viewBox="0 0 24 24" data-new-api="Dots24" data-old-api="Dots24" class="ZDI ZDI--Dots24 css-1jofpfq" fill="currentColor"><path d="M5.34 12a1.665 1.665 0 11-3.33 0 1.665 1.665 0 013.33 0zm8.325 0a1.665 1.665 0 11-3.33 0 1.665 1.665 0 013.33 0zm8.325 0a1.665 1.665 0 11-3.33 0 1.665 1.665 0 013.33 0z"></path></svg></div><div class="CommentContent css-1ygdre8">数据流向与请求/响应方是两个独立的维度。<br>数据从CPU到GPU，可以是CPU发起PCIe Write，也可以是GPU发起PCIe Read；数据从GPU到CPU，可以是CPU发起PCIe Read，也可以是GPU发起PCIe Write。<br>CPU发起的方式就是PCIe MMIO。</div><div class="css-dbby2p"><div class="css-82fsyv"><div class="css-12cl38p">2021-11-25</div></div><div class="css-18opwoy"><button type="button" class="Button  css-1o56bgb"><span style="display: inline-flex; align-items: center;">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" data-new-api="ChatBubbleFill24" data-old-api="ChatBubbleFill24" class="ZDI ZDI--ChatBubbleFill24 css-15ro776" fill="currentColor"><path d="M12 2.75a9.25 9.25 0 104.737 17.197l2.643.817a1 1 0 001.25-1.25l-.8-2.588A9.25 9.25 0 0012 2.75z" fill-rule="evenodd" clip-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button css-h1yvwn" style="transform: none;"><span style="display: inline-flex; align-items: center;">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" data-new-api="ThumbFill24" data-old-api="ThumbFill24" class="ZDI ZDI--ThumbFill24 css-15ro776" fill="currentColor"><path d="M8.5 4.078c0-1.834 1.986-2.979 3.573-2.06a4.826 4.826 0 012.379 4.71l-.114 1.022h3.581c2.53 0 4.334 2.454 3.58 4.868l-1.823 5.833a3.784 3.784 0 01-3.848 2.64c-2.372-.147-6.042-.341-8.828-.341H4.5A1.75 1.75 0 012.75 19V9.5c0-.967.784-1.75 1.75-1.75h.637a3.418 3.418 0 003.19-2.191c.115-.296.173-.611.173-.928v-.553z"></path></svg></span>赞</button></div></div></div></div></div></div><div><div class="css-194v73m"><div class="css-1jll2aj"><div class="Popover"><div id="Popover44-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover44-content"><a href="https://www.zhihu.com/people/60fb3b5af3fa65ec12618eafd60e1249" target="_blank" class="css-1d3mfcn"><img class="Avatar css-1qchsfe" src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/aaca4c6ac_l.jpg" srcset="https://pic1.zhimg.com/aaca4c6ac_l.jpg?source=06d4cd63 2x" alt="XTWeber" loading="lazy"></a></div></div></div><div class="css-14nvvry"><div class="css-1besdh8"><div class="css-dza3t2"><div class="css-1tww9qq"><div class="Popover"><div id="Popover45-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover45-content"><a href="https://www.zhihu.com/people/60fb3b5af3fa65ec12618eafd60e1249" target="_blank" class="css-o7lu8j">XTWeber</a></div></div></div></div><svg width="16" height="16" viewBox="0 0 24 24" data-new-api="Dots24" data-old-api="Dots24" class="ZDI ZDI--Dots24 css-1jofpfq" fill="currentColor"><path d="M5.34 12a1.665 1.665 0 11-3.33 0 1.665 1.665 0 013.33 0zm8.325 0a1.665 1.665 0 11-3.33 0 1.665 1.665 0 013.33 0zm8.325 0a1.665 1.665 0 11-3.33 0 1.665 1.665 0 013.33 0z"></path></svg></div><div class="CommentContent css-1ygdre8">感谢博主的干货，请问有ppt或者视频能分享下吗？谢谢</div><div class="css-dbby2p"><div class="css-82fsyv"><div class="css-12cl38p">2021-11-18</div></div><div class="css-18opwoy"><button type="button" class="Button  css-1o56bgb"><span style="display: inline-flex; align-items: center;">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" data-new-api="ChatBubbleFill24" data-old-api="ChatBubbleFill24" class="ZDI ZDI--ChatBubbleFill24 css-15ro776" fill="currentColor"><path d="M12 2.75a9.25 9.25 0 104.737 17.197l2.643.817a1 1 0 001.25-1.25l-.8-2.588A9.25 9.25 0 0012 2.75z" fill-rule="evenodd" clip-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button css-h1yvwn" style="transform: none;"><span style="display: inline-flex; align-items: center;">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" data-new-api="ThumbFill24" data-old-api="ThumbFill24" class="ZDI ZDI--ThumbFill24 css-15ro776" fill="currentColor"><path d="M8.5 4.078c0-1.834 1.986-2.979 3.573-2.06a4.826 4.826 0 012.379 4.71l-.114 1.022h3.581c2.53 0 4.334 2.454 3.58 4.868l-1.823 5.833a3.784 3.784 0 01-3.848 2.64c-2.372-.147-6.042-.341-8.828-.341H4.5A1.75 1.75 0 012.75 19V9.5c0-.967.784-1.75 1.75-1.75h.637a3.418 3.418 0 003.19-2.191c.115-.296.173-.611.173-.928v-.553z"></path></svg></span>赞</button></div></div></div></div><div><div class="css-8j5fyx"><div class="css-1jll2aj"><div class="Popover"><div id="Popover46-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover46-content"><a href="https://www.zhihu.com/people/a11db345259690383e290757d6b06009" target="_blank" class="css-1d3mfcn"><img class="Avatar css-1qchsfe" src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-0739292c687b2a49b3cdefb1842692a5_l.jpg" srcset="https://pic2.zhimg.com/v2-0739292c687b2a49b3cdefb1842692a5_l.jpg?source=06d4cd63 2x" alt="Dirty SONIC" loading="lazy"></a></div></div></div><div class="css-14nvvry"><div class="css-1besdh8"><div class="css-dza3t2"><div class="css-1tww9qq"><div class="Popover"><div id="Popover47-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover47-content"><a href="https://www.zhihu.com/people/a11db345259690383e290757d6b06009" target="_blank" class="css-o7lu8j">Dirty SONIC</a></div></div></div><svg width="12" height="12" viewBox="0 0 16 16" data-new-api="ArrowRightAlt16" data-old-api="ArrowRightAlt16" class="ZDI ZDI--ArrowRightAlt16 css-5hz1ob" fill="currentColor"><path d="M10.727 7.48a.63.63 0 010 1.039l-4.299 2.88c-.399.268-.926-.028-.926-.519V5.12c0-.491.527-.787.926-.52l4.299 2.881z"></path></svg><div class="css-1tww9qq"><div class="Popover"><div id="Popover48-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover48-content"><a href="https://www.zhihu.com/people/4b88b8fd34703b95cde7a736a85ec8cb" target="_blank" class="css-o7lu8j">函谷叨客</a></div></div></div></div><svg width="16" height="16" viewBox="0 0 24 24" data-new-api="Dots24" data-old-api="Dots24" class="ZDI ZDI--Dots24 css-1jofpfq" fill="currentColor"><path d="M5.34 12a1.665 1.665 0 11-3.33 0 1.665 1.665 0 013.33 0zm8.325 0a1.665 1.665 0 11-3.33 0 1.665 1.665 0 013.33 0zm8.325 0a1.665 1.665 0 11-3.33 0 1.665 1.665 0 013.33 0z"></path></svg></div><div class="CommentContent css-1ygdre8">受益匪浅，PPT能分享下吗？</div><div class="css-dbby2p"><div class="css-82fsyv"><div class="css-12cl38p">01-27</div></div><div class="css-18opwoy"><button type="button" class="Button  css-1o56bgb"><span style="display: inline-flex; align-items: center;">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" data-new-api="ChatBubbleFill24" data-old-api="ChatBubbleFill24" class="ZDI ZDI--ChatBubbleFill24 css-15ro776" fill="currentColor"><path d="M12 2.75a9.25 9.25 0 104.737 17.197l2.643.817a1 1 0 001.25-1.25l-.8-2.588A9.25 9.25 0 0012 2.75z" fill-rule="evenodd" clip-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button css-h1yvwn" style="transform: none;"><span style="display: inline-flex; align-items: center;">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" data-new-api="ThumbFill24" data-old-api="ThumbFill24" class="ZDI ZDI--ThumbFill24 css-15ro776" fill="currentColor"><path d="M8.5 4.078c0-1.834 1.986-2.979 3.573-2.06a4.826 4.826 0 012.379 4.71l-.114 1.022h3.581c2.53 0 4.334 2.454 3.58 4.868l-1.823 5.833a3.784 3.784 0 01-3.848 2.64c-2.372-.147-6.042-.341-8.828-.341H4.5A1.75 1.75 0 012.75 19V9.5c0-.967.784-1.75 1.75-1.75h.637a3.418 3.418 0 003.19-2.191c.115-.296.173-.611.173-.928v-.553z"></path></svg></span>赞</button></div></div></div></div></div><div><div class="css-8j5fyx"><div class="css-1jll2aj"><div class="Popover"><div id="Popover49-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover49-content"><a href="https://www.zhihu.com/people/38375b99a0d975f029a7cd2500dcac53" target="_blank" class="css-1d3mfcn"><img class="Avatar css-1qchsfe" src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-abed1a8c04700ba7d72b45195223e0ff_l(3).jpg" srcset="https://pic1.zhimg.com/v2-abed1a8c04700ba7d72b45195223e0ff_l.jpg?source=06d4cd63 2x" alt="小曼178" loading="lazy"></a></div></div></div><div class="css-14nvvry"><div class="css-1besdh8"><div class="css-dza3t2"><div class="css-1tww9qq"><div class="Popover"><div id="Popover50-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover50-content"><a href="https://www.zhihu.com/people/38375b99a0d975f029a7cd2500dcac53" target="_blank" class="css-o7lu8j">小曼178</a></div></div></div><svg width="12" height="12" viewBox="0 0 16 16" data-new-api="ArrowRightAlt16" data-old-api="ArrowRightAlt16" class="ZDI ZDI--ArrowRightAlt16 css-5hz1ob" fill="currentColor"><path d="M10.727 7.48a.63.63 0 010 1.039l-4.299 2.88c-.399.268-.926-.028-.926-.519V5.12c0-.491.527-.787.926-.52l4.299 2.881z"></path></svg><div class="css-1tww9qq"><div class="Popover"><div id="Popover51-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover51-content"><a href="https://www.zhihu.com/people/4b88b8fd34703b95cde7a736a85ec8cb" target="_blank" class="css-o7lu8j">函谷叨客</a></div></div></div></div><svg width="16" height="16" viewBox="0 0 24 24" data-new-api="Dots24" data-old-api="Dots24" class="ZDI ZDI--Dots24 css-1jofpfq" fill="currentColor"><path d="M5.34 12a1.665 1.665 0 11-3.33 0 1.665 1.665 0 013.33 0zm8.325 0a1.665 1.665 0 11-3.33 0 1.665 1.665 0 013.33 0zm8.325 0a1.665 1.665 0 11-3.33 0 1.665 1.665 0 013.33 0z"></path></svg></div><div class="CommentContent css-1ygdre8">谢谢博主的分享，请问是否可以分享ppt或视频呀？谢谢！</div><div class="css-dbby2p"><div class="css-82fsyv"><div class="css-12cl38p">2021-12-27</div></div><div class="css-18opwoy"><button type="button" class="Button  css-1o56bgb"><span style="display: inline-flex; align-items: center;">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" data-new-api="ChatBubbleFill24" data-old-api="ChatBubbleFill24" class="ZDI ZDI--ChatBubbleFill24 css-15ro776" fill="currentColor"><path d="M12 2.75a9.25 9.25 0 104.737 17.197l2.643.817a1 1 0 001.25-1.25l-.8-2.588A9.25 9.25 0 0012 2.75z" fill-rule="evenodd" clip-rule="evenodd"></path></svg></span>回复</button><button type="button" class="Button css-h1yvwn" style="transform: none;"><span style="display: inline-flex; align-items: center;">​<svg width="1.2em" height="1.2em" viewBox="0 0 24 24" data-new-api="ThumbFill24" data-old-api="ThumbFill24" class="ZDI ZDI--ThumbFill24 css-15ro776" fill="currentColor"><path d="M8.5 4.078c0-1.834 1.986-2.979 3.573-2.06a4.826 4.826 0 012.379 4.71l-.114 1.022h3.581c2.53 0 4.334 2.454 3.58 4.868l-1.823 5.833a3.784 3.784 0 01-3.848 2.64c-2.372-.147-6.042-.341-8.828-.341H4.5A1.75 1.75 0 012.75 19V9.5c0-.967.784-1.75 1.75-1.75h.637a3.418 3.418 0 003.19-2.191c.115-.296.173-.611.173-.928v-.553z"></path></svg></span>赞</button></div></div></div></div></div><button type="button" class="Button css-1p04wnp">展开其他 1 条回复<span style="display: inline-flex; align-items: center;">​<svg width="24" height="24" viewBox="0 0 24 24" data-new-api="ArrowRightSmall24" data-old-api="ArrowRightSmall24" class="ZDI ZDI--ArrowRightSmall24" fill="currentColor"><path d="M13.248 12l-4.025 3.78a.684.684 0 000 1.01.796.796 0 001.075 0l4.42-4.15a.867.867 0 000-1.28l-4.42-4.15a.796.796 0 00-1.075 0 .684.684 0 000 1.01L13.248 12z" fill-rule="evenodd" clip-rule="evenodd"></path></svg></span></button></div><div></div></div></div></div></div><div class="css-l8iyjs"></div><div class="css-805ti0" style="position: relative; box-shadow: 0px 0px;"><div><div class="css-59erns"><img class="Avatar css-1oi6kgx" src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-ef69d369588e9764f9252225e6dc29ce_l.jpg" srcset="https://pica.zhimg.com/v2-ef69d369588e9764f9252225e6dc29ce_l.jpg?source=32738c0c 2x"><div class="css-x0pxoz"><div class="css-i6bazn"><div class="css-1ryozpy"><div class="InputLike css-ip4bff Editable"><div class="Dropzone Editable-content RichText RichText--editable RichText--clearBoth ztext" style="min-height: 38px;"><div class="DraftEditor-root"><div class="public-DraftEditorPlaceholder-root"><div class="public-DraftEditorPlaceholder-inner" id="placeholder-7gat3" style="white-space: pre-wrap;">评论千万条，友善第一条</div></div><div class="DraftEditor-editorContainer"><div aria-describedby="placeholder-7gat3" class="notranslate public-DraftEditor-content" contenteditable="true" role="textbox" spellcheck="true" tabindex="0" style="outline: none; user-select: text; white-space: pre-wrap; overflow-wrap: break-word;"><div data-contents="true"><div class="Editable-unstyled" data-block="true" data-editor="7gat3" data-offset-key="2irca-0-0"><div data-offset-key="2irca-0-0" class="public-DraftStyleDefault-block public-DraftStyleDefault-ltr"><span data-offset-key="2irca-0-0"><br data-text="true"></span></div></div></div></div></div></div></div><div></div><input multiple="" type="file" accept="image/webp,image/jpg,image/jpeg,image/png,image/gif" style="display: none;"></div></div></div></div></div></div></div><div></div></div></div></div><div class="PostIndex-Contributions" data-za-detail-view-path-module="ColumnList" data-za-detail-view-path-module_name="文章被以下专栏收录" data-za-extra-module="{}"><h3 class="BlockTitle">文章被以下专栏收录</h3><ul><div class="ContentItem Column-ColumnItem"><div class="ContentItem-main"><div class="ContentItem-image"><a class="ColumnLink" href="https://www.zhihu.com/column/c_1440266400069345280"><div class="Popover"><div id="Popover7-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover7-content"><img class="Avatar Avatar--medium Avatar--round" width="40" height="40" src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/4b70deef7_xs.jpg" srcset="https://pica.zhimg.com/4b70deef7_l.jpg?source=172ae18b 2x" alt="高性能互连网络"></div></div></a></div><div class="ContentItem-head"><h2 class="ContentItem-title"><span><a class="ColumnLink ColumnItem-Title" href="https://www.zhihu.com/column/c_1440266400069345280"><div class="Popover"><div id="Popover8-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover8-content">高性能互连网络</div></div></a></span></h2><div class="ContentItem-meta">分享高性能互连网络的相关研究进展</div></div></div></div><div class="ContentItem Column-ColumnItem"><div class="ContentItem-main"><div class="ContentItem-image"><a class="ColumnLink" href="https://www.zhihu.com/column/c_1409084119363641344"><div class="Popover"><div id="Popover9-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover9-content"><img class="Avatar Avatar--medium Avatar--round" width="40" height="40" src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/4b70deef7_xs(1).jpg" srcset="https://picx.zhimg.com/4b70deef7_l.jpg?source=172ae18b 2x" alt="消化AI 慧维智能"></div></div></a></div><div class="ContentItem-head"><h2 class="ContentItem-title"><span><a class="ColumnLink ColumnItem-Title" href="https://www.zhihu.com/column/c_1409084119363641344"><div class="Popover"><div id="Popover10-toggle" aria-haspopup="true" aria-expanded="false" aria-owns="Popover10-content">消化AI 慧维智能</div></div></a></span></h2><div class="ContentItem-meta">致力于帮助医生提高诊疗水平与效率，提高检出率。</div></div></div></div></ul></div><div role="complementary" aria-label="推荐阅读" class="Recommendations-Main" style="width: 1581px;"><h3 class="BlockTitle Recommendations-BlockTitle">推荐阅读</h3><ul class="Recommendations-List"><button class="PagingButton PagingButton-Previous" disabled="" data-za-detail-view-path-module="Unknown" data-za-detail-view-path-module_name="推荐阅读" data-za-extra-module="{}"><svg width="40" height="40" viewBox="0 0 24 24" data-new-api="ArrowLeftSmall24" data-old-api="ArrowLeft" fill="#d3d3d3" class="Zi Zi--ArrowLeft"><path d="M10.752 12l4.025-3.78a.684.684 0 000-1.01.796.796 0 00-1.075 0l-4.42 4.15a.866.866 0 000 1.28l4.42 4.15a.796.796 0 001.075 0 .684.684 0 000-1.01L10.752 12z" fill-rule="evenodd" clip-rule="evenodd"></path></svg></button><a href="https://zhuanlan.zhihu.com/p/77804555" class="PostItem"><div><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-dc4341d3ffb2091d8de65f16bd143dde_250x0.jpg" srcset="https://pic1.zhimg.com/v2-dc4341d3ffb2091d8de65f16bd143dde_qhd.jpg?source=172ae18b 2x" class="PostItem-TitleImage" alt="绕过CPU，英伟达让GPU直连存储设备"><h1 class="PostItem-Title">绕过CPU，英伟达让GPU直连存储设备</h1><div class="PostItem-Footer"><span>奉孝翼德</span><span class="PostItem-FooterTitle">发表于云体验师</span></div></div></a><a href="https://zhuanlan.zhihu.com/p/24072384" class="PostItem"><div><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-8cb849323b93db3a6a473909afad365d_250x0.jpg" srcset="https://pic1.zhimg.com/v2-8cb849323b93db3a6a473909afad365d_qhd.jpg?source=172ae18b 2x" class="PostItem-TitleImage" alt="GPU,FPGA,还是ASIC? 浅谈深度学习计算的硬件选型"><h1 class="PostItem-Title">GPU,FPGA,还是ASIC? 浅谈深度学习计算的硬件选型</h1><div class="PostItem-Footer"><span>王天树</span><span class="PostItem-FooterTitle">发表于直升飞球</span></div></div></a><a href="https://zhuanlan.zhihu.com/p/135914241" class="PostItem"><div><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-db951c8ef9d33a2353f90c378ee6151d_250x0.jpg" srcset="https://picx.zhimg.com/v2-db951c8ef9d33a2353f90c378ee6151d_qhd.jpg?source=172ae18b 2x" class="PostItem-TitleImage" alt="Tensorflow笔记：分布式训练"><h1 class="PostItem-Title">Tensorflow笔记：分布式训练</h1><div class="PostItem-Footer"><span>锟斤拷</span><span class="PostItem-FooterTitle"></span></div></div></a><a href="https://zhuanlan.zhihu.com/p/347353435" class="PostItem"><div><img src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/v2-7da1ae5face698a66f72911b55a9d169_250x0.jpg" srcset="https://pic3.zhimg.com/v2-7da1ae5face698a66f72911b55a9d169_qhd.jpg?source=172ae18b 2x" class="PostItem-TitleImage" alt="GPU前沿：NVLink与PCIe的对比学习"><h1 class="PostItem-Title">GPU前沿：NVLink与PCIe的对比学习</h1><div class="PostItem-Footer"><span>Pinging</span><span class="PostItem-FooterTitle"></span></div></div></a><button class="PagingButton PagingButton-Next" data-za-detail-view-path-module="Unknown" data-za-detail-view-path-module_name="推荐阅读" data-za-extra-module="{}"><svg width="40" height="40" viewBox="0 0 24 24" data-new-api="ArrowRightSmall24" data-old-api="ArrowRight" fill="#d3d3d3" class="Zi Zi--ArrowRight"><path d="M13.248 12l-4.025 3.78a.684.684 0 000 1.01.796.796 0 001.075 0l4.42-4.15a.867.867 0 000-1.28l-4.42-4.15a.796.796 0 00-1.075 0 .684.684 0 000 1.01L13.248 12z" fill-rule="evenodd" clip-rule="evenodd"></path></svg></button></ul></div></div></div></main><div role="complementary"><div class="CornerButtons"><div class="CornerAnimayedFlex"><button data-tooltip="回到顶部" data-tooltip-position="left" data-tooltip-will-hide-on-click="true" aria-label="回到顶部" type="button" class="Button CornerButton Button--plain"><svg width="24" height="24" viewBox="0 0 24 24" data-new-api="ArrowShapeUpwardFill24" data-old-api="BackToTop" aria-label="回到顶部" class="Zi Zi--BackToTop" fill="currentColor"><path d="M13.204 3.107a1.75 1.75 0 00-2.408 0L3.806 9.73c-1.148 1.088-.378 3.02 1.204 3.02h2.24V20c0 .966.784 1.75 1.75 1.75h6A1.75 1.75 0 0016.75 20v-7.25h2.24c1.582 0 2.353-1.932 1.204-3.02l-6.99-6.623z" fill-rule="evenodd" clip-rule="evenodd"></path></svg></button></div></div></div></div></div><script id="js-clientConfig" type="text/json">{"fetchRoot":{"www":"https:\u002F\u002Fwww.zhihu.com","api":"https:\u002F\u002Fapi.zhihu.com","lens":"https:\u002F\u002Flens.zhihu.com","zhuanlan":"https:\u002F\u002Fzhuanlan.zhihu.com","walletpay":"https:\u002F\u002Fwalletpay.zhihu.com","captcha":"https:\u002F\u002Fcaptcha.zhihu.com","vzuu":"https:\u002F\u002Fv.vzuu.com","openapi":"https:\u002F\u002Fopenapi.zhihu.com","svip":"https:\u002F\u002Fsvip.zhihu.com"},"host":"zhihu.com","protocol":"https:","wwwHost":"www.zhihu.com","videoHost":"video.zhihu.com","allowSignUp":true}</script><script id="js-initialData" type="text/json">{"initialState":{"common":{"ask":{}},"loading":{"global":{"count":0},"local":{"env\u002FgetIpinfo\u002F":false,"article\u002Fget\u002F":false,"brand\u002FgetUrl\u002F":false,"article\u002FloadPostSearchEntity\u002F":false}},"club":{"tags":{},"admins":{"data":[]},"members":{"data":[]},"profile":{},"checkin":{},"comments":{"paging":{},"loading":{},"meta":{},"ids":{}},"postList":{"paging":{},"loading":{},"ids":{}},"recommend":{"data":[]},"silences":{"data":[]},"application":{"profile":null}},"entities":{"users":{"9b939bd116cd066ce372288d50538da8":{"uid":1437579071195046000,"userType":"people","id":"9b939bd116cd066ce372288d50538da8"},"han-gu-tao-ke":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-8966d1ab2d8ee8980d116f4d746ce456.jpg?source=172ae18b","uid":"1178294224352632832","userType":"people","isFollowing":false,"urlToken":"han-gu-tao-ke","id":"4b88b8fd34703b95cde7a736a85ec8cb","description":"一心筑函谷","name":"函谷叨客","isAdvertiser":false,"headline":"从事高性能互连网络研究","gender":1,"url":"\u002Fpeople\u002F4b88b8fd34703b95cde7a736a85ec8cb","avatarUrl":"https:\u002F\u002Fpica.zhimg.com\u002Fv2-8966d1ab2d8ee8980d116f4d746ce456_l.jpg?source=172ae18b","isOrg":false,"type":"people","badge":[],"badgeV2":{"title":"","mergedBadges":[],"detailBadges":[],"icon":"","nightIcon":""},"exposedMedal":{"medalId":"972465637922213888","medalName":"给自己证明","avatarUrl":"https:\u002F\u002Fpicx.zhimg.com\u002Fv2-1607ab617c9cbaf0c75cb00d0c42292c_r.png?source=172ae18b","miniAvatarUrl":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-1607ab617c9cbaf0c75cb00d0c42292c_l.png?source=172ae18b","description":"已完善全部个人资料","medalAvatarFrame":""}}},"questions":{},"answers":{},"articles":{"430101220":{"trackUrl":["https:\u002F\u002Fsugar.zhihu.com\u002Fplutus_adreaper\u002Fcontent_monitor_log?si=__SESSIONID__&ti=__ATOKEN__&at=view&pf=__OS__&ed=BiBUKF0xBSkqGGpRA2R6CFx1ClFNgfJERpdg&idfa=__IDFA__&imei=__IMEI__&androidid=__ANDROIDID__&oaid=__OAID__&ci=__CREATIVEID__&zid=__ZONEID__"],"entityWords":[{"name":"netmap","mention":"netmap","matchorder":1,"begin":45625,"end":45631,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"Commodity","score":0,"attachedInfoBytes":"sgJVCgZuZXRtYXASCUNvbW1vZGl0eRi55AIgv+QCKAE1AAAAADoHYXJ0aWNsZUAASABSJDcyOGM4OGI4LWVkMTktNDJhNC04MjdiLTgzZWI5YzUyMDZlMQ==","isOnAB":false,"isNatural":1},{"name":"循环神经网络","mention":"循环神经网络","matchorder":1,"begin":44167,"end":44173,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"OtherTerm","score":0,"attachedInfoBytes":"sgJhChLlvqrnjq\u002FnpZ7nu4\u002FnvZHnu5wSCU90aGVyVGVybRiH2QIgjdkCKAE1AAAAADoHYXJ0aWNsZUAASABSJDcyOGM4OGI4LWVkMTktNDJhNC04MjdiLTgzZWI5YzUyMDZlMQ==","isOnAB":false,"isNatural":1},{"name":"锁页内存","mention":"锁页内存","matchorder":1,"begin":3016,"end":3020,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"Computer","score":0,"attachedInfoBytes":"sgJYCgzplIHpobXlhoXlrZgSCENvbXB1dGVyGMgXIMwXKAE1AAAAADoHYXJ0aWNsZUAASABSJDcyOGM4OGI4LWVkMTktNDJhNC04MjdiLTgzZWI5YzUyMDZlMQ==","isOnAB":false,"isNatural":1},{"name":"缺页异常","mention":"缺页异常","matchorder":2,"begin":8160,"end":8164,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"Computer","score":0,"attachedInfoBytes":"sgJYCgznvLrpobXlvILluLgSCENvbXB1dGVyGOA\u002FIOQ\u002FKAI1AAAAADoHYXJ0aWNsZUAASABSJDcyOGM4OGI4LWVkMTktNDJhNC04MjdiLTgzZWI5YzUyMDZlMQ==","isOnAB":false,"isNatural":1},{"name":"零拷贝","mention":"零拷贝","matchorder":2,"begin":3021,"end":3024,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"OtherTerm","score":0,"attachedInfoBytes":"sgJWCgnpm7bmi7fotJ0SCU90aGVyVGVybRjNFyDQFygCNQAAAAA6B2FydGljbGVAAEgAUiQ3MjhjODhiOC1lZDE5LTQyYTQtODI3Yi04M2ViOWM1MjA2ZTE=","isOnAB":false,"isNatural":1},{"name":"控制通信","mention":"控制通信","matchorder":4,"begin":13990,"end":13994,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"Computer","score":0,"attachedInfoBytes":"sgJYCgzmjqfliLbpgJrkv6ESCENvbXB1dGVyGKZtIKptKAQ1AAAAADoHYXJ0aWNsZUAASABSJDcyOGM4OGI4LWVkMTktNDJhNC04MjdiLTgzZWI5YzUyMDZlMQ==","isOnAB":false,"isNatural":1},{"name":"batch size","mention":"batch size","matchorder":1,"begin":47654,"end":47664,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"Math","score":0,"attachedInfoBytes":"sgJUCgpiYXRjaCBzaXplEgRNYXRoGKb0AiCw9AIoATUAAAAAOgdhcnRpY2xlQABIAFIkNzI4Yzg4YjgtZWQxOS00MmE0LTgyN2ItODNlYjljNTIwNmUx","isOnAB":false,"isNatural":1},{"name":"微基准测试","mention":"微基准测试","matchorder":2,"begin":43408,"end":43413,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"OtherTerm","score":0,"attachedInfoBytes":"sgJeCg\u002Flvq7ln7rlh4bmtYvor5USCU90aGVyVGVybRiQ0wIgldMCKAI1AAAAADoHYXJ0aWNsZUAASABSJDcyOGM4OGI4LWVkMTktNDJhNC04MjdiLTgzZWI5YzUyMDZlMQ==","isOnAB":false,"isNatural":1},{"name":"注册函数","mention":"注册函数","matchorder":1,"begin":18690,"end":18694,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"Math","score":0,"attachedInfoBytes":"sgJWCgzms6jlhozlh73mlbASBE1hdGgYgpIBIIaSASgBNQAAAAA6B2FydGljbGVAAEgAUiQ3MjhjODhiOC1lZDE5LTQyYTQtODI3Yi04M2ViOWM1MjA2ZTE=","isOnAB":false,"isNatural":1},{"name":"interconnect","mention":"interconnect","matchorder":1,"begin":53352,"end":53364,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"Novel","score":0,"attachedInfoBytes":"sgJXCgxpbnRlcmNvbm5lY3QSBU5vdmVsGOigAyD0oAMoATUAAAAAOgdhcnRpY2xlQABIAFIkNzI4Yzg4YjgtZWQxOS00MmE0LTgyN2ItODNlYjljNTIwNmUx","isOnAB":false,"isNatural":1},{"name":"拷贝函数","mention":"拷贝函数","matchorder":1,"begin":4832,"end":4836,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"Math","score":0,"attachedInfoBytes":"sgJUCgzmi7fotJ3lh73mlbASBE1hdGgY4CUg5CUoATUAAAAAOgdhcnRpY2xlQABIAFIkNzI4Yzg4YjgtZWQxOS00MmE0LTgyN2ItODNlYjljNTIwNmUx","isOnAB":false,"isNatural":1},{"name":"pinned memory","mention":"pinned memory","matchorder":1,"begin":39301,"end":39314,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"OtherTerm","score":0,"attachedInfoBytes":"sgJcCg1waW5uZWQgbWVtb3J5EglPdGhlclRlcm0YhbMCIJKzAigBNQAAAAA6B2FydGljbGVAAEgAUiQ3MjhjODhiOC1lZDE5LTQyYTQtODI3Yi04M2ViOWM1MjA2ZTE=","isOnAB":false,"isNatural":1},{"name":"虚拟地址空间","mention":"虚拟地址空间","matchorder":1,"begin":4447,"end":4453,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"Computer","score":0,"attachedInfoBytes":"sgJeChLomZrmi5\u002FlnLDlnYDnqbrpl7QSCENvbXB1dGVyGN8iIOUiKAE1AAAAADoHYXJ0aWNsZUAASABSJDcyOGM4OGI4LWVkMTktNDJhNC04MjdiLTgzZWI5YzUyMDZlMQ==","isOnAB":false,"isNatural":1},{"name":"sysbench","mention":"sysbench","matchorder":1,"begin":44131,"end":44139,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"OtherTerm","score":0,"attachedInfoBytes":"sgJXCghzeXNiZW5jaBIJT3RoZXJUZXJtGOPYAiDr2AIoATUAAAAAOgdhcnRpY2xlQABIAFIkNzI4Yzg4YjgtZWQxOS00MmE0LTgyN2ItODNlYjljNTIwNmUx","isOnAB":false,"isNatural":1},{"name":"pin memory","mention":"pin memory","matchorder":1,"begin":17171,"end":17181,"entityid":0,"isBookMark":false,"link":{"linkType":0,"linkUrl":"","docType":"","topicToken":""},"entityClass":"OtherTerm","score":0,"attachedInfoBytes":"sgJZCgpwaW4gbWVtb3J5EglPdGhlclRlcm0Yk4YBIJ2GASgBNQAAAAA6B2FydGljbGVAAEgAUiQ3MjhjODhiOC1lZDE5LTQyYTQtODI3Yi04M2ViOWM1MjA2ZTE=","isOnAB":false,"isNatural":1}],"id":430101220,"title":"【研究综述】浅谈GPU通信和PCIe P2P DMA","type":"article","articleType":"normal","excerptTitle":"","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F430101220","imageUrl":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-89ea4d6acbeca045b1983fd8c082e497_720w.jpg?source=172ae18b","titleImage":"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-89ea4d6acbeca045b1983fd8c082e497_720w.jpg?source=172ae18b","excerpt":"\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-bdc1b256bfd70c104bb9bd25ba18c33d_200x112.png\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" data-watermark=\"watermark\" data-original-src=\"v2-bdc1b256bfd70c104bb9bd25ba18c33d\" data-watermark-src=\"v2-589c2e8cc43934697166b6edc599b82d\" data-private-watermark-src=\"\" class=\"origin_image inline-img zh-lightbox-thumb\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-bdc1b256bfd70c104bb9bd25ba18c33d_r.png\"\u002F\u003E目前网络通信已经成为分布式机器学习的性能瓶颈。本文将讨论GPU通信和PCIe P2P DMA技术，为大规模分布式应用通信性能的优化提供参考。本文将依次回答如下三个问题，并探讨今后IO设备互连该走向什么方向。 为了回答上述问题，本文将分为四个部分展开。首先，…","created":1636169398,"updated":1636448219,"author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-8966d1ab2d8ee8980d116f4d746ce456.jpg?source=172ae18b","uid":"1178294224352632832","userType":"people","isFollowing":false,"urlToken":"han-gu-tao-ke","id":"4b88b8fd34703b95cde7a736a85ec8cb","description":"一心筑函谷","name":"函谷叨客","isAdvertiser":false,"headline":"从事高性能互连网络研究","gender":1,"url":"\u002Fpeople\u002F4b88b8fd34703b95cde7a736a85ec8cb","avatarUrl":"https:\u002F\u002Fpica.zhimg.com\u002Fv2-8966d1ab2d8ee8980d116f4d746ce456_l.jpg?source=172ae18b","isOrg":false,"type":"people","badge":[],"badgeV2":{"title":"","mergedBadges":[],"detailBadges":[],"icon":"","nightIcon":""},"exposedMedal":{"medalId":"972465637922213888","medalName":"给自己证明","avatarUrl":"https:\u002F\u002Fpicx.zhimg.com\u002Fv2-1607ab617c9cbaf0c75cb00d0c42292c_r.png?source=172ae18b","miniAvatarUrl":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-1607ab617c9cbaf0c75cb00d0c42292c_l.png?source=172ae18b","description":"已完善全部个人资料","medalAvatarFrame":""}},"commentPermission":"all","copyrightPermission":"public","state":"published","ipInfo":"","imageWidth":850,"imageHeight":476,"content":"\u003Cp data-pid=\"cCwojx_b\"\u003E目前网络通信已经成为分布式机器学习的性能瓶颈。本文将讨论GPU通信和PCIe P2P DMA技术，为大规模分布式应用通信性能的优化提供参考。本文将依次回答如下三个问题，并探讨今后IO设备互连该走向什么方向。\u003C\u002Fp\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-589c2e8cc43934697166b6edc599b82d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-589c2e8cc43934697166b6edc599b82d_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-589c2e8cc43934697166b6edc599b82d_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-589c2e8cc43934697166b6edc599b82d_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"ZVV_xR1G\"\u003E为了回答上述问题，本文将分为四个部分展开。首先，简要介绍GPU的基本架构和GPU内存管理技术的演进与发展；重点讨论GPUDirect技术的演进，技术细节和其性能评测；之后，更一般地，我们在第三部分讨论不同GPU互连架构下，通信性能的特征和差异；最后，我们对现有设备通信进行扩展，讨论通用P2P技术的演进。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-36dd894509c45bf41fae7b37de6667c6_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-36dd894509c45bf41fae7b37de6667c6_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-36dd894509c45bf41fae7b37de6667c6_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-36dd894509c45bf41fae7b37de6667c6_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"hO7qE6lQ\"\u003E首先是第一部分内容，我将简要介绍GPU内存管理方式的演进。这部分内容主要参考了[1-6]。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-8793cdc626e9547ecea374e95786185e_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-8793cdc626e9547ecea374e95786185e_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-8793cdc626e9547ecea374e95786185e_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-8793cdc626e9547ecea374e95786185e_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"GpUY75l8\"\u003E这张图是开普勒GPU架构图。其中，HSHUB（High Speed HUB）完成GPU与CPU之间的数据交换，所有的存储器件接入一个交叉开关。计算核心被划分为不同的SM（Stream Multi-Processor）。每个SM包含数十至数百个计算核心，共享SM中的存储资源。其中，共享内存部分被用作scratchpad，这部分存储资源需要用户进行显式管理，RO Cache用于存放一些常量数据。与CPU不同的地方在于，L1 Cache和L2 Cache之间不维护一致性。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-e98f24bee6a58d50cbec7f7207859b79_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-e98f24bee6a58d50cbec7f7207859b79_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-e98f24bee6a58d50cbec7f7207859b79_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-e98f24bee6a58d50cbec7f7207859b79_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"qXTSpfD6\"\u003E从用户编程角度而言，在使用存储资源时看到的就是CPU指针和GPU指针。对GPU内存的使用经历了三个阶段，第一个阶段是分离内存管理，GPU上运行的Kernel代码不能直接访问CPU内存，在载入Kernel之前或Kernel执行结束之后必须进行显式的拷贝操作；第二个阶段是半分离内存管理，Kernel代码能够直接用指针寻址到整个系统中的内存资源；第三个阶段是分离内存管理，CPU还是GPU上的代码都可以使用指针直接访问到系统中的任意内存资源。对于用户而言，第三个阶段看起来只是提供了一个语法糖，但在底层硬件实现上两者有着显著的差异。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-24b88a78a9e8ce22757edbe1db286e78_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-24b88a78a9e8ce22757edbe1db286e78_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-24b88a78a9e8ce22757edbe1db286e78_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-24b88a78a9e8ce22757edbe1db286e78_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"rjUMOlHo\"\u003E接下来我将分别详细介绍三种不同内存管理方式的区别以及部分实现细节。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-ddbbc1b0223a88d4fa08ed67f4b74803_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-ddbbc1b0223a88d4fa08ed67f4b74803_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-ddbbc1b0223a88d4fa08ed67f4b74803_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-ddbbc1b0223a88d4fa08ed67f4b74803_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"tg5-3pKG\"\u003E对于分离内存管理，其又可以分为两种，即锁页内存和零拷贝内存。在最原始的方式下，从主机内存拷贝数据到GPU，首先操作系统会分配一块用于数据中转的临时锁页内存，然后将用户缓冲区中的数据拷贝到锁页内存中，再通过PCIe DMA拷贝到GPU显存中。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-e4b7c3482e384deaa755c8242fe4d9b9_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-e4b7c3482e384deaa755c8242fe4d9b9_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-e4b7c3482e384deaa755c8242fe4d9b9_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-e4b7c3482e384deaa755c8242fe4d9b9_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"gewyy_0J\"\u003E而对于锁页内存，首先分配内存的API发生了变化，而且分配的区域将直接成为锁页内存区域，在向GPU显存进行拷贝时只需要进行一次PCIe DMA操作即可。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-a585bf939aa55a4190abef7eeaacc08a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-a585bf939aa55a4190abef7eeaacc08a_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-a585bf939aa55a4190abef7eeaacc08a_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-a585bf939aa55a4190abef7eeaacc08a_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"3a-5FrIh\"\u003E进一步的，刚才看到GPU要使用CPU的数据是需要通过CudaMemcpy进行显式拷贝操作的，这种方式适合大批量的数据传递。如果只是想更新某个标志位，可以使用零拷贝内存。所谓零拷贝，就是GPU寄存器堆直接与主机内存交互。从代码里可以看到，将主机内存指针进行映射后，Kernel就可以直接使用指针来访问主机内存了，读取的数据会直接写入寄存器中。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-a0b4218635498b8ddeebe87da3c252e1_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-a0b4218635498b8ddeebe87da3c252e1_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-a0b4218635498b8ddeebe87da3c252e1_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-a0b4218635498b8ddeebe87da3c252e1_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"mt1WBDiq\"\u003E在分离内存管理的基础上，Nvidia推出了半分分离内存管理，也就是统一虚拟地址空间。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-4861e9ef304168561d100b2138505c0a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-4861e9ef304168561d100b2138505c0a_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-4861e9ef304168561d100b2138505c0a_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-4861e9ef304168561d100b2138505c0a_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"JE3iy8pu\"\u003E对于半分离内存管理，实际上也是语法糖，将原有的四个方向的拷贝函数合成了一个，用户调用统一的拷贝函数，由Cuda Runtime来判定数据源和目标所在的物理地址。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-e8fd6a2599ed019fa6671358c7be28ea_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-e8fd6a2599ed019fa6671358c7be28ea_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-e8fd6a2599ed019fa6671358c7be28ea_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-e8fd6a2599ed019fa6671358c7be28ea_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"j1q1GLYQ\"\u003E在UVA之后，Nvidia又创造性地提出了Unified Memory统一内存管理机制。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-fa48a328cec51cd0a86e03496a81ebe8_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-fa48a328cec51cd0a86e03496a81ebe8_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-fa48a328cec51cd0a86e03496a81ebe8_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-fa48a328cec51cd0a86e03496a81ebe8_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"DCCIKOH-\"\u003EUnified Memory在Unified Virtual Address的基础上更进一步，将系统内的所有内存资源都整合到相同的虚拟地址空间中。不管是CPU还是GPU代码，不用再区分其指针指向的空间，这给用户编程提供了极大的便利性。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2916c9b3c950d24383ad9c21226e16ff_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2916c9b3c950d24383ad9c21226e16ff_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2916c9b3c950d24383ad9c21226e16ff_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-2916c9b3c950d24383ad9c21226e16ff_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"BcoyBtY0\"\u003E我们看两个例子，代码功能是在CPU上分配一段数据，CPU进行运算，将结果拷贝到GPU上运算，GPU运算结束再拷贝到CPU中，CPU再继续运算。如果使用Unified Memory，在分配完数据后，不需要进行显式数据拷贝，直接调用相关函数对其进行处理即可，在GPU处理完后需要执行一次同步。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-38c832c1b77f1014e21502e567214999_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-38c832c1b77f1014e21502e567214999_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-38c832c1b77f1014e21502e567214999_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-38c832c1b77f1014e21502e567214999_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"G_6M4PNS\"\u003E上面例子的优势还不明显，我们再看下一个例子。这是一个深拷贝操作，CPU分配一个二维数组，显式拷贝时，要对二维数组进行逐行拷贝。但使用Unified Memory，Kernel就可以直接对数据进行操作。到这里我们看到了UM作为语法糖发挥的一些作用，看起来与UVA好像区别不大，都是GPU虚拟地址直接访问主机内存空间。但对于UVA，GPU访问主存是直接将数据搬到寄存器里的，不经过其显存，这也就意味着每次访问都至少要经过一次PCIe操作。UM在底层硬件实现上机制完全不同。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-83387ccd2d522f8e6a0929ca2b070f2a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-83387ccd2d522f8e6a0929ca2b070f2a_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-83387ccd2d522f8e6a0929ca2b070f2a_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-83387ccd2d522f8e6a0929ca2b070f2a_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"eAc9M0wt\"\u003E实际上，直到Pascal架构才算真正有了对UM的硬件上的支持。在Pascal架构之前，Kepler和Maxwell仅仅还是沿用了前面讲的CPU数据搬移到GPU寄存器中，只是在CUDA Runtime中提供了对地址的判断。而在Pascal架构上，实现了对物理内存页的按需迁移，GPU和CPU的并发访问，内存超额配置等，以及在Volta架构上又进一步实现了访问计数器，GPU和CPU的Cache一致性等新特性。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-75718b57afa47b9155cb1e1b7f170d88_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-75718b57afa47b9155cb1e1b7f170d88_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-75718b57afa47b9155cb1e1b7f170d88_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-75718b57afa47b9155cb1e1b7f170d88_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"imLxeAc4\"\u003E我们首先来看在Pascal架构之前UM的硬件工作方式。这段代码首先分配GPU显存，这时GPU的MMU会分配一段物理内存，然后构造页表项。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-14ba6af8c4ade02f50af4660a0b61f61_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-14ba6af8c4ade02f50af4660a0b61f61_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-14ba6af8c4ade02f50af4660a0b61f61_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-14ba6af8c4ade02f50af4660a0b61f61_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"DDQf9cSg\"\u003E当CPU指针访问这段显存时，发生缺页异常，进行物理页迁移，将GPU的物理页迁移到CPU内存中，此时GPU的页表会进行释放。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-66af9d18ba43452a91abbf103e72fef2_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-66af9d18ba43452a91abbf103e72fef2_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-66af9d18ba43452a91abbf103e72fef2_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-66af9d18ba43452a91abbf103e72fef2_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"a7rXO8p8\"\u003E而当Kernel使用该地址时，会再次构造GPU页表项，将CPU内存页迁移到GPU上。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-e3af1d452635383cfde04ab41c286603_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-e3af1d452635383cfde04ab41c286603_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-e3af1d452635383cfde04ab41c286603_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-e3af1d452635383cfde04ab41c286603_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"KgWdfSBT\"\u003E在这种方式下，UM不能支持内存超额配置，也就是申请的内存数量不能超过GPU显存总量。同时也不支持按需页迁移，例如当GPU显存已经塞满时，如果要访问CPU内存，数据会直接进入GPU寄存器，而不会对显存进行置换，如果频繁访问CPU内存就会带来较大的开销。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-6d7a56696bd7674e374982fb42b6f110_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-6d7a56696bd7674e374982fb42b6f110_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-6d7a56696bd7674e374982fb42b6f110_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-6d7a56696bd7674e374982fb42b6f110_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"59F8X0g1\"\u003E在Pascal之后的架构对GPU缺页异常提供了支持，在分配GPU内存时，只是分配了一个页表项，没有进行实际的显存分配。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-f0a6dfa3ed5125495af6a899ba6941b5_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-f0a6dfa3ed5125495af6a899ba6941b5_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-f0a6dfa3ed5125495af6a899ba6941b5_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-f0a6dfa3ed5125495af6a899ba6941b5_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"HAlAq59d\"\u003E当CPU代码访问内存时，发生缺页异常，分配CPU物理内存页，创建CPU页表项。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-9e91c0c5f25c106171d8b7fa777eb828_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-9e91c0c5f25c106171d8b7fa777eb828_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-9e91c0c5f25c106171d8b7fa777eb828_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-9e91c0c5f25c106171d8b7fa777eb828_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"e5OR3Frz\"\u003E当GPU代码访问时，发生GPU缺页异常，CPU内存页通过PCIe被迁移到GPU显存中。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-08d458e9bc08f345b500d72e22b4fa06_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-08d458e9bc08f345b500d72e22b4fa06_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-08d458e9bc08f345b500d72e22b4fa06_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-08d458e9bc08f345b500d72e22b4fa06_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"Rj2OXwAW\"\u003E接下来我们看Pascal架构是怎么支持内存超额配置和按需页迁移的。在当前状态下，对于GPU和CPU虚拟地址空间，Page 1到Page 4指向了GPU显存，Page 5指向了CPU内存。当GPU访问Page 5时，发现GPU页表为空，出现缺页异常。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-0388efda4af62df909dd22689c097840_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-0388efda4af62df909dd22689c097840_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-0388efda4af62df909dd22689c097840_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-0388efda4af62df909dd22689c097840_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"sOninmU7\"\u003E此时，GPU的MMU会在显存中选择一个物理页面迁移到CPU主存中，这里是Page 4，然后在CPU页表中建立Page 4到物理页面的映射。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-48da64f02c0e01d5295880f4bbd37b57_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-48da64f02c0e01d5295880f4bbd37b57_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-48da64f02c0e01d5295880f4bbd37b57_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-48da64f02c0e01d5295880f4bbd37b57_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"NXQxwGPN\"\u003E同时，CPU主存中的Page 5被迁移到GPU显存中，建立Page 5到物理页面的映射。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-4a4646df1874ce6badcb5df1a40e85ba_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-4a4646df1874ce6badcb5df1a40e85ba_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-4a4646df1874ce6badcb5df1a40e85ba_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-4a4646df1874ce6badcb5df1a40e85ba_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"limLhLn-\"\u003E完成整个缺页异常的处理流程。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-93fd4821eea953288bf050c0c893dc79_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-93fd4821eea953288bf050c0c893dc79_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-93fd4821eea953288bf050c0c893dc79_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-93fd4821eea953288bf050c0c893dc79_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"FuOOX956\"\u003E上述示例只是给出了基本的按需页迁移的过程。UM还涉及到很多相关问题，比如Cache一致性问题，CPU和GPU对同一个数据的多次并发读写，导致页面来回迁移的问题等，以及冷热页面的替换算法问题等。Power系列对UM特性的支持更完备，一个主要原因是其支持GPU和Power 9直接通过NVLink进行互连，后面在Summit和SummitDev的评测中我们可以看到这种架构。需要注意的是，UM本质上还是一种语法糖，这些特性的支持也只是为了尽可能提升语法糖的性能。由于这部分内容本身不是今天讨论的重点，所以点到为止。更详细的性能测评数据可以看相关参考文献。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-aa63c420adbbd77e34ade8d943819126_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-aa63c420adbbd77e34ade8d943819126_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-aa63c420adbbd77e34ade8d943819126_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-aa63c420adbbd77e34ade8d943819126_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"HaEx2N5G\"\u003E接下来是本文讨论的重点内容，GPUDirect技术的介绍。首先我会介绍GPUDirect技术是如何演进的，然后我会重点讨论GPUDirect技术的实现细节，最后给出GPUDirect技术的详细评测结果。这部分内容主要参考了[7-9]。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-93515c2d0ac2f808636492d10e29a6af_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-93515c2d0ac2f808636492d10e29a6af_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-93515c2d0ac2f808636492d10e29a6af_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-93515c2d0ac2f808636492d10e29a6af_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"nfWQ6Cpw\"\u003E在介绍GPUDirect技术之前，我们不妨回顾一下GPU通信的过程。通常可以将其粗略地划分为CPU控制的GPU通信和GPU控制的GPU通信。在第一种情况下，GPU运算完成后，将数据同步给CPU，由CPU执行MPI通信。按照算法设计，GPU可以等待CPU通信完成后继续执行运算，或者在通信过程中就开始继续运算。不管哪种方式，整个过程中，一定要由CPU进行通信的控制以及与计算过程的同步，这就必然引起PCIe的通信开销。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-3b969d398d63df3ce133115c486279f2_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-3b969d398d63df3ce133115c486279f2_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-3b969d398d63df3ce133115c486279f2_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-3b969d398d63df3ce133115c486279f2_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"0HDZ9K48\"\u003E而对于GPU控制的通信而言，整个执行流程中CPU都会旁路，GPU独立发起通信，并和网络设备进行同步。缺陷是要消耗部分GPU计算资源来完成通信，并且GPU控制通信的效率可能并不高，后面的实验结果也会证实这一点。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-973df7f05681621c7f9ea711da944a21_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-973df7f05681621c7f9ea711da944a21_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-973df7f05681621c7f9ea711da944a21_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-973df7f05681621c7f9ea711da944a21_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"8xAtaW6e\"\u003E回顾了GPU的两种基本通信模式后，我们进入到GPUDirect的发展历史中。首先在2009年出现了GPUDirect 1.0技术，在1.0之前。GPU和CPU无法共享通信缓冲区，通信数据需要在内存中进行一次拷贝后，再发向网卡。而1.0就是为了避免这种拷贝的，程序pin住一段内存后，既可以用作与GPU的数据交互， 又可以作为网卡的Memory Region使用。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-9df1c4da72c9f1b96ef4e08c5c6f362e_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-9df1c4da72c9f1b96ef4e08c5c6f362e_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-9df1c4da72c9f1b96ef4e08c5c6f362e_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-9df1c4da72c9f1b96ef4e08c5c6f362e_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"AihuXYVz\"\u003E第二代GPUDirect技术被称作GPUDirect P2P，重点解决的是节点内GPU通信问题。两个GPU可以通过PCIe P2P直接进行数据搬移，避免了主机内存和CPU的参与。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-5b57d0016d6b77d53a619fc02243bfa5_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-5b57d0016d6b77d53a619fc02243bfa5_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-5b57d0016d6b77d53a619fc02243bfa5_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-5b57d0016d6b77d53a619fc02243bfa5_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"vd0IPudX\"\u003E而第三代GPUDirect技术就是我们所熟知的GPUDirect RDMA了，GPU和网卡可以直接通过PCIe进行数据交互，避免了跨节点通信过程中内存和CPU的参与。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-f405f41723ca5b6edf56913d53cb36da_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-f405f41723ca5b6edf56913d53cb36da_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-f405f41723ca5b6edf56913d53cb36da_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-f405f41723ca5b6edf56913d53cb36da_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"TFBXDyLp\"\u003E接下来我们将继续深入下去，探讨上述技术究竟如何落实。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-ef2b137c65dec837d126b032f111d415_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-ef2b137c65dec837d126b032f111d415_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-ef2b137c65dec837d126b032f111d415_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-ef2b137c65dec837d126b032f111d415_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"bwqJh06W\"\u003E在上述GPUDirect RDMA的示意图中，我们只看到了GPU和网卡进行数据搬移，但是还有很多问题其实都被忽略掉了。那么，如果我们将上述通信过程细化，至少有三个关键问题需要解决。首先，为了实现CPU控制通信，数据进行P2P搬移，我们要解决网卡直接读写GPU显存的问题；其次，为了实现GPU直接控制通信，还有两个问题要解决。其一，GPU如何访问通信资源？其二，GPU如何与网卡进行同步？\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-87822b0e166f209586f85c348a7ca269_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-87822b0e166f209586f85c348a7ca269_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-87822b0e166f209586f85c348a7ca269_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-87822b0e166f209586f85c348a7ca269_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"9S4D4osZ\"\u003E接下来我们将逐次解决上述问题。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-7f2168e9e161e8298a55eac5ef6ae0db_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-7f2168e9e161e8298a55eac5ef6ae0db_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-7f2168e9e161e8298a55eac5ef6ae0db_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-7f2168e9e161e8298a55eac5ef6ae0db_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"lCyLezK6\"\u003E首先，对于网卡读写GPU显存，我们不妨先回顾一下网卡是如何访问CPU内存的。对于用户进程而言， 其将一个虚拟地址传递给网卡驱动，通过注册内存区域获取物理页表项，然后将页表填入网卡的MTT表中。在这个过程中，内存中建立了页表项，同时，pin memory的操作对每个物理内存页的元数据进行了修改，对于网卡而言，其动作是进行虚拟地址到物理地址的转换，然后发起PCIe请求，至于物理地址映射到主机内存还是设备内存它并不关心。因此，如果我们能够解决向网卡注册GPU虚拟地址的问题，就等价于解决了网卡读写GPU显存的问题。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-9b9b768791247bba4ab67a111d58a015_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-9b9b768791247bba4ab67a111d58a015_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-9b9b768791247bba4ab67a111d58a015_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-9b9b768791247bba4ab67a111d58a015_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"HSk0x-a5\"\u003E但是，当我们直接使用一个GPU虚拟地址进行内存注册时，会得到一个Segmetation Fault的错误。因为reg_mr注册时会陷入内核，通过调用get_user_pages获取物理页表，但对于GPU虚拟地址，CPU并不存在其对应的页表项，自然会出现错误。为了实现GPU内存的注册，需要对驱动进行一定的修改。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-6e89ef0f8e4c3269a3ceff1455b623e5_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-6e89ef0f8e4c3269a3ceff1455b623e5_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-6e89ef0f8e4c3269a3ceff1455b623e5_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-6e89ef0f8e4c3269a3ceff1455b623e5_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"aFnYsJU8\"\u003E为了实现网卡对其它设备内存的注册，MLNX提供了一套标准的注册框架。所有的设备驱动需要向MLNX的设备管理模块进行注册，提供类似于操作系统get_ser_pages的回调函数，当网卡驱动需要对一个地址进行注册时，会对地址进行判断，然后调用相应的函数获得设备指针，最终调用设备驱动中的物理页获取函数，得到设备内存的物理地址。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-b099df93fe6585370cfde364cf841b78_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-b099df93fe6585370cfde364cf841b78_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-b099df93fe6585370cfde364cf841b78_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-b099df93fe6585370cfde364cf841b78_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"ZXEUec6U\"\u003E这张图是Nvidia提供的注册函数与MLNX驱动框架之间的对接，具体细节就不再详细阐述了。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-d3759661398e3b050a1ac54047c3aeb5_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-d3759661398e3b050a1ac54047c3aeb5_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-d3759661398e3b050a1ac54047c3aeb5_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-d3759661398e3b050a1ac54047c3aeb5_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"FIkR_tws\"\u003E在新的注册框架下，通过内存注册，GPU内存在BAR空间的地址被下发到网卡，当网卡使用这些地址读写GPU显存时，GPU内部的HSHUB再进行一次地址映射，将BAR空间地址映射为实际的显存页面。这里有一个隐含的Trick，GPU的虚拟地址到物理地址也是分页寻址的。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-71f4396ac670619c6f2a0534d9c9f57a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-71f4396ac670619c6f2a0534d9c9f57a_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-71f4396ac670619c6f2a0534d9c9f57a_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-71f4396ac670619c6f2a0534d9c9f57a_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"tbuWOuOX\"\u003E至此，网卡能够直接读写GPU显存了，这也就意味着我们已经实现了CPU控制的GPU通信，同时数据通过PCIe P2P进行传输。接下来我们重点考虑GPU直接控制的通信方式。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-41da4e95f387b9979972542717f35c51_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-41da4e95f387b9979972542717f35c51_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-41da4e95f387b9979972542717f35c51_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-41da4e95f387b9979972542717f35c51_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"HD_uGyfg\"\u003EGPU控制通信其实就是GPU对通信资源进行相应的操作。为了解决这个问题，我们首先从一个比较宏观的角度来看CPU进行RDMA通信时包含哪些操作。从图中的分类可以看到，CPU在通信过程中，除了提交工作请求和同步，其它所有工作都在进行通信资源的创建和设置，而且都需要和内核进行交互。首先，GPU没有必要管理这些资源创建过程，其次，GPU上的代码也没有办法直接跟主机操作系统进行交互。因此，唯一能够且有必要由GPU控制的流程就是提交工作请求和同步过程。接下来我们重点考虑这一过程的实现。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-c260f4cc5abc7482ea5064027587adc0_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-c260f4cc5abc7482ea5064027587adc0_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-c260f4cc5abc7482ea5064027587adc0_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-c260f4cc5abc7482ea5064027587adc0_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"VDIGGwVN\"\u003E在提交工作请求中，涉及到的通信资源有哪些呢？按照资源类型，可以分为上下文资源，队列资源和数据区域。按照资源所处的位置，又可以分为位于设备内存和主机内存。其中，部分资源是仅由网卡进行访问的，这部分资源可以留在主机内存中保持不变，例如队列基地址，通信序列号等。另一部分资源是由CPU进行读写或临时创建的，因此需要详细考虑。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-e83dd6edddd364350d6210d14fef3f40_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-e83dd6edddd364350d6210d14fef3f40_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-e83dd6edddd364350d6210d14fef3f40_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-e83dd6edddd364350d6210d14fef3f40_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"Th_lDOJq\"\u003E当我们迁移到GPU的场景下，我们发现，GPU要访问这些通信资源，至少要考虑两个问题。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-2fa6380c9b95281b686ad581a6c64aee_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-2fa6380c9b95281b686ad581a6c64aee_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-2fa6380c9b95281b686ad581a6c64aee_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-2fa6380c9b95281b686ad581a6c64aee_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"-hjJ6hdw\"\u003E首先，门铃资源位于网卡，GPU要控制通信必然要涉及到写门铃，也就是GPU如何访问网卡寄存器的问题。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-93cb9ae03e1b352b959fb0be608fd15f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-93cb9ae03e1b352b959fb0be608fd15f_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-93cb9ae03e1b352b959fb0be608fd15f_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-93cb9ae03e1b352b959fb0be608fd15f_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"tfU1rKh0\"\u003E第二个问题在于，除了刚才提到的网卡要直接操作的资源，GPU控制的这些资源，可以放在主机内存，也可以放在显存中。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-1e83b54bbe861408fef0b9eb8ffec844_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-1e83b54bbe861408fef0b9eb8ffec844_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-1e83b54bbe861408fef0b9eb8ffec844_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-1e83b54bbe861408fef0b9eb8ffec844_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"dMJhJzJg\"\u003E对于问题一，我们还是先参考CPU是如何访问网卡BAR空间的。在CPU的页表中其实包含两种表项，一种表项指向实际的物理内存，表项的创建发生于出现缺页异常，另一种表项指向IO设备空间，由ioremap函数创建。通过ioremap，设备内存被映射到CPU的虚拟地址空间。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-ea4984141868c996499430fb3fa42189_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-ea4984141868c996499430fb3fa42189_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-ea4984141868c996499430fb3fa42189_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-ea4984141868c996499430fb3fa42189_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"gJlWqqVH\"\u003E对于GPU而言，使用cudaHostMemRegister和cudaHostGetDevicePointer等函数可以建立GPU虚拟地址到CPU内存空间的映射，也就是在GPU中建立到主机内存的页表项。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-ff7de1d8f95a3501dc6ab3bf61ad69ea_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-ff7de1d8f95a3501dc6ab3bf61ad69ea_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-ff7de1d8f95a3501dc6ab3bf61ad69ea_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-ff7de1d8f95a3501dc6ab3bf61ad69ea_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"Ve50tC7N\"\u003E但在早期的CUDA版本中，如果使用ioremap映射后的地址进行注册，会引发段错误。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-ec81970eb8f9b75bdba25799fc42ddf2_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-ec81970eb8f9b75bdba25799fc42ddf2_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-ec81970eb8f9b75bdba25799fc42ddf2_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-ec81970eb8f9b75bdba25799fc42ddf2_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"51zc04wr\"\u003E在CUDA 4.0之后该问题被修正，PCIe BAR空间能够直接映射到GPU虚拟地址空间。GPU访问门铃寄存器的问题得以解决。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-ad6a80891289f08408af1af31ad0d65d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-ad6a80891289f08408af1af31ad0d65d_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-ad6a80891289f08408af1af31ad0d65d_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-ad6a80891289f08408af1af31ad0d65d_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"GY7Z1OTr\"\u003E如何确保2在1之后完成？放在显存中显然可以加速对通信资源的访问，但如果通信连接较大，势必会消耗大量的显存资源，因此需要进行折衷考虑。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-e3a7123182af839a7781a2342b00f0ae_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-e3a7123182af839a7781a2342b00f0ae_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-e3a7123182af839a7781a2342b00f0ae_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-e3a7123182af839a7781a2342b00f0ae_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"rqqeSG31\"\u003E放在显存中显然可以加速对通信资源的访问，但如果通信连接较大，势必会消耗大量的显存资源，因此需要进行折衷考虑。后面的评测仅仅从通信性能上考量两种放置策略的差异。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-5028da7e886a30d7147dd2f692baafb4_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-5028da7e886a30d7147dd2f692baafb4_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-5028da7e886a30d7147dd2f692baafb4_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-5028da7e886a30d7147dd2f692baafb4_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"VZCkqgZ0\"\u003E最后一个问题就是GPU如何提交网络请求并与网卡进行同步。实际上有ibv_post_send，ibv_post_recv和ibv_poll_cq三个函数就可以了，因此，需要做的事情就是将libibverbs移植到GPU上执行。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-a159c6f3d886ae6458468ac263073400_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-a159c6f3d886ae6458468ac263073400_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-a159c6f3d886ae6458468ac263073400_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-a159c6f3d886ae6458468ac263073400_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"2AfT6lc7\"\u003E移植本身没有什么太大的难度，大部分libibverbs库的代码都可以直接在GPU上运行。至此，我们解决了全部GPU控制通信的问题。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-ea76684e778f7b1656e66ddf4e2d71b2_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-ea76684e778f7b1656e66ddf4e2d71b2_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-ea76684e778f7b1656e66ddf4e2d71b2_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-ea76684e778f7b1656e66ddf4e2d71b2_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp class=\"ztext-empty-paragraph\"\u003E\u003Cbr\u002F\u003E\u003C\u002Fp\u003E\u003Cp data-pid=\"QvppUBLL\"\u003E我们对整个过程做一个小结和回顾。首先，我们修改了Mellanox和Nvidia的内存注册部分，达到了网卡直接读写GPU显存的目的，实现了CPU控制的GPUDirect；接着，我们对通信资源进行划分，结合内存映射部分的修改，达到了GPU访问通信资源的目的，最后对libibverbs进行代码移植，最终实现了GPU控制的GPUDirect功能。在完成上述目标后，接下来要做的就是对GPUDirect进行优化，那么首先要对其进行详细的性能评测。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-238ebd0d4342ab00a6878340c187e825_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-238ebd0d4342ab00a6878340c187e825_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-238ebd0d4342ab00a6878340c187e825_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-238ebd0d4342ab00a6878340c187e825_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"HN5Me9i_\"\u003E对GPUDirect的性能评测主要分为两个部分，其一是不同的拓扑连接方式，也就是GPU在节点内是否隶属于同一个RC或PCIe Switch，这部分数据来源是Nvidia；其二是不同的控制方式，也就是CPU控制的通信和GPU控制的通信，这部分数据来源是德国海德堡大学。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-c862eddd4eb2156c61694289d1c9848f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-c862eddd4eb2156c61694289d1c9848f_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-c862eddd4eb2156c61694289d1c9848f_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-c862eddd4eb2156c61694289d1c9848f_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"CEpFEvSl\"\u003E所有的延迟测试都是用ud ping pong，带宽测试都是rdma_write。网卡理论带宽是56Gbps。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-88710f8b43f4cc38ce302f7e80f59b57_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-88710f8b43f4cc38ce302f7e80f59b57_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-88710f8b43f4cc38ce302f7e80f59b57_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-88710f8b43f4cc38ce302f7e80f59b57_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-030a66d6aecb9ebbfba4ab83bd4e90be_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-030a66d6aecb9ebbfba4ab83bd4e90be_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-030a66d6aecb9ebbfba4ab83bd4e90be_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-030a66d6aecb9ebbfba4ab83bd4e90be_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-402aa3fbe67539aefcdab56591894c4e_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-402aa3fbe67539aefcdab56591894c4e_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-402aa3fbe67539aefcdab56591894c4e_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-402aa3fbe67539aefcdab56591894c4e_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-0f0e70b17e762dd85c799e22d74a54e6_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-0f0e70b17e762dd85c799e22d74a54e6_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-0f0e70b17e762dd85c799e22d74a54e6_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-0f0e70b17e762dd85c799e22d74a54e6_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-437d831eaad2cb5bca39bd7c7465daf0_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-437d831eaad2cb5bca39bd7c7465daf0_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-437d831eaad2cb5bca39bd7c7465daf0_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-437d831eaad2cb5bca39bd7c7465daf0_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-df5f565f59e9a538426739593746049a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-df5f565f59e9a538426739593746049a_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-df5f565f59e9a538426739593746049a_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-df5f565f59e9a538426739593746049a_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-98ae80c3358bd8d640582a33006ec75b_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-98ae80c3358bd8d640582a33006ec75b_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-98ae80c3358bd8d640582a33006ec75b_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-98ae80c3358bd8d640582a33006ec75b_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"zkKCWeZz\"\u003E对比不同拓扑结构下的带宽，可以看到由CPU和GPU直接进行通信性能最好，对于GPU和GPU的通信，通过PCIe Switch进行转发的效果最佳。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-eb24eaac2624d1e96ceef5ca30227a09_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-eb24eaac2624d1e96ceef5ca30227a09_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-eb24eaac2624d1e96ceef5ca30227a09_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-eb24eaac2624d1e96ceef5ca30227a09_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"S8A-bLoq\"\u003E在延迟测试中能看到类似的结果。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-a1f69cff5c743f9a939592bc99a5dfb0_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-a1f69cff5c743f9a939592bc99a5dfb0_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-a1f69cff5c743f9a939592bc99a5dfb0_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-a1f69cff5c743f9a939592bc99a5dfb0_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"hKGTF4vd\"\u003E之后我们对CPU和GPU控制的通信进行对比。对比对象分为4类，首先是CPU控制的CPU和CPU通信，这是通信性能的天花板。然后是两类GPU控制的通信，分别是队列开辟在CPU内存中和GPU显存中，然后是CPU控制的GPU通信，使用P2P进行数据搬移，队列位于CPU内存中。实验测试指标是延迟，带宽和消息速率。在看实验结果之前我们可以预期自上到下性能应该是逐渐降低的。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-21b86fb6df070731b3724b41a085bdea_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-21b86fb6df070731b3724b41a085bdea_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-21b86fb6df070731b3724b41a085bdea_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-21b86fb6df070731b3724b41a085bdea_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"IYsMgsmf\"\u003E基本上后面的延迟和带宽结果和推测是吻合的。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-4e6be5e5b6b60cdc624c2625f5635252_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-4e6be5e5b6b60cdc624c2625f5635252_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-4e6be5e5b6b60cdc624c2625f5635252_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-4e6be5e5b6b60cdc624c2625f5635252_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-0ba4ec3a3b721772cedb2fae8aaa33ae_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-0ba4ec3a3b721772cedb2fae8aaa33ae_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-0ba4ec3a3b721772cedb2fae8aaa33ae_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-0ba4ec3a3b721772cedb2fae8aaa33ae_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-9b3c07ccfc6c5cc8038900041bd64060_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-9b3c07ccfc6c5cc8038900041bd64060_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-9b3c07ccfc6c5cc8038900041bd64060_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-9b3c07ccfc6c5cc8038900041bd64060_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-1b269417587c520df22e23d07f27d599_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-1b269417587c520df22e23d07f27d599_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-1b269417587c520df22e23d07f27d599_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-1b269417587c520df22e23d07f27d599_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"a830PMXo\"\u003E之后我们对通信函数的执行延迟进行分析，可以看到CPU提交WQE的速率要远远高于GPU。这主要是因为提交WQE的代码里有大量的分支语句，而GPU的计算核心主要是进行数据并行计算，因此其控制逻辑的执行能力远远弱于CPU。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-309c13eb5d296d6f535767f3e4b23ca0_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-309c13eb5d296d6f535767f3e4b23ca0_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-309c13eb5d296d6f535767f3e4b23ca0_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-309c13eb5d296d6f535767f3e4b23ca0_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"j8dSRB5U\"\u003E接下来我们对GPUDirect的评测部分进行小结，首先，在不同PCIe拓扑连接关系下，网卡和GPU位于相同的PCIe Switch下的性能是最优的，其次是同一个RC下，性能最差的是跨QPI的通信。对于不同的通信控制方式，最好的方式是CPU控制加数据P2P，GPU控制方式的性能瓶颈在于执行verbs的开销太大。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-ebd9f15047f22a114dd8d4584d6b55f5_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-ebd9f15047f22a114dd8d4584d6b55f5_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-ebd9f15047f22a114dd8d4584d6b55f5_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-ebd9f15047f22a114dd8d4584d6b55f5_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"5s5lieVX\"\u003E接下来进入我们的第三部分，不同互连架构下的GPU通信性能评测。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-6121359304512b6a8740824cc3e5d2d7_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-6121359304512b6a8740824cc3e5d2d7_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-6121359304512b6a8740824cc3e5d2d7_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-6121359304512b6a8740824cc3e5d2d7_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"01AcGr6z\"\u003E在前两部分我们重点探讨了GPU的节点间通信性能，这部分我们将详细分析节点内的通信性能。这部分内容来自TPDS的一篇文章[10]，主要是对PCIe，NVLink等GPU节点内互连的性能进行了评测。测试集使用的是Tartan Benchmark Suite。论文的内容非常多，我这里只列举了延迟，带宽和NUMA的影响，路由策略和拓扑方面不做讨论。通信模式上也只考虑点对点通信，有需要的话可以再去论文里面找数据。这篇文章实际上给出了很多评测数据，但实际上有价值的数据可能并不多，更多的是提供不同互连架构的带宽延迟相对性能的感性认知。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-4cc2b2b898baebb980f8ae155a252054_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-4cc2b2b898baebb980f8ae155a252054_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-4cc2b2b898baebb980f8ae155a252054_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-4cc2b2b898baebb980f8ae155a252054_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"3tjfGRYZ\"\u003E首先介绍一下节点内通信的评测环境。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-afec45b19d409fec5fd66f49c6dd9ec9_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-afec45b19d409fec5fd66f49c6dd9ec9_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-afec45b19d409fec5fd66f49c6dd9ec9_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-afec45b19d409fec5fd66f49c6dd9ec9_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"bE22V1bm\"\u003E节点内评测用了两个系统，DGX-1和DGX-2，其中DGX-1又用了两种GPU和互连。在左图中， 每个平面内的GPU形成一个全连接，不同平面内形成NUMA架构，NVLink本身不支持路由，不同平面间的GPU通信必须通过GPU进行转发。每个P100最多4个NVLink插槽，每个V100最多6个NVLink插槽。每个插槽可以理解为是200Gbps，P100带宽上限400Gbps，V100带宽上限1Tbps。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-c9a034c1173d197c5bf5c526c14b8eab_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-c9a034c1173d197c5bf5c526c14b8eab_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-c9a034c1173d197c5bf5c526c14b8eab_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-c9a034c1173d197c5bf5c526c14b8eab_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"zJ72JFMP\"\u003E在DGX-2系统中引入了NVSwitch，主要用于加速GPU之间的all-to-all通信。所有节点划分为两个baseboard，每个baseboard包括6台交换机和8个节点，每个节点出6个lane，每个lane的带宽是200Gbps，节点聚合带宽达到1.2Tbps。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-51a1c3c23139cac38d919c529446e2cf_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-51a1c3c23139cac38d919c529446e2cf_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-51a1c3c23139cac38d919c529446e2cf_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-51a1c3c23139cac38d919c529446e2cf_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"CLkt-u8p\"\u003E在DGX-2内部，不同GPU通过PCIe互连成为树形结构，每个CPU下面挂两级PCIe Switch，用于互连8个V100。还有一个系统是NV-SLI，它只有两个节点，节点间通过8个NVLink-Lane进行互连，聚合带宽可以达到1.6Tbps。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-1cab568633bafb72c462e74ebf323631_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-1cab568633bafb72c462e74ebf323631_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-1cab568633bafb72c462e74ebf323631_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-1cab568633bafb72c462e74ebf323631_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"blO8d8wv\"\u003E接下来对不同互连结构的通信性能进行评测，首先是DGX-1平台，图中给出了P100平台和V100平台下PCIe和NVLink的通信延迟。色调越冷延迟越高。对于PCIe通信而言，节点之间的通信延迟几乎是均匀分布的，不管是同一个PCIe Switch下，还是同一个CPU下，还是不同CPU下，延迟基本上都在20微秒左右。V100的延迟略有增加，作者认为是其通信转发的流水线深度有所增加。对于NVLink，P100和V100基本上展现出了相同的趋势，对于0号节点，1，2，3，4因为与其直接相连，所以延迟相同，而5，6，7需要4号节点做转发，所以延迟较高，甚至比CPU转发的延迟更高。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-9b780ea8f05ccd473eb0ce4970e9407d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-9b780ea8f05ccd473eb0ce4970e9407d_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-9b780ea8f05ccd473eb0ce4970e9407d_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-9b780ea8f05ccd473eb0ce4970e9407d_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"y5TLvqH0\"\u003E对于NV-SLI系统，只有两个GPU，NV-SLI访问延迟约8微秒，PCIe访问延迟约13微秒。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-2f079e23cb0fc23a2ffe782160856d95_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-2f079e23cb0fc23a2ffe782160856d95_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-2f079e23cb0fc23a2ffe782160856d95_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-2f079e23cb0fc23a2ffe782160856d95_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"VsodJkQO\"\u003E对于DGX-2系统，所有的访问都是对称的，NVSwitch引入的跳步延迟几乎可以忽略不计。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-3cbf63dd3758eee4c4d60113ba17e4a0_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-3cbf63dd3758eee4c4d60113ba17e4a0_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-3cbf63dd3758eee4c4d60113ba17e4a0_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-3cbf63dd3758eee4c4d60113ba17e4a0_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"8hiVguaI\"\u003E接下来看通信带宽，在DGX-1中，对于PCIe通信，居然出现了一种NUMA anti-locality现象，也就是离的越近的节点，其带宽反而越低。我们观察0号节点，发现其和1号节点隶属于同一个PCIe Switch，但其带宽反而低于不同PCIe Switch下的节点对。对于NVLink，其带宽则符合NUMA的访问规律，离的越远，访问带宽越低。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-49f8d9aeaeb392c40c2844a4d94b9c8a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-49f8d9aeaeb392c40c2844a4d94b9c8a_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-49f8d9aeaeb392c40c2844a4d94b9c8a_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-49f8d9aeaeb392c40c2844a4d94b9c8a_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"6fPppnaw\"\u003ENV-SLI的带宽和延迟的变化趋势基本一致。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-8441b8ee79abd0b82aef7db4574078a5_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-8441b8ee79abd0b82aef7db4574078a5_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-8441b8ee79abd0b82aef7db4574078a5_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-8441b8ee79abd0b82aef7db4574078a5_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"6HOzba1R\"\u003EDGX-2中可以看到更加明显的anti-locality现象。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-a8a071aaafbd8313486f403048733c6f_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-a8a071aaafbd8313486f403048733c6f_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-a8a071aaafbd8313486f403048733c6f_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-a8a071aaafbd8313486f403048733c6f_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"9w4YV5nF\"\u003E接下来讨论节点间通信的评测结果。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-318f5dfe7b54e2dd398005795254769c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-318f5dfe7b54e2dd398005795254769c_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-318f5dfe7b54e2dd398005795254769c_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-318f5dfe7b54e2dd398005795254769c_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"iv3RS8ix\"\u003E节点间通信测试使用的是Summit和SummitDev两个集群。其中SummitDev的CPU是Power 8，通过x-Bus互连，带宽约38GB\u002Fs，GPU是P100Summit超算节点内部互连架构图，CPU是Power 9，通过x-Bus互连，带宽约64GB\u002Fs，GPU是V100，通过NVLink直接跟Power 9相连。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-9ee9ce505c5a2a89b82a03c909c39c25_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-9ee9ce505c5a2a89b82a03c909c39c25_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-9ee9ce505c5a2a89b82a03c909c39c25_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-9ee9ce505c5a2a89b82a03c909c39c25_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"oPRARQ0r\"\u003E评测中比较了5种通信实现方式。首先，pinnedMem指的是数据从显存拷贝到主存时是否使用了pinned memory，GPUDirect指的是网卡和GPU是否能够共用内存中的缓冲区。对于UnpinnedMem，至少要经过三次拷贝，第一次从GPU显存拷贝到CPU中的临时缓冲区，然后拷贝到用户缓冲区，再拷贝到网卡通信缓冲区。PinnedMem GPUDirect只需要经过一次GPU显存到内存的拷贝。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-62f9bbcd2a2be98fa74298e34e92e7f6_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-62f9bbcd2a2be98fa74298e34e92e7f6_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-62f9bbcd2a2be98fa74298e34e92e7f6_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-62f9bbcd2a2be98fa74298e34e92e7f6_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"vNBmi2S3\"\u003E从实验结果中观察到以下现象：1.直到4KB大小，不同策略的通信延迟和带宽性能差异不大；2.对于延迟，在4KB到64KB，GPUDirect RDMA表现出了较差的性能；3.对于带宽，在4KB到256KB，GPUDirect RDMA表现出了较差的性能。作者认为大概率是因为Power 8的IOH转发性能较差；4.从4MB开始，GPUDirect RDMA的相对性能有所提升，但还是比Pinned Mem-GPUDirect差一些；5.当消息大小超过64MB后，GPUDirect的带宽开始下滑。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-74b18867743396c602c6be16e45b7575_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-74b18867743396c602c6be16e45b7575_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-74b18867743396c602c6be16e45b7575_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-74b18867743396c602c6be16e45b7575_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"WZBngwC1\"\u003E在Summit上，GPUDirect表现出了较好的性能，但并不清楚Summit对GPUDirect RDMA做了什么样的优化。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-526ad196d3ee618341fbc5c0ab44ac36_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-526ad196d3ee618341fbc5c0ab44ac36_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-526ad196d3ee618341fbc5c0ab44ac36_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-526ad196d3ee618341fbc5c0ab44ac36_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"ZKc-RnCf\"\u003E到现在为止，我们已经分析了GPUDirect的实现，性能特征，已经它和其它通信方式的对比。继续往前走，我们将遇到的问题就是如何去处理通用IO设备通信问题。这部分内容主要参考了[11-13]。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-21431a159fa642f6724a5c9e8c5986ef_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-21431a159fa642f6724a5c9e8c5986ef_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-21431a159fa642f6724a5c9e8c5986ef_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-21431a159fa642f6724a5c9e8c5986ef_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"J736kfj7\"\u003E目前，加速器，存储，网络这三者之间都表现出强烈的对等通信需求。我们可以看到，网络和存储之间出现了NVMe over Fabrics，加速器和存储之间有GPU和SSD直通，即Nvidia的Magnum IO框架，网络和加速器之间有GPUDirect，Habana，谷歌TPU。但是这些设备之间的通信框架和标准五花八门，没有一个统一的对等通信框架。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-944a980eb2a196b726cbaa017fb09de2_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-944a980eb2a196b726cbaa017fb09de2_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-944a980eb2a196b726cbaa017fb09de2_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-944a980eb2a196b726cbaa017fb09de2_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"zDUNUK2t\"\u003E因此，Linux想在内核里增加对P2P通信的统一支持，目前整个社区提出的解决方案大概有以下几种，分别针对不同的应用场景，我就不再详细展开介绍了。今天重点讨论的是POC，它是内核提供的一组标准API，全称是Provider，Orchestrator，Client架构。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-a0bf47308820557faee98f9b4d7a2738_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-a0bf47308820557faee98f9b4d7a2738_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-a0bf47308820557faee98f9b4d7a2738_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-a0bf47308820557faee98f9b4d7a2738_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"BK6kOQE7\"\u003E现在对P2P的支持仅限于同一个PCIe Switch下的不同End Point，对于同一个RC下的End Point或不同RC下的End Point不做任何保障。内核提供了一个设备厂商白名单，位于白名单上的芯片组能够确保是支持P2P功能的。整个P2P框架中分为三部分，顾名思义，Provider提供P2P内存资源，类似于正常DMA的内存资源，Client发起P2P操作，Orchestrator协同两者的工作。之所以增加一个Orchestrator是因为同一个Provider可能要提供给多个Client使用，Orchestrator起到了一个管理者的作用，类似于之前Mellanox提供的网卡P2P框架中的peer_mem模块。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-2e8e9725a7bd4583f8ae5482c1923dac_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-2e8e9725a7bd4583f8ae5482c1923dac_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-2e8e9725a7bd4583f8ae5482c1923dac_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-2e8e9725a7bd4583f8ae5482c1923dac_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"HAZYGLbF\"\u003E每个模块使用内核提供的标准API，provider进行资源注册和开放，orchestrator进行P2P内存分配和释放，client使用新的DMA接口进行内存映射，获取物理地址表项。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-258a22db80ac586ee5875be9f3481e73_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-258a22db80ac586ee5875be9f3481e73_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-258a22db80ac586ee5875be9f3481e73_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-258a22db80ac586ee5875be9f3481e73_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"wFj_wlbY\"\u003E对于P2P技术而言，GPUDirect算是其应用层，那么之后我们将进行一些微基准测试，看看P2P技术在PCIe层面究竟表现如何。在图中实验平台中，两个IO设备作为对等通信实体挂在同一个PCIe Switch下面，其中一个通过P2P DMA访问另一个设备的内存或通过普通DMA访问主存。CPU上运行应用程序来产生内存读写负载，观察在有内存负载的情况下，P2P DMA和访存的性能差异。接下来的所有实验基本上都沿用该设计，只是IO设备会进行替换。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-fd368e44d52f587fd3c32e898e7d3e6c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-fd368e44d52f587fd3c32e898e7d3e6c_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-fd368e44d52f587fd3c32e898e7d3e6c_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-fd368e44d52f587fd3c32e898e7d3e6c_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"t1mGT5Ey\"\u003E首先是一个微基准测试，两个设备分别是NoLoad和NetFPGA。其中，NoLoad是一个基于FPGA的NVMe加速器，其支持CMB（Controller Memory Buffer）。CMB是NVMe协议的可选项，驱动可以使用CMB作为命令队列缓冲区，以及数据缓冲区。同时，对pcie-bench进行了修改，使其能够读写其它IO设备的内存空间。内存负载选用的是ParaDNN和sysbench，ParaDNN产生的是神经网络训练负载，是一个20层的循环神经网络，128*4096*128的输入。sysbench将进行持续性的内存读写。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-d329791ae91ea36a9b0f77e7774ad234_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-d329791ae91ea36a9b0f77e7774ad234_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-d329791ae91ea36a9b0f77e7774ad234_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-d329791ae91ea36a9b0f77e7774ad234_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"jh3uLSQn\"\u003E实验中使用512B DMA随机写操作，持续120秒，柱状图给出的是平均值。Error bar给出了测试时间段内的最高值和最小值。无负载情况下，内存写操作和p2p写操作的测试结果与pcie-bench测试结果相同；ParaDNN干扰下，最多会使内存写操作带宽降至一半。sysbench干扰下，内存读操作几乎不受影响，内存写操作最多将带宽降低至30%。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-0e136b0eb06920e5840d973c77135227_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-0e136b0eb06920e5840d973c77135227_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-0e136b0eb06920e5840d973c77135227_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-0e136b0eb06920e5840d973c77135227_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"tI88q2cV\"\u003E读测试进行1000次512B读操作，记录这些读操作的延迟概率密度分布。sysbench的内存写操作严重影响了DMA Read的延迟性能；DMA p2p的读性能完全不受任何内存负载的影响；DMA p2p的读延迟性能相对于普通DMA要稍高一些。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-5487e2406dd76cdda027a2e99e55001a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-5487e2406dd76cdda027a2e99e55001a_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-5487e2406dd76cdda027a2e99e55001a_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-5487e2406dd76cdda027a2e99e55001a_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"S589bFEH\"\u003E第二个测试用于考察内存负载对于网络通信性能的影响。硬件使用Intel XL710网卡，物理带宽40Gbps，作者修改了一个开源的以太网通信框架netmap，使其可以将IO设备内存作为网络通信缓冲区使用。每台机器使用8个CPU核心进行收发包的处理，对数据包进行batch，每32个包进行一次发送，记录30秒内的带宽。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-4e5b0002dec71f2d280973dcdca4803c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-4e5b0002dec71f2d280973dcdca4803c_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-4e5b0002dec71f2d280973dcdca4803c_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-4e5b0002dec71f2d280973dcdca4803c_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"BhkIG34j\"\u003E在内存读写负载较高时，发送方向的带宽几乎不受任何影响，和无负载情况保持相同。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-5fbd2777dad8bec8070b8f72e489b36b_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-5fbd2777dad8bec8070b8f72e489b36b_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-5fbd2777dad8bec8070b8f72e489b36b_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-5fbd2777dad8bec8070b8f72e489b36b_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"Nal-RLrW\"\u003E对于Rx DMA，在包大小为1500B时，内存读负载使其带宽下降了15%，内存写负载使其带宽下降了27%。说明设备发起的DMA写请求更容易受到内存负载的影响。当包长小于256B时，不管是Tx还是Rx，P2P的带宽都小于普通DMA带宽，这是因为NoLoad本身是一个存储设备，其读写都是以一个block大小为单位进行的，即512B，小数据很难充分利用其带宽。同时，图d中，为什么P2P的带宽会受到内存负载影响。作者的解释是完成事件队列开在内存中，Tx方向上对描述符写回进行了合并，而Rx没有，每个接收到的数据包都要进行描述符写回，所以Rx更容易受到内存负载的影响，换言之Rx方向上的IOPS更高，导致其受到了内存负载的影响。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-db43383a02ce2ac5d0d72f88eb034f1b_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-db43383a02ce2ac5d0d72f88eb034f1b_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-db43383a02ce2ac5d0d72f88eb034f1b_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-db43383a02ce2ac5d0d72f88eb034f1b_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"8bNvFHDK\"\u003E上图通过处理器的PCM(Processor Counter Monitor)记录了P2P DMA过程中，Tx和Rx方向上的DMA写操作，这些DMA仅用于描述符的写回。很显然，Tx的描述符写回吞吐远低于Rx的描述符写回，说明Tx的描述符写回对内存带宽的需求并不高。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-064b1a25121ca598f854b862f5c99ab4_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-064b1a25121ca598f854b862f5c99ab4_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-064b1a25121ca598f854b862f5c99ab4_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-064b1a25121ca598f854b862f5c99ab4_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"TFKICQFG\"\u003E测试三使用NVMe SSD作为P2P操作的发起方，作者对UNVMe驱动进行了修改，测试过程中仍然使用8个CPU核心，NVMe的batch size是64。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-fce765beef8406272a136a32c622d43d_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-fce765beef8406272a136a32c622d43d_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-fce765beef8406272a136a32c622d43d_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-fce765beef8406272a136a32c622d43d_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"RCs6S-DH\"\u003ENVMe写命令的吞吐量基本不受内存负载影响，论文中没有给出具体实验结果。对于NVMe的读命令和网卡的Rx，都需要写回完成事件，即都需要发起DMA Write操作，但是NVMe的读命令却不受内存负载的影响。其根本原因在于两者的IOPS不一样，对于商用NVMe SSD，1M IOPS已经是一个很高的数值了，但对于网卡而言，哪怕只是10Gbps线速，IOPS要达到约14.88M左右，因此，NIC RX受到RX描述符写回的影响更大。可以看到网卡的单次操作最大是1500B，而NVMe SSD起步至少就是4KB，因此网卡的IOPS要高很多。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-ac72c9d3b90fbda07bc2a8dded4fb31c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-ac72c9d3b90fbda07bc2a8dded4fb31c_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-ac72c9d3b90fbda07bc2a8dded4fb31c_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-ac72c9d3b90fbda07bc2a8dded4fb31c_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-d963c9c4c020a09ac05eac6d23fd4126_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-d963c9c4c020a09ac05eac6d23fd4126_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-d963c9c4c020a09ac05eac6d23fd4126_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-d963c9c4c020a09ac05eac6d23fd4126_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"h5Brmv6u\"\u003E对于NVMe的读命令和网卡的Rx，都需要写回完成事件，即都需要发起DMA Write操作，但是NVMe的读命令却不受内存负载的影响。其根本原因在于两者的IOPS不一样，对于商用NVMe SSD，1M IOPS已经是一个很高的数值了，但对于网卡而言，哪怕只是10Gbps线速，IOPS要达到约14.88M左右，因此，NIC RX受到RX描述符写回的影响更大。可以看到网卡的单次操作最大是1500B，而NVMe SSD起步至少就是4KB，因此网卡的IOPS要高很多。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-ded14e9a6911ae94eb6673f006853332_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-ded14e9a6911ae94eb6673f006853332_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-ded14e9a6911ae94eb6673f006853332_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-ded14e9a6911ae94eb6673f006853332_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"OaimeXB5\"\u003E我们对上述P2P性能测试进行一个小结。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-73f6fb90f5de39f2b95265b2d671bc17_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-73f6fb90f5de39f2b95265b2d671bc17_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-73f6fb90f5de39f2b95265b2d671bc17_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-73f6fb90f5de39f2b95265b2d671bc17_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-6533a6a8f15fdd4240a6a052ba2ca2a4_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-6533a6a8f15fdd4240a6a052ba2ca2a4_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-6533a6a8f15fdd4240a6a052ba2ca2a4_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-6533a6a8f15fdd4240a6a052ba2ca2a4_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"zeP-F8mL\"\u003E至此，我们已经解决了现阶段P2P技术和GPUDirect技术的若干疑问，下一个面临的问题就是IO设备直接通信将如何发展下去。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-637f5be742f8e540f6e2c2362b41b809_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-637f5be742f8e540f6e2c2362b41b809_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-637f5be742f8e540f6e2c2362b41b809_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-637f5be742f8e540f6e2c2362b41b809_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"MLH44at5\"\u003E我们刚才提到的统一P2P框架，其实也只是处于整个发展过程中的过渡期，其出发点还是要兼容现有的PCIe协议，但是PCIe本质上还是为CPU和IO设备进行通信而设计的，并不适用于设备互连。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-8ae28f4842b8107438b4ae182e4fbce9_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-8ae28f4842b8107438b4ae182e4fbce9_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-8ae28f4842b8107438b4ae182e4fbce9_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic2.zhimg.com\u002Fv2-8ae28f4842b8107438b4ae182e4fbce9_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"NSXvm7rx\"\u003E所以我认为下一个阶段不再是加速器、网络、存储三足鼎立，而应该是所有的设备都能够具有直接通信的能力，作为对等IO进行互连互通。\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-35de1cde53d8e90a5bef96c68909893c_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-35de1cde53d8e90a5bef96c68909893c_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-35de1cde53d8e90a5bef96c68909893c_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-35de1cde53d8e90a5bef96c68909893c_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"FESt_p9R\"\u003E那么首先要解决的一个问题就是怎么为这些对等IO设备提供统一的资源抽象。我们知道，CPU在使用加速器例如GPU，使用加载内核和同步的方式，使用SSD的时候使用读写命令队列，GPU使用SSD也采用这种方式。那么SSD是否能够直接使用GPU资源或其它加速器资源？\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-c933c11af54b6bd95701584e4963f06a_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-c933c11af54b6bd95701584e4963f06a_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-c933c11af54b6bd95701584e4963f06a_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic3.zhimg.com\u002Fv2-c933c11af54b6bd95701584e4963f06a_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"Z24aH-G4\"\u003E我们是否能够给所有设备提供一套标准的访问抽象？我认为不管是CPU和GPU通信，还是CPU和SSD通信，其本质都是一个请求和响应的交互模式，那么，是否有可能为对等IO设备的通信提供一套RPC的调用接口，不管是存储还是计算资源都能够通过相同的接口进行调用？\u003C\u002Fp\u003E\u003Cfigure data-size=\"normal\"\u003E\u003Cnoscript\u003E\u003Cimg src=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-8d107dc44ccec03a8d6783f6e4dd037b_b.jpg\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb\" width=\"1280\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-8d107dc44ccec03a8d6783f6e4dd037b_r.jpg\"\u002F\u003E\u003C\u002Fnoscript\u003E\u003Cimg src=\"data:image\u002Fsvg+xml;utf8,&lt;svg xmlns=&#39;http:\u002F\u002Fwww.w3.org\u002F2000\u002Fsvg&#39; width=&#39;1280&#39; height=&#39;720&#39;&gt;&lt;\u002Fsvg&gt;\" data-caption=\"\" data-size=\"normal\" data-rawwidth=\"1280\" data-rawheight=\"720\" class=\"origin_image zh-lightbox-thumb lazy\" width=\"1280\" data-original=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-8d107dc44ccec03a8d6783f6e4dd037b_r.jpg\" data-actualsrc=\"https:\u002F\u002Fpic4.zhimg.com\u002Fv2-8d107dc44ccec03a8d6783f6e4dd037b_b.jpg\"\u002F\u003E\u003C\u002Ffigure\u003E\u003Cp data-pid=\"NmbS8RHz\"\u003E---------------------------------------------------------------------------\u003C\u002Fp\u003E\u003Cp data-pid=\"1OU6_b5I\"\u003E参考文献：\u003C\u002Fp\u003E\u003Cp data-pid=\"MhXVcf2A\"\u003E1.A quantitative evaluation of unified memory in GPUs\u003C\u002Fp\u003E\u003Cp data-pid=\"3T8T3w9t\"\u003E2.An Evaluation of Unified Memory Technology on NVIDIA GPUs\u003C\u002Fp\u003E\u003Cp data-pid=\"AdKjArPI\"\u003E3.Performance Evaluation of Advanced Features in CUDA Unified Memory\u003C\u002Fp\u003E\u003Cp data-pid=\"1Bz-ySLS\"\u003E4.Unified Memory on Pascal and Volta\u003C\u002Fp\u003E\u003Cp data-pid=\"VtfVjm1_\"\u003E5.Everything you need to know about unified memory\u003C\u002Fp\u003E\u003Cp data-pid=\"sUSSIBNI\"\u003E6.Benchmarking GPUDirect RDMA on Modern Server Platforms\u003C\u002Fp\u003E\u003Cp data-pid=\"jFxktmju\"\u003E7.Direct Communication between distributed GPUs\u003C\u002Fp\u003E\u003Cp data-pid=\"XSTTtHGV\"\u003E8.Towards Efficient Communication Methods and Models for Scalable GPU-Centric Computing Systems\u003C\u002Fp\u003E\u003Cp data-pid=\"lS1Thrux\"\u003E9.An introduction to CUDA-Aware MPI\u003C\u002Fp\u003E\u003Cp data-pid=\"dA9wEM97\"\u003E10.Evaluating modern GPU interconnect\u003C\u002Fp\u003E\u003Cp data-pid=\"X_5NJcQU\"\u003E11.Exploring the PCIe Routes\u003C\u002Fp\u003E\u003Cp data-pid=\"AQqYqbbb\"\u003E12.How beneficial is Peer-to-Peer DMA?\u003C\u002Fp\u003E\u003Cp data-pid=\"z4LAxgKA\"\u003E13.SPIN: Seamless Operating System Integration of Peer-to-Peer DMA Between SSDs and GPUs\u003C\u002Fp\u003E","adminClosedComment":false,"topics":[{"url":"https:\u002F\u002Fwww.zhihu.com\u002Fapi\u002Fv4\u002Ftopics\u002F19608622","type":"topic","id":"19608622","name":"高性能计算"},{"url":"https:\u002F\u002Fwww.zhihu.com\u002Fapi\u002Fv4\u002Ftopics\u002F19570894","type":"topic","id":"19570894","name":"图形处理器（GPU）"},{"url":"https:\u002F\u002Fwww.zhihu.com\u002Fapi\u002Fv4\u002Ftopics\u002F20047090","type":"topic","id":"20047090","name":"大规模机器学习"}],"voteupCount":269,"voting":0,"heavyUpStatus":"allow_heavy_up","column":{"description":"","canManage":false,"intro":"分享高性能互连网络的相关研究进展","isFollowing":false,"urlToken":"c_1440266400069345280","id":"c_1440266400069345280","articlesCount":7,"acceptSubmission":false,"title":"高性能互连网络","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fc_1440266400069345280","commentPermission":"all","created":1636166268,"updated":1636166268,"imageUrl":"https:\u002F\u002Fpica.zhimg.com\u002F4b70deef7_720w.jpg?source=172ae18b","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-8966d1ab2d8ee8980d116f4d746ce456.jpg?source=172ae18b","uid":"1178294224352632832","userType":"people","isFollowing":false,"urlToken":"han-gu-tao-ke","id":"4b88b8fd34703b95cde7a736a85ec8cb","description":"一心筑函谷","name":"函谷叨客","isAdvertiser":false,"headline":"从事高性能互连网络研究","gender":1,"url":"\u002Fpeople\u002F4b88b8fd34703b95cde7a736a85ec8cb","avatarUrl":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-8966d1ab2d8ee8980d116f4d746ce456_l.jpg?source=172ae18b","isOrg":false,"type":"people"},"followers":4,"type":"column"},"commentCount":16,"contributions":[{"id":35152399,"state":"accepted","type":"first_publish","column":{"description":"","canManage":false,"intro":"分享高性能互连网络的相关研究进展","isFollowing":false,"urlToken":"c_1440266400069345280","id":"c_1440266400069345280","articlesCount":7,"acceptSubmission":false,"title":"高性能互连网络","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fc_1440266400069345280","commentPermission":"all","created":1636166268,"updated":1636166268,"imageUrl":"https:\u002F\u002Fpica.zhimg.com\u002F4b70deef7_720w.jpg?source=172ae18b","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-8966d1ab2d8ee8980d116f4d746ce456.jpg?source=172ae18b","uid":"1178294224352632832","userType":"people","isFollowing":false,"urlToken":"han-gu-tao-ke","id":"4b88b8fd34703b95cde7a736a85ec8cb","description":"一心筑函谷","name":"函谷叨客","isAdvertiser":false,"headline":"从事高性能互连网络研究","gender":1,"url":"\u002Fpeople\u002F4b88b8fd34703b95cde7a736a85ec8cb","avatarUrl":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-8966d1ab2d8ee8980d116f4d746ce456_l.jpg?source=172ae18b","isOrg":false,"type":"people"},"followers":4,"type":"column"}},{"id":35887265,"state":"accepted","type":"first_publish","column":{"description":"","canManage":false,"intro":"致力于帮助医生提高诊疗水平与效率，提高检出率。","isFollowing":false,"urlToken":"c_1409084119363641344","id":"c_1409084119363641344","articlesCount":15,"acceptSubmission":false,"title":"消化AI 慧维智能","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fc_1409084119363641344","commentPermission":"all","created":1628731833,"updated":1628731833,"imageUrl":"https:\u002F\u002Fpicx.zhimg.com\u002F4b70deef7_720w.jpg?source=172ae18b","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpica.zhimg.com\u002Fv2-69e6441f7fe6e9d3d33c6c1d1be993a0.jpg?source=172ae18b","uid":"959038986782588928","userType":"people","isFollowing":false,"urlToken":"sheng-bai-se","id":"ff7c2814d422998437de96905e88b883","description":"","name":"慧维智能","isAdvertiser":false,"headline":"","gender":-1,"url":"\u002Fpeople\u002Fff7c2814d422998437de96905e88b883","avatarUrl":"https:\u002F\u002Fpica.zhimg.com\u002Fv2-69e6441f7fe6e9d3d33c6c1d1be993a0_l.jpg?source=172ae18b","isOrg":false,"type":"people"},"followers":0,"type":"column"}}],"isTitleImageFullScreen":false,"upvotedFollowees":[],"commercialInfo":{"isCommercial":false,"plugin":{}},"suggestEdit":{"status":false,"reason":"","tip":"","url":"","title":""},"reason":"","annotationAction":[],"canTip":true,"tipjarorsCount":0,"isLabeled":false,"hasPublishingDraft":false,"isFavorited":false,"favlistsCount":800,"isNormal":true,"status":0,"shareText":"【研究综述】浅谈GPU通信和PCIe P2P DMA - 来自知乎专栏「高性能互连网络」，作者: 函谷叨客 https:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F430101220 （想看更多？下载 @知乎 App：http:\u002F\u002Fweibo.com\u002Fp\u002F100404711598 ）","canComment":{"status":true,"reason":""},"mcnFpShow":-1,"isVisible":true,"isLiked":false,"likedCount":65,"hasColumn":true,"republishers":[{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpica.zhimg.com\u002Fv2-69e6441f7fe6e9d3d33c6c1d1be993a0.jpg?source=172ae18b","uid":"959038986782588928","userType":"people","isFollowing":false,"urlToken":"sheng-bai-se","id":"ff7c2814d422998437de96905e88b883","description":"","name":"慧维智能","isAdvertiser":false,"headline":"","gender":-1,"url":"\u002Fpeople\u002Fff7c2814d422998437de96905e88b883","avatarUrl":"https:\u002F\u002Fpica.zhimg.com\u002Fv2-69e6441f7fe6e9d3d33c6c1d1be993a0_l.jpg?source=172ae18b","isOrg":false,"type":"people"}],"isNewLinkCard":true,"emojiReaction":{"cryFaceCount":0,"cryFaceHasSet":false,"hugCount":0,"hugHasSet":false,"likeCount":65,"likeHasSet":false,"onlookerCount":0,"onlookerHasSet":false},"abParam":{"shangyebiaoshi":"1"},"attachedInfo":"kgIkCgkxODM3MDY5ODcSCTQzMDEwMTIyMBgHIgpJTUFHRV9URVhU","shareGuide":{"hasPositiveBubble":false,"hasTimeBubble":false,"hitShareGuideCluster":false},"settings":{"tableOfContents":{"enabled":false}},"canReference":false,"reactionInstruction":{}}},"columns":{"c_1440266400069345280":{"description":"","canManage":false,"intro":"分享高性能互连网络的相关研究进展","isFollowing":false,"urlToken":"c_1440266400069345280","id":"c_1440266400069345280","articlesCount":7,"acceptSubmission":false,"title":"高性能互连网络","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fc_1440266400069345280","commentPermission":"all","created":1636166268,"updated":1636166268,"imageUrl":"https:\u002F\u002Fpica.zhimg.com\u002F4b70deef7_720w.jpg?source=172ae18b","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-8966d1ab2d8ee8980d116f4d746ce456.jpg?source=172ae18b","uid":"1178294224352632832","userType":"people","isFollowing":false,"urlToken":"han-gu-tao-ke","id":"4b88b8fd34703b95cde7a736a85ec8cb","description":"一心筑函谷","name":"函谷叨客","isAdvertiser":false,"headline":"从事高性能互连网络研究","gender":1,"url":"\u002Fpeople\u002F4b88b8fd34703b95cde7a736a85ec8cb","avatarUrl":"https:\u002F\u002Fpic1.zhimg.com\u002Fv2-8966d1ab2d8ee8980d116f4d746ce456_l.jpg?source=172ae18b","isOrg":false,"type":"people"},"followers":4,"type":"column"},"c_1409084119363641344":{"description":"","canManage":false,"intro":"致力于帮助医生提高诊疗水平与效率，提高检出率。","isFollowing":false,"urlToken":"c_1409084119363641344","id":"c_1409084119363641344","articlesCount":15,"acceptSubmission":false,"title":"消化AI 慧维智能","url":"https:\u002F\u002Fzhuanlan.zhihu.com\u002Fc_1409084119363641344","commentPermission":"all","created":1628731833,"updated":1628731833,"imageUrl":"https:\u002F\u002Fpicx.zhimg.com\u002F4b70deef7_720w.jpg?source=172ae18b","author":{"isFollowed":false,"avatarUrlTemplate":"https:\u002F\u002Fpica.zhimg.com\u002Fv2-69e6441f7fe6e9d3d33c6c1d1be993a0.jpg?source=172ae18b","uid":"959038986782588928","userType":"people","isFollowing":false,"urlToken":"sheng-bai-se","id":"ff7c2814d422998437de96905e88b883","description":"","name":"慧维智能","isAdvertiser":false,"headline":"","gender":-1,"url":"\u002Fpeople\u002Fff7c2814d422998437de96905e88b883","avatarUrl":"https:\u002F\u002Fpica.zhimg.com\u002Fv2-69e6441f7fe6e9d3d33c6c1d1be993a0_l.jpg?source=172ae18b","isOrg":false,"type":"people"},"followers":0,"type":"column"}},"topics":{},"roundtables":{},"favlists":{},"comments":{},"notifications":{},"ebooks":{},"activities":{},"feeds":{},"pins":{},"promotions":{},"drafts":{},"chats":{},"posts":{},"clubs":{},"clubTags":{},"zvideos":{},"zvideoContributions":{},"briefs":{},"eduCourses":{}},"currentUser":"9b939bd116cd066ce372288d50538da8","account":{"lockLevel":{},"unlockTicketStatus":false,"unlockTicket":null,"challenge":[],"errorStatus":false,"message":"","isFetching":false,"accountInfo":{},"urlToken":{"loading":false},"cardUserInfo":{"vipInfo":{}},"handleWidget":{},"widgetList":[],"userWidgetId":""},"settings":{"socialBind":null,"inboxMsg":null,"notification":{},"email":{},"privacyFlag":null,"blockedUsers":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"blockedFollowees":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"ignoredTopics":{"isFetching":false,"paging":{"pageNo":1,"pageSize":6},"data":[]},"restrictedTopics":null,"laboratory":{}},"notification":{},"people":{"profileStatus":{},"activitiesByUser":{},"answersByUser":{},"answersSortByVotesByUser":{},"answersIncludedByUser":{},"votedAnswersByUser":{},"thankedAnswersByUser":{},"voteAnswersByUser":{},"thankAnswersByUser":{},"topicAnswersByUser":{},"zvideosByUser":{},"articlesByUser":{},"articlesSortByVotesByUser":{},"articlesIncludedByUser":{},"pinsByUser":{},"questionsByUser":{},"commercialQuestionsByUser":{},"favlistsByUser":{},"followingByUser":{},"followersByUser":{},"mutualsByUser":{},"followingColumnsByUser":{},"followingQuestionsByUser":{},"followingFavlistsByUser":{},"followingTopicsByUser":{},"publicationsByUser":{},"columnsByUser":{},"allFavlistsByUser":{},"brands":null,"creationsByUser":{},"creationsSortByVotesByUser":{},"creationsFeed":{},"infinity":{},"batchUsers":{},"profileInfinity":null},"env":{"ab":{"config":{"params":[{"id":"vessay_v2_sdk","type":"Int","value":"1","layerId":"Qtkm"},{"id":"pc_ppt_publish","type":"Int","value":"1","layerId":"pc_ppt_publish"},{"id":"titlepagechoose","type":"Int","value":"0","layerId":"titlepagechoose"},{"id":"helpcenter_pc","type":"Int","value":"1","layerId":"helpcenter_pc"},{"id":"pc_comment","type":"Int","value":"1","layerId":"EsOR"},{"id":"pc_follow","type":"Int","value":"1","layerId":"pc_follow"},{"id":"draftsentrance","type":"Int","value":"1","layerId":"draftsentrance"},{"id":"se_clubtab","type":"Int","value":"0","layerId":"e8ys"}],"experiments":[{"expId":"pc_ppt_publish-2_v2","expPrefix":"pc_ppt_publish","isDynamicallyUpdated":false,"isRuntime":false,"includeTriggerInfo":false},{"expId":"helpcenter_pc-2_v11","expPrefix":"helpcenter_pc","isDynamicallyUpdated":false,"isRuntime":false,"includeTriggerInfo":false},{"expId":"pc_comment-2_v4","expPrefix":"pc_comment","isDynamicallyUpdated":false,"isRuntime":false,"includeTriggerInfo":false},{"expId":"pc_follow-3_v5","expPrefix":"pc_follow","isDynamicallyUpdated":false,"isRuntime":false,"includeTriggerInfo":false}],"chains":[{"chainId":"_all_"}],"encodedParams":"CtwBGwA\u002FAEcAtABpAWoBdAE7AswC1wLYAk8DUAOgA6EDogO3A\u002FMD9AMzBIwEjQSmBNYEEQUpBTIFUQWLBYwFngUWBjAGMQZ+BusGJwdXB3cHeAebB9gH3AfdBycIZwh0CHYIeQjFCNoI5Qg\u002FCUIJVAlVCWAJjQmrCcMJxAnFCcYJxwnICckJygnLCcwJ0QnlCfEJ9AkECkkKZQprCpgKpQqpCr4KxArUCt0K7Qr9Cv4KKQs7CzwLQwtGC3ELdguFC4cLjQu5C8AL1wvgC+UL5gs4DHEMjwysDMMMyQy1CxJuAAAAAQABAAIDAAAAAAAAAAAAAAAEBAAEAAABAQAAAQAAAQAAAAEAAAAAAgIABAAABgAAAQABAAAAAAAAAAAAAAAAAAAAAAAHAwAAAAABAAAAAAEBAAcAAQEAAQAAAAAABQAAAgAAAAIAAAAAAAM="},"triggers":{}},"userAgent":{"Edge":false,"IE":false,"Wechat":false,"Weibo":false,"QQ":false,"MQQBrowser":false,"Qzone":false,"Mobile":false,"Android":false,"iOS":false,"isAppleDevice":false,"Zhihu":false,"ZhihuHybrid":false,"isBot":false,"Tablet":false,"UC":false,"Quark":false,"Sogou":false,"Qihoo":false,"Baidu":false,"BaiduApp":false,"Safari":false,"GoogleBot":false,"AndroidDaily":false,"iOSDaily":false,"WxMiniProgram":false,"BaiduMiniProgram":false,"QQMiniProgram":false,"JDMiniProgram":false,"isWebView":false,"isMiniProgram":false,"origin":"Mozilla\u002F5.0 (Windows NT 10.0; Win64; x64) AppleWebKit\u002F537.36 (KHTML, like Gecko) Chrome\u002F104.0.5112.81 Safari\u002F537.36 Edg\u002F104.0.1293.54"},"appViewConfig":{},"ctx":{"path":"\u002Fp\u002F430101220","query":{},"href":"http:\u002F\u002Fzhuanlan.zhihu.com\u002Fp\u002F430101220","host":"zhuanlan.zhihu.com"},"trafficSource":"production","edition":{"beijing":false,"baidu":false,"sogou":false,"baiduBeijing":false,"sogouBeijing":false,"sogouInput":false,"baiduSearch":false,"googleSearch":false,"shenma":false,"miniProgram":false,"xiaomi":false},"theme":"light","appHeaderTheme":{"current":"normal","disable":true,"normal":{"bgColor":"GBK99A"},"custom":{"bgColor":"GBK99A"}},"enableShortcut":true,"referer":"https:\u002F\u002Fwww.bing.com\u002F","xUDId":"ADAds6PjzxOPTmBuqv67KXaBAfLOjNtmuyk=","mode":"ssr","conf":{},"xTrafficFreeOrigin":"","ipInfo":{"cityName":"上海","countryName":"中国","regionName":"上海","countryCode":"CN"},"logged":true,"vars":{"passThroughHeaders":{}}},"me":{"columnContributions":[]},"label":{"recognizerLists":{}},"ecommerce":{},"comments":{"pagination":{},"collapsed":{},"reverse":{},"reviewing":{},"conversation":{},"parent":{}},"commentsV2":{"stickers":[],"commentWithPicPermission":{},"notificationsComments":{},"pagination":{},"collapsed":{},"reverse":{},"reviewing":{},"conversation":{},"conversationMore":{},"parent":{}},"pushNotifications":{"default":{"isFetching":false,"isDrained":false,"ids":[]},"follow":{"isFetching":false,"isDrained":false,"ids":[]},"vote_thank":{"isFetching":false,"isDrained":false,"ids":[]},"currentTab":"default","notificationsCount":{"default":0,"follow":0,"vote_thank":0}},"messages":{"data":{},"currentTab":"common","messageCount":0},"register":{"registerValidateSucceeded":null,"registerValidateErrors":{},"registerConfirmError":null,"sendDigitsError":null,"registerConfirmSucceeded":null},"login":{"loginUnregisteredError":false,"loginBindWechatError":false,"loginConfirmError":null,"sendDigitsError":null,"needSMSIdentify":false,"validateDigitsError":false,"loginConfirmSucceeded":null,"qrcodeLoginToken":"","qrcodeLoginScanStatus":0,"qrcodeLoginError":null,"qrcodeLoginReturnNewToken":false},"switches":{},"captcha":{"captchaNeeded":false,"captchaValidated":false,"captchaBase64String":null,"captchaValidationMessage":null,"loginCaptchaExpires":false},"sms":{"supportedCountries":[]},"chat":{"chats":{},"inbox":{"recents":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"strangers":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"friends":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"search":{"isFetching":false,"isDrained":false,"isPrevDrained":false,"result":[],"next":null,"key":null},"config":{"newCount":0,"strangerMessageSwitch":false,"strangerMessageUnread":false,"friendCount":0}},"global":{"isChatMqttExisted":false}},"emoticons":{"emoticonGroupList":[],"emoticonGroupDetail":{}},"creator":{"currentCreatorUrlToken":null,"homeData":{"recommendQuestions":[]},"tools":{"question":{"invitationCount":{"questionFolloweeCount":0,"questionTotalCount":0},"goodatTopics":[]},"customPromotion":{"itemLists":{}},"recommend":{"recommendTimes":{}}},"explore":{"academy":{"tabs":[],"article":{}}},"rights":[],"newRights":[],"rightsStatus":{},"levelUpperLimit":10,"account":{"growthLevel":{}},"mcn":{},"applyStatus":{},"videoSupport":{},"textBenefit":{},"mcnManage":{},"tasks":{},"newTasks":{"creatorTask":{"tasks":[],"des":[]}},"scoreInfo":{},"recentlyCreated":[],"analysis":{"all":{},"answer":{},"zvideo":{},"article":{},"pin":{},"singleContent":{}},"announcement":{},"bannerList":[],"school":{"tabs":[],"contents":[],"banner":null,"entities":{}},"creatorsRecommendInfo":{},"menusShowControlByServer":{"bVipRecomend":false,"creationRelationship":false},"income":{"aggregation":{}}},"answers":{"voters":{},"copyrightApplicants":{},"favlists":{},"newAnswer":{},"entityWords":{},"concernedUpvoters":{},"simpleConcernedUpvoters":{},"paidContent":{},"settings":{}},"recommendation":{"homeRecommendations":[]},"shareTexts":{},"articles":{"voters":{},"concernedUpvoters":{}},"previewPost":{},"favlists":{"relations":{}},"columns":{"voters":{}},"reward":{"answer":{},"article":{},"question":{}},"video":{"data":{},"shareVideoDetail":{},"last":{}},"topstory":{"recommend":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"follow":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"room":{"meta":{},"isFetching":false,"afterId":0,"items":[],"next":null},"followWonderful":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"sidebar":null,"announcement":{},"hotList":[],"guestFeeds":{"isFetching":false,"isDrained":false,"afterId":0,"items":[],"next":null},"followExtra":{"isNewUser":null,"isFetched":false,"followCount":0,"followers":[]},"hotDaily":{"data":[],"paging":{}},"hotHighlight":{"isFetching":false,"isDrained":false,"data":[],"paging":{}},"banner":{},"commercialBanner":{"show":false,"banner":{},"trackData":{}},"video":{"items":[],"next":null,"isLoading":false,"isDrained":false}},"readStatus":{},"column":{},"requestColumn":{"categories":[],"error":null},"articleContribution":{"contributeRequests":[],"deleteContributeIdList":[],"handledContributeIdList":[],"recommendedColumns":[],"pinnedColumns":[],"sentContributeRequestsIdList":[null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,null,"c_1440266400069345280","c_1409084119363641344"]},"columnContribution":{"contributeRequests":[],"autoInviteEnabled":false,"recommendedContributors":[],"contributionInvitation":null},"draftHistory":{"history":{},"drafts":{}},"upload":{},"articleDraft":{"titleImage":"","titleImageSize":{},"isTitleImageFullScreen":false,"canTitleImageFullScreen":false,"title":"","titleImageUploading":false,"error":"","content":"","draftLoading":false,"updating":false,"globalLoading":false,"pendingVideo":{"resource":null,"error":null},"deleteFail":{"fail":false},"recommendTopics":[],"selectedColumn":0,"articleDisclaimers":[]},"articleDrafts":{"isDrained":false,"isLoading":false,"items":[]},"columnAutocomplete":{"users":[],"friends":[]},"columnCollection":{},"userProfit":{"permission":{"permissionStatus":{"zhiZixuan":0,"recommend":-1,"task":0,"plugin":0,"infinity":0},"visible":false}},"mcn":{"bindInfo":{},"memberCategoryList":[],"producerList":[],"categoryList":[],"lists":{},"banners":{},"protocolStatus":{"isAgreedNew":true,"isAgreedOld":true},"probationCountdownDays":0},"zvideos":{"campaignVideoList":{},"campaigns":{},"tagoreCategory":[],"recommendations":{},"insertable":{},"recruit":{"form":{"platform":"","nickname":"","followerCount":"","domain":"","contact":""},"submited":false,"ranking":[]},"club":{},"qyActivityData":{},"talkActivityData":{},"party2022ActivityData":{},"batchVideos":{},"contribution":{"selectedContribution":null,"campaign":null,"configs":{},"contributionLists":{},"recommendQuestions":{"isLoading":true,"paging":{"isEnd":false,"isStart":true,"totals":0},"data":[]},"questionSearchResults":{"isLoading":true,"paging":{"isEnd":false,"isStart":true,"totals":0},"data":[]}},"creationReferences":{},"zvideoCollection":{},"zvideoGrant":{},"collectData":{"isFetching":false,"list":[]},"videoSource":{"isLoaded":false}},"republish":{},"commentPermission":{},"creatorRightStatus":{"list":[]}},"fetchHost":"www.zhihu.com","subAppName":"column"}</script><script crossorigin="" src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/vendor.4bb309fcb0b4b803488b.js.download"></script><script crossorigin="" src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/column.lib_09e9ad9b.6faf2a4951b4ff734e07.js.download"></script><script crossorigin="" src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/column.lib_79b5cf47.1419adbd3890e66b0630.js.download"></script><script crossorigin="" src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/column.lib_29107295.92a39e4cefc23aa607d1.js.download"></script><script crossorigin="" src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/column.lib_0ad37f8a.bafb36126cc61095ca41.js.download"></script><script crossorigin="" src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/column.app.c315806dbb1eab8d6858.js.download"></script><script defer="" src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/aria.js.download"></script><script src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/hm.js.download" async=""></script><script crossorigin="" src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/zap.js.download"></script><script src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/push.js.download"></script><div><div style="display: none;"><i>想来知乎工作？请发送邮件到 jobs@zhihu.com</i></div></div><div><div><div class="css-8pdeid"></div></div></div><script crossorigin="" src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/js"></script><script crossorigin="" src="./【研究综述】浅谈GPU通信和PCIe P2P DMA - 知乎_files/emoticon.js.download"></script><div><div><div class="Editable-languageSuggestions" style="left: -1179px; top: -999px;"><div><div class="Popover"><label class="Editable-languageSuggestionsInput Input-wrapper"><input autocomplete="off" role="combobox" aria-expanded="false" aria-autocomplete="list" aria-activedescendant="AutoComplete17-0" id="Popover16-toggle" aria-haspopup="true" aria-owns="Popover16-content" class="Input" placeholder="选择语言" value=""><svg width="24" height="24" viewBox="0 0 24 24" data-new-api="ArrowUpDown24" data-old-api="Select" fill="#afbdcf" class="Zi Zi--Select"><path d="M12.53 3.47a.75.75 0 00-1.06 0l-5 5a.75.75 0 001.06 1.06L12 5.06l4.47 4.47a.75.75 0 101.06-1.06l-5-5zm-5 11a.75.75 0 00-1.06 1.06l5 5a.75.75 0 001.06 0l5-5a.75.75 0 10-1.06-1.06L12 18.94l-4.47-4.47z" fill-rule="evenodd" clip-rule="evenodd"></path></svg></label></div></div></div></div></div><div><div><div class="Editable-languageSuggestions" style="left: -1179px; top: -999px;"><div><div class="Popover"><label class="Editable-languageSuggestionsInput Input-wrapper"><input autocomplete="off" role="combobox" aria-expanded="false" aria-autocomplete="list" aria-activedescendant="AutoComplete53-0" id="Popover52-toggle" aria-haspopup="true" aria-owns="Popover52-content" class="Input" placeholder="选择语言" value=""><svg width="24" height="24" viewBox="0 0 24 24" data-new-api="ArrowUpDown24" data-old-api="Select" fill="#afbdcf" class="Zi Zi--Select"><path d="M12.53 3.47a.75.75 0 00-1.06 0l-5 5a.75.75 0 001.06 1.06L12 5.06l4.47 4.47a.75.75 0 101.06-1.06l-5-5zm-5 11a.75.75 0 00-1.06 1.06l5 5a.75.75 0 001.06 0l5-5a.75.75 0 10-1.06-1.06L12 18.94l-4.47-4.47z" fill-rule="evenodd" clip-rule="evenodd"></path></svg></label></div></div></div></div></div></body></html>